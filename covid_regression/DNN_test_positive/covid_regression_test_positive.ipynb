{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wehs7661/deep_learning_projects/blob/master/covid_regression/DNN_test_positive/covid_regression_test_positive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz0_QVkxCrX3"
      },
      "source": [
        "# **A deep neural network for predicting the COVID-19 test positive rate**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebbook is adapted from the homework notebook ([Homework 1](https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.ipynb), written by Heng-Jui Chang @ NTUEE) of the 2021 Machine Learning class taught by Dr. Hung-Yi Lee @ NTUEE. The explanation about the assignment can be found in the following links:\n",
        "- Slides: https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.pdf  \n",
        "- Videos (Mandarin): https://cool.ntu.edu.tw/courses/4793/modules/items/172854  \n",
        "https://cool.ntu.edu.tw/courses/4793/modules/items/172853  \n",
        "- Video (English): https://cool.ntu.edu.tw/courses/4793/modules/items/176529"
      ],
      "metadata": {
        "id": "nuvRS9yxA1y8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeZnPAiwDRWG"
      },
      "source": [
        "The goal of this notebook meet all the requirements of the original assignments, which include\n",
        "- Solving a regression problem with deep neural networks (DNN)\n",
        "- Understanding basic DNN training tips.\n",
        "- Selecting and justifying important features\n",
        "- Improving training by playing around different optimizers or varying learning rates\n",
        "- Applying L2 regularization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's get started!"
      ],
      "metadata": {
        "id": "AcZS-1AVDHkh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Section 1. Statement of the problem**\n",
        "Before we get to the statement of the problem, let's first download the datasets and take a look at them. These datasets were obtained from the [daily surveys conducted by the Delphi Group @ CMU](https://delphi.cmu.edu/covidcast/). Note that if the Google drive links are dead, you can download data from [kaggle](https://www.kaggle.com/c/ml2021spring-hw1/data), and upload data manually to the workspace.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ut4h8iaaDKjY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMj55YDKG6ch",
        "outputId": "a175b481-5fff-45cb-846b-5ff9b24c52e3"
      },
      "source": [
        "tr_path = 'covid.train.csv'  # path to training data\n",
        "tt_path = 'covid.test.csv'   # path to testing data\n",
        "\n",
        "!gdown --id '19CCyCgJrUxtvgZF53vnctJiOJ23T5mqF' --output covid.train.csv\n",
        "!gdown --id '1CE240jLm2npU-tdz81-oVKEF3T2yfT1O' --output covid.test.csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19CCyCgJrUxtvgZF53vnctJiOJ23T5mqF\n",
            "To: /content/covid.train.csv\n",
            "100% 2.00M/2.00M [00:00<00:00, 182MB/s]\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CE240jLm2npU-tdz81-oVKEF3T2yfT1O\n",
            "To: /content/covid.test.csv\n",
            "100% 651k/651k [00:00<00:00, 142MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "pd.set_option('display.max_columns', None) # to show all coumns below\n",
        "df = pd.read_csv('covid.train.csv'); df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "XqyYQquILV6r",
        "outputId": "03f6cab8-9c6d-403b-ce94-b5f222b0b0b7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id   AL   AK   AZ   AR   CA   CO   CT   FL   GA   ID   IL   IN   IA  \\\n",
              "0        0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "1        1  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "2        2  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "3        3  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "4        4  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
              "2695  2695  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "2696  2696  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "2697  2697  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "2698  2698  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "2699  2699  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "\n",
              "       KS   KY   LA   MD   MA   MI   MN   MS   MO   NE   NV   NJ   NM   NY  \\\n",
              "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
              "2695  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "2696  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "2697  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "2698  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "2699  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "\n",
              "       NC   OH   OK   OR   PA   RI   SC   TX   UT   VA   WA   WV   WI  \\\n",
              "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
              "2695  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
              "2696  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
              "2697  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
              "2698  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
              "2699  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
              "\n",
              "           cli       ili  hh_cmnty_cli  nohh_cmnty_cli  wearing_mask  \\\n",
              "0     0.814610  0.771356     25.648907       21.242063     84.644672   \n",
              "1     0.838995  0.807767     25.679101       21.280270     84.005294   \n",
              "2     0.897802  0.887893     26.060544       21.503832     84.438618   \n",
              "3     0.972842  0.965496     25.754087       21.016210     84.133873   \n",
              "4     0.955306  0.963079     25.947015       20.941798     83.995931   \n",
              "...        ...       ...           ...             ...           ...   \n",
              "2695  0.655823  0.659976     25.265366       20.468897     91.011756   \n",
              "2696  0.598352  0.602552     25.299465       20.756444     90.682057   \n",
              "2697  0.586713  0.597559     25.271178       20.770195     90.866100   \n",
              "2698  0.576435  0.595312     24.607461       20.176201     90.846126   \n",
              "2699  0.562426  0.572969     24.020275       19.654514     90.928655   \n",
              "\n",
              "      travel_outside_state  work_outside_home       shop  restaurant  \\\n",
              "0                13.462475          36.519841  63.139094   23.835119   \n",
              "1                13.467716          36.637887  63.318650   23.688882   \n",
              "2                13.038611          36.429119  62.434539   23.812411   \n",
              "3                12.581952          36.416557  62.024517   23.682974   \n",
              "4                12.938675          37.014578  62.116842   23.593983   \n",
              "...                    ...                ...        ...         ...   \n",
              "2695              6.801897          32.727184  50.265694   15.188547   \n",
              "2696              7.152368          33.638563  50.050349   15.462823   \n",
              "2697              6.857209          33.959012  50.024971   15.090116   \n",
              "2698              6.851475          33.932384  49.885129   14.779264   \n",
              "2699              6.642911          33.822577  50.056772   14.961085   \n",
              "\n",
              "      spent_time  large_event  public_transit    anxious  depressed  \\\n",
              "0      44.726055    16.946929        1.716262  15.494193  12.043275   \n",
              "1      44.385166    16.463551        1.664819  15.299228  12.051505   \n",
              "2      43.430423    16.151527        1.602635  15.409449  12.088688   \n",
              "3      43.196313    16.123386        1.641863  15.230063  11.809047   \n",
              "4      43.362200    16.159971        1.677523  15.717207  12.355918   \n",
              "...          ...          ...             ...        ...        ...   \n",
              "2695   31.597793     8.013637        1.768811  14.699027  11.227049   \n",
              "2696   31.656358     8.239559        1.789015  14.808636  11.371546   \n",
              "2697   30.839219     7.849525        1.760094  14.617563  11.163213   \n",
              "2698   30.617100     7.754800        1.780730  14.513419  11.281241   \n",
              "2699   30.595194     7.744075        1.921828  14.160990  11.163526   \n",
              "\n",
              "      felt_isolated  worried_become_ill  worried_finances  tested_positive  \\\n",
              "0         17.000647           53.439316         43.279629        19.586492   \n",
              "1         16.552264           53.256795         43.622728        20.151838   \n",
              "2         16.702086           53.991549         43.604229        20.704935   \n",
              "3         16.506973           54.185521         42.665766        21.292911   \n",
              "4         16.273294           53.637069         42.972417        21.166656   \n",
              "...             ...                 ...               ...              ...   \n",
              "2695      18.814486           68.115748         38.478143        13.869286   \n",
              "2696      19.257324           67.691795         38.953184        13.434180   \n",
              "2697      18.742673           68.024690         38.920206        13.008853   \n",
              "2698      18.539741           67.855755         39.224244        12.725638   \n",
              "2699      18.702564           67.731162         38.740651        12.613441   \n",
              "\n",
              "         cli.1     ili.1  hh_cmnty_cli.1  nohh_cmnty_cli.1  wearing_mask.1  \\\n",
              "0     0.838995  0.807767       25.679101         21.280270       84.005294   \n",
              "1     0.897802  0.887893       26.060544         21.503832       84.438618   \n",
              "2     0.972842  0.965496       25.754087         21.016210       84.133873   \n",
              "3     0.955306  0.963079       25.947015         20.941798       83.995931   \n",
              "4     0.947513  0.968764       26.350501         21.109971       83.819531   \n",
              "...        ...       ...             ...               ...             ...   \n",
              "2695  0.598352  0.602552       25.299465         20.756444       90.682057   \n",
              "2696  0.586713  0.597559       25.271178         20.770195       90.866100   \n",
              "2697  0.576435  0.595312       24.607461         20.176201       90.846126   \n",
              "2698  0.562426  0.572969       24.020275         19.654514       90.928655   \n",
              "2699  0.600671  0.611160       23.797738         19.519105       90.957424   \n",
              "\n",
              "      travel_outside_state.1  work_outside_home.1     shop.1  restaurant.1  \\\n",
              "0                  13.467716            36.637887  63.318650     23.688882   \n",
              "1                  13.038611            36.429119  62.434539     23.812411   \n",
              "2                  12.581952            36.416557  62.024517     23.682974   \n",
              "3                  12.938675            37.014578  62.116842     23.593983   \n",
              "4                  12.452336            36.270021  61.294809     22.576992   \n",
              "...                      ...                  ...        ...           ...   \n",
              "2695                7.152368            33.638563  50.050349     15.462823   \n",
              "2696                6.857209            33.959012  50.024971     15.090116   \n",
              "2697                6.851475            33.932384  49.885129     14.779264   \n",
              "2698                6.642911            33.822577  50.056772     14.961085   \n",
              "2699                6.800289            33.196095  49.620924     14.609582   \n",
              "\n",
              "      spent_time.1  large_event.1  public_transit.1  anxious.1  depressed.1  \\\n",
              "0        44.385166      16.463551          1.664819  15.299228    12.051505   \n",
              "1        43.430423      16.151527          1.602635  15.409449    12.088688   \n",
              "2        43.196313      16.123386          1.641863  15.230063    11.809047   \n",
              "3        43.362200      16.159971          1.677523  15.717207    12.355918   \n",
              "4        42.954574      15.544373          1.578030  15.295650    12.218123   \n",
              "...            ...            ...               ...        ...          ...   \n",
              "2695     31.656358       8.239559          1.789015  14.808636    11.371546   \n",
              "2696     30.839219       7.849525          1.760094  14.617563    11.163213   \n",
              "2697     30.617100       7.754800          1.780730  14.513419    11.281241   \n",
              "2698     30.595194       7.744075          1.921828  14.160990    11.163526   \n",
              "2699     30.420998       7.687974          1.992580  14.409427    11.330301   \n",
              "\n",
              "      felt_isolated.1  worried_become_ill.1  worried_finances.1  \\\n",
              "0           16.552264             53.256795           43.622728   \n",
              "1           16.702086             53.991549           43.604229   \n",
              "2           16.506973             54.185521           42.665766   \n",
              "3           16.273294             53.637069           42.972417   \n",
              "4           16.045504             52.446223           42.907472   \n",
              "...               ...                   ...                 ...   \n",
              "2695        19.257324             67.691795           38.953184   \n",
              "2696        18.742673             68.024690           38.920206   \n",
              "2697        18.539741             67.855755           39.224244   \n",
              "2698        18.702564             67.731162           38.740651   \n",
              "2699        19.134697             67.795100           38.595125   \n",
              "\n",
              "      tested_positive.1     cli.2     ili.2  hh_cmnty_cli.2  nohh_cmnty_cli.2  \\\n",
              "0             20.151838  0.897802  0.887893       26.060544         21.503832   \n",
              "1             20.704935  0.972842  0.965496       25.754087         21.016210   \n",
              "2             21.292911  0.955306  0.963079       25.947015         20.941798   \n",
              "3             21.166656  0.947513  0.968764       26.350501         21.109971   \n",
              "4             19.896607  0.883833  0.893020       26.480624         21.003982   \n",
              "...                 ...       ...       ...             ...               ...   \n",
              "2695          13.434180  0.586713  0.597559       25.271178         20.770195   \n",
              "2696          13.008853  0.576435  0.595312       24.607461         20.176201   \n",
              "2697          12.725638  0.562426  0.572969       24.020275         19.654514   \n",
              "2698          12.613441  0.600671  0.611160       23.797738         19.519105   \n",
              "2699          12.477227  0.560519  0.571126       23.467835         19.174193   \n",
              "\n",
              "      wearing_mask.2  travel_outside_state.2  work_outside_home.2     shop.2  \\\n",
              "0          84.438618               13.038611            36.429119  62.434539   \n",
              "1          84.133873               12.581952            36.416557  62.024517   \n",
              "2          83.995931               12.938675            37.014578  62.116842   \n",
              "3          83.819531               12.452336            36.270021  61.294809   \n",
              "4          84.049437               12.224644            35.380198  60.664482   \n",
              "...              ...                     ...                  ...        ...   \n",
              "2695       90.866100                6.857209            33.959012  50.024971   \n",
              "2696       90.846126                6.851475            33.932384  49.885129   \n",
              "2697       90.928655                6.642911            33.822577  50.056772   \n",
              "2698       90.957424                6.800289            33.196095  49.620924   \n",
              "2699       91.110463                6.931543            33.096657  49.510599   \n",
              "\n",
              "      restaurant.2  spent_time.2  large_event.2  public_transit.2  anxious.2  \\\n",
              "0        23.812411     43.430423      16.151527          1.602635  15.409449   \n",
              "1        23.682974     43.196313      16.123386          1.641863  15.230063   \n",
              "2        23.593983     43.362200      16.159971          1.677523  15.717207   \n",
              "3        22.576992     42.954574      15.544373          1.578030  15.295650   \n",
              "4        22.091433     43.290957      15.214655          1.641667  14.778802   \n",
              "...            ...           ...            ...               ...        ...   \n",
              "2695     15.090116     30.839219       7.849525          1.760094  14.617563   \n",
              "2696     14.779264     30.617100       7.754800          1.780730  14.513419   \n",
              "2697     14.961085     30.595194       7.744075          1.921828  14.160990   \n",
              "2698     14.609582     30.420998       7.687974          1.992580  14.409427   \n",
              "2699     14.464053     30.469791       7.692942          1.966064  14.616400   \n",
              "\n",
              "      depressed.2  felt_isolated.2  worried_become_ill.2  worried_finances.2  \\\n",
              "0       12.088688        16.702086             53.991549           43.604229   \n",
              "1       11.809047        16.506973             54.185521           42.665766   \n",
              "2       12.355918        16.273294             53.637069           42.972417   \n",
              "3       12.218123        16.045504             52.446223           42.907472   \n",
              "4       12.417256        16.134238             52.560315           43.321985   \n",
              "...           ...              ...                   ...                 ...   \n",
              "2695    11.163213        18.742673             68.024690           38.920206   \n",
              "2696    11.281241        18.539741             67.855755           39.224244   \n",
              "2697    11.163526        18.702564             67.731162           38.740651   \n",
              "2698    11.330301        19.134697             67.795100           38.595125   \n",
              "2699    11.522773        19.295834             68.284078           38.453820   \n",
              "\n",
              "      tested_positive.2  \n",
              "0             20.704935  \n",
              "1             21.292911  \n",
              "2             21.166656  \n",
              "3             19.896607  \n",
              "4             20.178428  \n",
              "...                 ...  \n",
              "2695          13.008853  \n",
              "2696          12.725638  \n",
              "2697          12.613441  \n",
              "2698          12.477227  \n",
              "2699          11.811719  \n",
              "\n",
              "[2700 rows x 95 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d742d10d-8be2-4483-87dc-5920f6ef1997\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>AL</th>\n",
              "      <th>AK</th>\n",
              "      <th>AZ</th>\n",
              "      <th>AR</th>\n",
              "      <th>CA</th>\n",
              "      <th>CO</th>\n",
              "      <th>CT</th>\n",
              "      <th>FL</th>\n",
              "      <th>GA</th>\n",
              "      <th>ID</th>\n",
              "      <th>IL</th>\n",
              "      <th>IN</th>\n",
              "      <th>IA</th>\n",
              "      <th>KS</th>\n",
              "      <th>KY</th>\n",
              "      <th>LA</th>\n",
              "      <th>MD</th>\n",
              "      <th>MA</th>\n",
              "      <th>MI</th>\n",
              "      <th>MN</th>\n",
              "      <th>MS</th>\n",
              "      <th>MO</th>\n",
              "      <th>NE</th>\n",
              "      <th>NV</th>\n",
              "      <th>NJ</th>\n",
              "      <th>NM</th>\n",
              "      <th>NY</th>\n",
              "      <th>NC</th>\n",
              "      <th>OH</th>\n",
              "      <th>OK</th>\n",
              "      <th>OR</th>\n",
              "      <th>PA</th>\n",
              "      <th>RI</th>\n",
              "      <th>SC</th>\n",
              "      <th>TX</th>\n",
              "      <th>UT</th>\n",
              "      <th>VA</th>\n",
              "      <th>WA</th>\n",
              "      <th>WV</th>\n",
              "      <th>WI</th>\n",
              "      <th>cli</th>\n",
              "      <th>ili</th>\n",
              "      <th>hh_cmnty_cli</th>\n",
              "      <th>nohh_cmnty_cli</th>\n",
              "      <th>wearing_mask</th>\n",
              "      <th>travel_outside_state</th>\n",
              "      <th>work_outside_home</th>\n",
              "      <th>shop</th>\n",
              "      <th>restaurant</th>\n",
              "      <th>spent_time</th>\n",
              "      <th>large_event</th>\n",
              "      <th>public_transit</th>\n",
              "      <th>anxious</th>\n",
              "      <th>depressed</th>\n",
              "      <th>felt_isolated</th>\n",
              "      <th>worried_become_ill</th>\n",
              "      <th>worried_finances</th>\n",
              "      <th>tested_positive</th>\n",
              "      <th>cli.1</th>\n",
              "      <th>ili.1</th>\n",
              "      <th>hh_cmnty_cli.1</th>\n",
              "      <th>nohh_cmnty_cli.1</th>\n",
              "      <th>wearing_mask.1</th>\n",
              "      <th>travel_outside_state.1</th>\n",
              "      <th>work_outside_home.1</th>\n",
              "      <th>shop.1</th>\n",
              "      <th>restaurant.1</th>\n",
              "      <th>spent_time.1</th>\n",
              "      <th>large_event.1</th>\n",
              "      <th>public_transit.1</th>\n",
              "      <th>anxious.1</th>\n",
              "      <th>depressed.1</th>\n",
              "      <th>felt_isolated.1</th>\n",
              "      <th>worried_become_ill.1</th>\n",
              "      <th>worried_finances.1</th>\n",
              "      <th>tested_positive.1</th>\n",
              "      <th>cli.2</th>\n",
              "      <th>ili.2</th>\n",
              "      <th>hh_cmnty_cli.2</th>\n",
              "      <th>nohh_cmnty_cli.2</th>\n",
              "      <th>wearing_mask.2</th>\n",
              "      <th>travel_outside_state.2</th>\n",
              "      <th>work_outside_home.2</th>\n",
              "      <th>shop.2</th>\n",
              "      <th>restaurant.2</th>\n",
              "      <th>spent_time.2</th>\n",
              "      <th>large_event.2</th>\n",
              "      <th>public_transit.2</th>\n",
              "      <th>anxious.2</th>\n",
              "      <th>depressed.2</th>\n",
              "      <th>felt_isolated.2</th>\n",
              "      <th>worried_become_ill.2</th>\n",
              "      <th>worried_finances.2</th>\n",
              "      <th>tested_positive.2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.814610</td>\n",
              "      <td>0.771356</td>\n",
              "      <td>25.648907</td>\n",
              "      <td>21.242063</td>\n",
              "      <td>84.644672</td>\n",
              "      <td>13.462475</td>\n",
              "      <td>36.519841</td>\n",
              "      <td>63.139094</td>\n",
              "      <td>23.835119</td>\n",
              "      <td>44.726055</td>\n",
              "      <td>16.946929</td>\n",
              "      <td>1.716262</td>\n",
              "      <td>15.494193</td>\n",
              "      <td>12.043275</td>\n",
              "      <td>17.000647</td>\n",
              "      <td>53.439316</td>\n",
              "      <td>43.279629</td>\n",
              "      <td>19.586492</td>\n",
              "      <td>0.838995</td>\n",
              "      <td>0.807767</td>\n",
              "      <td>25.679101</td>\n",
              "      <td>21.280270</td>\n",
              "      <td>84.005294</td>\n",
              "      <td>13.467716</td>\n",
              "      <td>36.637887</td>\n",
              "      <td>63.318650</td>\n",
              "      <td>23.688882</td>\n",
              "      <td>44.385166</td>\n",
              "      <td>16.463551</td>\n",
              "      <td>1.664819</td>\n",
              "      <td>15.299228</td>\n",
              "      <td>12.051505</td>\n",
              "      <td>16.552264</td>\n",
              "      <td>53.256795</td>\n",
              "      <td>43.622728</td>\n",
              "      <td>20.151838</td>\n",
              "      <td>0.897802</td>\n",
              "      <td>0.887893</td>\n",
              "      <td>26.060544</td>\n",
              "      <td>21.503832</td>\n",
              "      <td>84.438618</td>\n",
              "      <td>13.038611</td>\n",
              "      <td>36.429119</td>\n",
              "      <td>62.434539</td>\n",
              "      <td>23.812411</td>\n",
              "      <td>43.430423</td>\n",
              "      <td>16.151527</td>\n",
              "      <td>1.602635</td>\n",
              "      <td>15.409449</td>\n",
              "      <td>12.088688</td>\n",
              "      <td>16.702086</td>\n",
              "      <td>53.991549</td>\n",
              "      <td>43.604229</td>\n",
              "      <td>20.704935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.838995</td>\n",
              "      <td>0.807767</td>\n",
              "      <td>25.679101</td>\n",
              "      <td>21.280270</td>\n",
              "      <td>84.005294</td>\n",
              "      <td>13.467716</td>\n",
              "      <td>36.637887</td>\n",
              "      <td>63.318650</td>\n",
              "      <td>23.688882</td>\n",
              "      <td>44.385166</td>\n",
              "      <td>16.463551</td>\n",
              "      <td>1.664819</td>\n",
              "      <td>15.299228</td>\n",
              "      <td>12.051505</td>\n",
              "      <td>16.552264</td>\n",
              "      <td>53.256795</td>\n",
              "      <td>43.622728</td>\n",
              "      <td>20.151838</td>\n",
              "      <td>0.897802</td>\n",
              "      <td>0.887893</td>\n",
              "      <td>26.060544</td>\n",
              "      <td>21.503832</td>\n",
              "      <td>84.438618</td>\n",
              "      <td>13.038611</td>\n",
              "      <td>36.429119</td>\n",
              "      <td>62.434539</td>\n",
              "      <td>23.812411</td>\n",
              "      <td>43.430423</td>\n",
              "      <td>16.151527</td>\n",
              "      <td>1.602635</td>\n",
              "      <td>15.409449</td>\n",
              "      <td>12.088688</td>\n",
              "      <td>16.702086</td>\n",
              "      <td>53.991549</td>\n",
              "      <td>43.604229</td>\n",
              "      <td>20.704935</td>\n",
              "      <td>0.972842</td>\n",
              "      <td>0.965496</td>\n",
              "      <td>25.754087</td>\n",
              "      <td>21.016210</td>\n",
              "      <td>84.133873</td>\n",
              "      <td>12.581952</td>\n",
              "      <td>36.416557</td>\n",
              "      <td>62.024517</td>\n",
              "      <td>23.682974</td>\n",
              "      <td>43.196313</td>\n",
              "      <td>16.123386</td>\n",
              "      <td>1.641863</td>\n",
              "      <td>15.230063</td>\n",
              "      <td>11.809047</td>\n",
              "      <td>16.506973</td>\n",
              "      <td>54.185521</td>\n",
              "      <td>42.665766</td>\n",
              "      <td>21.292911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.897802</td>\n",
              "      <td>0.887893</td>\n",
              "      <td>26.060544</td>\n",
              "      <td>21.503832</td>\n",
              "      <td>84.438618</td>\n",
              "      <td>13.038611</td>\n",
              "      <td>36.429119</td>\n",
              "      <td>62.434539</td>\n",
              "      <td>23.812411</td>\n",
              "      <td>43.430423</td>\n",
              "      <td>16.151527</td>\n",
              "      <td>1.602635</td>\n",
              "      <td>15.409449</td>\n",
              "      <td>12.088688</td>\n",
              "      <td>16.702086</td>\n",
              "      <td>53.991549</td>\n",
              "      <td>43.604229</td>\n",
              "      <td>20.704935</td>\n",
              "      <td>0.972842</td>\n",
              "      <td>0.965496</td>\n",
              "      <td>25.754087</td>\n",
              "      <td>21.016210</td>\n",
              "      <td>84.133873</td>\n",
              "      <td>12.581952</td>\n",
              "      <td>36.416557</td>\n",
              "      <td>62.024517</td>\n",
              "      <td>23.682974</td>\n",
              "      <td>43.196313</td>\n",
              "      <td>16.123386</td>\n",
              "      <td>1.641863</td>\n",
              "      <td>15.230063</td>\n",
              "      <td>11.809047</td>\n",
              "      <td>16.506973</td>\n",
              "      <td>54.185521</td>\n",
              "      <td>42.665766</td>\n",
              "      <td>21.292911</td>\n",
              "      <td>0.955306</td>\n",
              "      <td>0.963079</td>\n",
              "      <td>25.947015</td>\n",
              "      <td>20.941798</td>\n",
              "      <td>83.995931</td>\n",
              "      <td>12.938675</td>\n",
              "      <td>37.014578</td>\n",
              "      <td>62.116842</td>\n",
              "      <td>23.593983</td>\n",
              "      <td>43.362200</td>\n",
              "      <td>16.159971</td>\n",
              "      <td>1.677523</td>\n",
              "      <td>15.717207</td>\n",
              "      <td>12.355918</td>\n",
              "      <td>16.273294</td>\n",
              "      <td>53.637069</td>\n",
              "      <td>42.972417</td>\n",
              "      <td>21.166656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.972842</td>\n",
              "      <td>0.965496</td>\n",
              "      <td>25.754087</td>\n",
              "      <td>21.016210</td>\n",
              "      <td>84.133873</td>\n",
              "      <td>12.581952</td>\n",
              "      <td>36.416557</td>\n",
              "      <td>62.024517</td>\n",
              "      <td>23.682974</td>\n",
              "      <td>43.196313</td>\n",
              "      <td>16.123386</td>\n",
              "      <td>1.641863</td>\n",
              "      <td>15.230063</td>\n",
              "      <td>11.809047</td>\n",
              "      <td>16.506973</td>\n",
              "      <td>54.185521</td>\n",
              "      <td>42.665766</td>\n",
              "      <td>21.292911</td>\n",
              "      <td>0.955306</td>\n",
              "      <td>0.963079</td>\n",
              "      <td>25.947015</td>\n",
              "      <td>20.941798</td>\n",
              "      <td>83.995931</td>\n",
              "      <td>12.938675</td>\n",
              "      <td>37.014578</td>\n",
              "      <td>62.116842</td>\n",
              "      <td>23.593983</td>\n",
              "      <td>43.362200</td>\n",
              "      <td>16.159971</td>\n",
              "      <td>1.677523</td>\n",
              "      <td>15.717207</td>\n",
              "      <td>12.355918</td>\n",
              "      <td>16.273294</td>\n",
              "      <td>53.637069</td>\n",
              "      <td>42.972417</td>\n",
              "      <td>21.166656</td>\n",
              "      <td>0.947513</td>\n",
              "      <td>0.968764</td>\n",
              "      <td>26.350501</td>\n",
              "      <td>21.109971</td>\n",
              "      <td>83.819531</td>\n",
              "      <td>12.452336</td>\n",
              "      <td>36.270021</td>\n",
              "      <td>61.294809</td>\n",
              "      <td>22.576992</td>\n",
              "      <td>42.954574</td>\n",
              "      <td>15.544373</td>\n",
              "      <td>1.578030</td>\n",
              "      <td>15.295650</td>\n",
              "      <td>12.218123</td>\n",
              "      <td>16.045504</td>\n",
              "      <td>52.446223</td>\n",
              "      <td>42.907472</td>\n",
              "      <td>19.896607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.955306</td>\n",
              "      <td>0.963079</td>\n",
              "      <td>25.947015</td>\n",
              "      <td>20.941798</td>\n",
              "      <td>83.995931</td>\n",
              "      <td>12.938675</td>\n",
              "      <td>37.014578</td>\n",
              "      <td>62.116842</td>\n",
              "      <td>23.593983</td>\n",
              "      <td>43.362200</td>\n",
              "      <td>16.159971</td>\n",
              "      <td>1.677523</td>\n",
              "      <td>15.717207</td>\n",
              "      <td>12.355918</td>\n",
              "      <td>16.273294</td>\n",
              "      <td>53.637069</td>\n",
              "      <td>42.972417</td>\n",
              "      <td>21.166656</td>\n",
              "      <td>0.947513</td>\n",
              "      <td>0.968764</td>\n",
              "      <td>26.350501</td>\n",
              "      <td>21.109971</td>\n",
              "      <td>83.819531</td>\n",
              "      <td>12.452336</td>\n",
              "      <td>36.270021</td>\n",
              "      <td>61.294809</td>\n",
              "      <td>22.576992</td>\n",
              "      <td>42.954574</td>\n",
              "      <td>15.544373</td>\n",
              "      <td>1.578030</td>\n",
              "      <td>15.295650</td>\n",
              "      <td>12.218123</td>\n",
              "      <td>16.045504</td>\n",
              "      <td>52.446223</td>\n",
              "      <td>42.907472</td>\n",
              "      <td>19.896607</td>\n",
              "      <td>0.883833</td>\n",
              "      <td>0.893020</td>\n",
              "      <td>26.480624</td>\n",
              "      <td>21.003982</td>\n",
              "      <td>84.049437</td>\n",
              "      <td>12.224644</td>\n",
              "      <td>35.380198</td>\n",
              "      <td>60.664482</td>\n",
              "      <td>22.091433</td>\n",
              "      <td>43.290957</td>\n",
              "      <td>15.214655</td>\n",
              "      <td>1.641667</td>\n",
              "      <td>14.778802</td>\n",
              "      <td>12.417256</td>\n",
              "      <td>16.134238</td>\n",
              "      <td>52.560315</td>\n",
              "      <td>43.321985</td>\n",
              "      <td>20.178428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2695</th>\n",
              "      <td>2695</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.655823</td>\n",
              "      <td>0.659976</td>\n",
              "      <td>25.265366</td>\n",
              "      <td>20.468897</td>\n",
              "      <td>91.011756</td>\n",
              "      <td>6.801897</td>\n",
              "      <td>32.727184</td>\n",
              "      <td>50.265694</td>\n",
              "      <td>15.188547</td>\n",
              "      <td>31.597793</td>\n",
              "      <td>8.013637</td>\n",
              "      <td>1.768811</td>\n",
              "      <td>14.699027</td>\n",
              "      <td>11.227049</td>\n",
              "      <td>18.814486</td>\n",
              "      <td>68.115748</td>\n",
              "      <td>38.478143</td>\n",
              "      <td>13.869286</td>\n",
              "      <td>0.598352</td>\n",
              "      <td>0.602552</td>\n",
              "      <td>25.299465</td>\n",
              "      <td>20.756444</td>\n",
              "      <td>90.682057</td>\n",
              "      <td>7.152368</td>\n",
              "      <td>33.638563</td>\n",
              "      <td>50.050349</td>\n",
              "      <td>15.462823</td>\n",
              "      <td>31.656358</td>\n",
              "      <td>8.239559</td>\n",
              "      <td>1.789015</td>\n",
              "      <td>14.808636</td>\n",
              "      <td>11.371546</td>\n",
              "      <td>19.257324</td>\n",
              "      <td>67.691795</td>\n",
              "      <td>38.953184</td>\n",
              "      <td>13.434180</td>\n",
              "      <td>0.586713</td>\n",
              "      <td>0.597559</td>\n",
              "      <td>25.271178</td>\n",
              "      <td>20.770195</td>\n",
              "      <td>90.866100</td>\n",
              "      <td>6.857209</td>\n",
              "      <td>33.959012</td>\n",
              "      <td>50.024971</td>\n",
              "      <td>15.090116</td>\n",
              "      <td>30.839219</td>\n",
              "      <td>7.849525</td>\n",
              "      <td>1.760094</td>\n",
              "      <td>14.617563</td>\n",
              "      <td>11.163213</td>\n",
              "      <td>18.742673</td>\n",
              "      <td>68.024690</td>\n",
              "      <td>38.920206</td>\n",
              "      <td>13.008853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2696</th>\n",
              "      <td>2696</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.598352</td>\n",
              "      <td>0.602552</td>\n",
              "      <td>25.299465</td>\n",
              "      <td>20.756444</td>\n",
              "      <td>90.682057</td>\n",
              "      <td>7.152368</td>\n",
              "      <td>33.638563</td>\n",
              "      <td>50.050349</td>\n",
              "      <td>15.462823</td>\n",
              "      <td>31.656358</td>\n",
              "      <td>8.239559</td>\n",
              "      <td>1.789015</td>\n",
              "      <td>14.808636</td>\n",
              "      <td>11.371546</td>\n",
              "      <td>19.257324</td>\n",
              "      <td>67.691795</td>\n",
              "      <td>38.953184</td>\n",
              "      <td>13.434180</td>\n",
              "      <td>0.586713</td>\n",
              "      <td>0.597559</td>\n",
              "      <td>25.271178</td>\n",
              "      <td>20.770195</td>\n",
              "      <td>90.866100</td>\n",
              "      <td>6.857209</td>\n",
              "      <td>33.959012</td>\n",
              "      <td>50.024971</td>\n",
              "      <td>15.090116</td>\n",
              "      <td>30.839219</td>\n",
              "      <td>7.849525</td>\n",
              "      <td>1.760094</td>\n",
              "      <td>14.617563</td>\n",
              "      <td>11.163213</td>\n",
              "      <td>18.742673</td>\n",
              "      <td>68.024690</td>\n",
              "      <td>38.920206</td>\n",
              "      <td>13.008853</td>\n",
              "      <td>0.576435</td>\n",
              "      <td>0.595312</td>\n",
              "      <td>24.607461</td>\n",
              "      <td>20.176201</td>\n",
              "      <td>90.846126</td>\n",
              "      <td>6.851475</td>\n",
              "      <td>33.932384</td>\n",
              "      <td>49.885129</td>\n",
              "      <td>14.779264</td>\n",
              "      <td>30.617100</td>\n",
              "      <td>7.754800</td>\n",
              "      <td>1.780730</td>\n",
              "      <td>14.513419</td>\n",
              "      <td>11.281241</td>\n",
              "      <td>18.539741</td>\n",
              "      <td>67.855755</td>\n",
              "      <td>39.224244</td>\n",
              "      <td>12.725638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2697</th>\n",
              "      <td>2697</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.586713</td>\n",
              "      <td>0.597559</td>\n",
              "      <td>25.271178</td>\n",
              "      <td>20.770195</td>\n",
              "      <td>90.866100</td>\n",
              "      <td>6.857209</td>\n",
              "      <td>33.959012</td>\n",
              "      <td>50.024971</td>\n",
              "      <td>15.090116</td>\n",
              "      <td>30.839219</td>\n",
              "      <td>7.849525</td>\n",
              "      <td>1.760094</td>\n",
              "      <td>14.617563</td>\n",
              "      <td>11.163213</td>\n",
              "      <td>18.742673</td>\n",
              "      <td>68.024690</td>\n",
              "      <td>38.920206</td>\n",
              "      <td>13.008853</td>\n",
              "      <td>0.576435</td>\n",
              "      <td>0.595312</td>\n",
              "      <td>24.607461</td>\n",
              "      <td>20.176201</td>\n",
              "      <td>90.846126</td>\n",
              "      <td>6.851475</td>\n",
              "      <td>33.932384</td>\n",
              "      <td>49.885129</td>\n",
              "      <td>14.779264</td>\n",
              "      <td>30.617100</td>\n",
              "      <td>7.754800</td>\n",
              "      <td>1.780730</td>\n",
              "      <td>14.513419</td>\n",
              "      <td>11.281241</td>\n",
              "      <td>18.539741</td>\n",
              "      <td>67.855755</td>\n",
              "      <td>39.224244</td>\n",
              "      <td>12.725638</td>\n",
              "      <td>0.562426</td>\n",
              "      <td>0.572969</td>\n",
              "      <td>24.020275</td>\n",
              "      <td>19.654514</td>\n",
              "      <td>90.928655</td>\n",
              "      <td>6.642911</td>\n",
              "      <td>33.822577</td>\n",
              "      <td>50.056772</td>\n",
              "      <td>14.961085</td>\n",
              "      <td>30.595194</td>\n",
              "      <td>7.744075</td>\n",
              "      <td>1.921828</td>\n",
              "      <td>14.160990</td>\n",
              "      <td>11.163526</td>\n",
              "      <td>18.702564</td>\n",
              "      <td>67.731162</td>\n",
              "      <td>38.740651</td>\n",
              "      <td>12.613441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2698</th>\n",
              "      <td>2698</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.576435</td>\n",
              "      <td>0.595312</td>\n",
              "      <td>24.607461</td>\n",
              "      <td>20.176201</td>\n",
              "      <td>90.846126</td>\n",
              "      <td>6.851475</td>\n",
              "      <td>33.932384</td>\n",
              "      <td>49.885129</td>\n",
              "      <td>14.779264</td>\n",
              "      <td>30.617100</td>\n",
              "      <td>7.754800</td>\n",
              "      <td>1.780730</td>\n",
              "      <td>14.513419</td>\n",
              "      <td>11.281241</td>\n",
              "      <td>18.539741</td>\n",
              "      <td>67.855755</td>\n",
              "      <td>39.224244</td>\n",
              "      <td>12.725638</td>\n",
              "      <td>0.562426</td>\n",
              "      <td>0.572969</td>\n",
              "      <td>24.020275</td>\n",
              "      <td>19.654514</td>\n",
              "      <td>90.928655</td>\n",
              "      <td>6.642911</td>\n",
              "      <td>33.822577</td>\n",
              "      <td>50.056772</td>\n",
              "      <td>14.961085</td>\n",
              "      <td>30.595194</td>\n",
              "      <td>7.744075</td>\n",
              "      <td>1.921828</td>\n",
              "      <td>14.160990</td>\n",
              "      <td>11.163526</td>\n",
              "      <td>18.702564</td>\n",
              "      <td>67.731162</td>\n",
              "      <td>38.740651</td>\n",
              "      <td>12.613441</td>\n",
              "      <td>0.600671</td>\n",
              "      <td>0.611160</td>\n",
              "      <td>23.797738</td>\n",
              "      <td>19.519105</td>\n",
              "      <td>90.957424</td>\n",
              "      <td>6.800289</td>\n",
              "      <td>33.196095</td>\n",
              "      <td>49.620924</td>\n",
              "      <td>14.609582</td>\n",
              "      <td>30.420998</td>\n",
              "      <td>7.687974</td>\n",
              "      <td>1.992580</td>\n",
              "      <td>14.409427</td>\n",
              "      <td>11.330301</td>\n",
              "      <td>19.134697</td>\n",
              "      <td>67.795100</td>\n",
              "      <td>38.595125</td>\n",
              "      <td>12.477227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2699</th>\n",
              "      <td>2699</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.562426</td>\n",
              "      <td>0.572969</td>\n",
              "      <td>24.020275</td>\n",
              "      <td>19.654514</td>\n",
              "      <td>90.928655</td>\n",
              "      <td>6.642911</td>\n",
              "      <td>33.822577</td>\n",
              "      <td>50.056772</td>\n",
              "      <td>14.961085</td>\n",
              "      <td>30.595194</td>\n",
              "      <td>7.744075</td>\n",
              "      <td>1.921828</td>\n",
              "      <td>14.160990</td>\n",
              "      <td>11.163526</td>\n",
              "      <td>18.702564</td>\n",
              "      <td>67.731162</td>\n",
              "      <td>38.740651</td>\n",
              "      <td>12.613441</td>\n",
              "      <td>0.600671</td>\n",
              "      <td>0.611160</td>\n",
              "      <td>23.797738</td>\n",
              "      <td>19.519105</td>\n",
              "      <td>90.957424</td>\n",
              "      <td>6.800289</td>\n",
              "      <td>33.196095</td>\n",
              "      <td>49.620924</td>\n",
              "      <td>14.609582</td>\n",
              "      <td>30.420998</td>\n",
              "      <td>7.687974</td>\n",
              "      <td>1.992580</td>\n",
              "      <td>14.409427</td>\n",
              "      <td>11.330301</td>\n",
              "      <td>19.134697</td>\n",
              "      <td>67.795100</td>\n",
              "      <td>38.595125</td>\n",
              "      <td>12.477227</td>\n",
              "      <td>0.560519</td>\n",
              "      <td>0.571126</td>\n",
              "      <td>23.467835</td>\n",
              "      <td>19.174193</td>\n",
              "      <td>91.110463</td>\n",
              "      <td>6.931543</td>\n",
              "      <td>33.096657</td>\n",
              "      <td>49.510599</td>\n",
              "      <td>14.464053</td>\n",
              "      <td>30.469791</td>\n",
              "      <td>7.692942</td>\n",
              "      <td>1.966064</td>\n",
              "      <td>14.616400</td>\n",
              "      <td>11.522773</td>\n",
              "      <td>19.295834</td>\n",
              "      <td>68.284078</td>\n",
              "      <td>38.453820</td>\n",
              "      <td>11.811719</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2700 rows × 95 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d742d10d-8be2-4483-87dc-5920f6ef1997')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d742d10d-8be2-4483-87dc-5920f6ef1997 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d742d10d-8be2-4483-87dc-5920f6ef1997');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As shown above, the training set has 95 columns, which include:\n",
        "- 1 column of the IDs\n",
        "- 40 columns showing the states encoded to one-hot vectors\n",
        "- 18 columns of Day 1 features\n",
        "- 18 columns of Day 2 features\n",
        "- 18 columns of Day 3 features\n",
        "\n",
        "For each day, 18 features include the follows:\n",
        "- 4 columns of COVID-like illness, including\n",
        "  - `ili`: Percentage of people having influenza-like illness\n",
        "  - `cli`: Percentage of people having COVID-like illness\n",
        "  - `hh_cmnty_cli`: Percentage of people reporintg illness in their local community, including their household.\n",
        "  - `noww_cmnty_cli`: Percentage of people reporting illness in their local community, not including their household. \n",
        "- 8 columns of behavior indicators, including `wearing_mask`, `travel_outside_state`, `work_outside_home`, `shop`, `restaurant`, `spent_time`, `large_event`, and `public_transit`. Most names of indicators are self-explanatory, except for `spent_time`, which is the percentage of respondents who \"spent time indoors with someone who isn't currently staying with you\" in the past 24 hours. \n",
        "- 5 columns of mental health indicators, including `anxious`, `depressed`, `felt_isolated`, `worried_become_ill`, and `worried_finances`.\n",
        "- 1 column showing the percentage of people who tested positive. \n",
        "\n",
        "All indicators above are expressed in percentages. For more details about how the data was collected and how the indicators were designed, please visit [this site](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/fb-survey.html).\n",
        "\n"
      ],
      "metadata": {
        "id": "I9t74gwFMc5A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As can be examined, there are 2700 samples (2700 rows) in the training dataset and 893 samples in the test set. In the test set, there are also the same 95 columns as in the training set. With these datasets, our goal is to build a deep neural network to **predict the COVID-19 positive rate of Day 3 (in percentage)**, using any numbers of features among the 93 indicators as features."
      ],
      "metadata": {
        "id": "3ejKQ0SZv0LE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Section 2. Setting things up**"
      ],
      "metadata": {
        "id": "T_nj1_l9OJ7d"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS_4-77xHk44"
      },
      "source": [
        "First, we import packages to be used in our notebook and set the random seed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-onQd4JNA5H"
      },
      "source": [
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# For data preprocess\n",
        "import numpy as np\n",
        "import csv\n",
        "import os\n",
        "\n",
        "# For plotting\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "myseed = 42069  # set a random seed for reproducibility\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(myseed)\n",
        "torch.manual_seed(myseed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(myseed)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtE3b6JEH7rw"
      },
      "source": [
        "For convenience, here are some handy utility functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWMT3uf1NGQp"
      },
      "source": [
        "def get_device():\n",
        "    ''' Get device (if GPU is available, use GPU) '''\n",
        "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def plot_learning_curve(loss_record, title=''):\n",
        "    ''' Plot learning curve of your DNN (train & dev loss) '''\n",
        "    total_steps = len(loss_record['train'])\n",
        "    x_1 = range(total_steps)\n",
        "    x_2 = x_1[::len(loss_record['train']) // len(loss_record['dev'])]\n",
        "    figure(figsize=(6, 4))\n",
        "    plt.plot(x_1, loss_record['train'], c='tab:red', label='train')\n",
        "    plt.plot(x_2, loss_record['dev'], c='tab:cyan', label='dev')\n",
        "    plt.ylim(0.0, 5.)\n",
        "    plt.xlabel('Training steps')\n",
        "    plt.ylabel('MSE loss')\n",
        "    plt.title('Learning curve of {}'.format(title))\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_pred(dv_set, model, device, lim=35., preds=None, targets=None):\n",
        "    ''' Plot prediction of your DNN '''\n",
        "    if preds is None or targets is None:\n",
        "        model.eval()\n",
        "        preds, targets = [], []\n",
        "        for x, y in dv_set:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            with torch.no_grad():\n",
        "                pred = model(x)\n",
        "                preds.append(pred.detach().cpu())\n",
        "                targets.append(y.detach().cpu())\n",
        "        preds = torch.cat(preds, dim=0).numpy()\n",
        "        targets = torch.cat(targets, dim=0).numpy()\n",
        "\n",
        "    figure(figsize=(5, 5))\n",
        "    plt.scatter(targets, preds, c='r', alpha=0.5)\n",
        "    plt.plot([-0.2, lim], [-0.2, lim], c='b')\n",
        "    plt.xlim(-0.2, lim)\n",
        "    plt.ylim(-0.2, lim)\n",
        "    plt.xlabel('ground truth value')\n",
        "    plt.ylabel('predicted value')\n",
        "    plt.title('Ground Truth v.s. Prediction')\n",
        "    plt.show()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Section 3. Preparing the datasets**"
      ],
      "metadata": {
        "id": "HPXswSaIDq0n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we will define a class `COVID19Dataset` to prepare the training set, validation set and the test set. Specifically, `COVID19Dataset` \n",
        "- Reads `.csv` files\n",
        "- Extracts features\n",
        "- Splits `covid.train.csv` into the training set and validation set when needed\n",
        "- Normalizes features\n",
        "\n",
        "Notably, in `COVID19Dataset`, 1 out of every 10 points in the training set is used for validation. Also, below I've added some docstrings and modified `COVID19Dataset` from its original code written by Chang to allow higher flexibility of considering arbitrary numbers of features. "
      ],
      "metadata": {
        "id": "Nts7djnpwjuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Using 40 states & 2 tested_positive features (indices = 57 & 75)"
      ],
      "metadata": {
        "id": "DsEouh3Pz1ds"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zlpIp9ANJRU"
      },
      "source": [
        "class COVID19Dataset(Dataset):\n",
        "    ''' Dataset for loading and preprocessing the COVID19 dataset '''\n",
        "    def __init__(self, path, mode='train', feats=list(range(93))):\n",
        "        \"\"\"\n",
        "        Prepares a dataset as specified.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        path : str\n",
        "            The path of the training dataset or the test set. \n",
        "        mode : str\n",
        "            How the dataset should be prepared. Available options include \"train\", \n",
        "            \"dev\", and \"test\".\n",
        "        feats: \n",
        "            The list of feature indices to consider.\n",
        "        \"\"\"\n",
        "        self.mode = mode\n",
        "\n",
        "        # Step 1: Read data into numpy arrays\n",
        "        with open(path, 'r') as fp:\n",
        "            data = list(csv.reader(fp))\n",
        "            data = np.array(data[1:])[:, 1:].astype(float)\n",
        "        \n",
        "        # Step 2: Prepare the dataset\n",
        "        if mode == 'test':\n",
        "            # Testing data\n",
        "            # data: 893 x 93 (40 states + day 1 (18) + day 2 (18) + day 3 (17))\n",
        "            data = data[:, feats]\n",
        "            self.data = torch.FloatTensor(data)\n",
        "        else:\n",
        "            # Training data (train/dev sets)\n",
        "            # data: 2700 x 94 (40 states + day 1 (18) + day 2 (18) + day 3 (18))\n",
        "            target = data[:, -1]\n",
        "            data = data[:, feats]\n",
        "            \n",
        "            # Splitting training data into train & dev sets\n",
        "            if mode == 'train':\n",
        "                indices = [i for i in range(len(data)) if i % 10 != 0]\n",
        "            elif mode == 'dev':\n",
        "                indices = [i for i in range(len(data)) if i % 10 == 0]\n",
        "            \n",
        "            # Convert data into PyTorch tensors\n",
        "            self.data = torch.FloatTensor(data[indices])\n",
        "            self.target = torch.FloatTensor(target[indices])\n",
        "\n",
        "        # Step 3: Normalize features (you may remove this part to see what will happen)\n",
        "        self.data[:, 40:] = \\\n",
        "            (self.data[:, 40:] - self.data[:, 40:].mean(dim=0, keepdim=True)) \\\n",
        "            / self.data[:, 40:].std(dim=0, keepdim=True)\n",
        "\n",
        "        self.dim = self.data.shape[1]\n",
        "\n",
        "        print(f'Finished reading the {mode} set of COVID19 Dataset ({len(self.data)} samples found, each dim = {self.dim})')\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Returns one sample at a time\n",
        "        if self.mode in ['train', 'dev']:\n",
        "            # For training\n",
        "            return self.data[index], self.target[index]\n",
        "        else:\n",
        "            # For testing (no target)\n",
        "            return self.data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        # Returns the size of the dataset\n",
        "        return len(self.data)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we define `prep_dataloader`, which can be used to construct dataloaders for loading data. (Specifically, in `prep_dataloader`, `DataLoader` loads data from a given `Dataset` into batches.)"
      ],
      "metadata": {
        "id": "HqHleX100pba"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlhLk5t6MBX3"
      },
      "source": [
        "def prep_dataloader(path, mode, batch_size, n_jobs=0, feats=list(range(93))):\n",
        "    ''' Generates a dataset, then is put into a dataloader. '''\n",
        "    dataset = COVID19Dataset(path, mode=mode, feats=feats)  # Construct dataset\n",
        "    dataloader = DataLoader(\n",
        "        dataset, batch_size,\n",
        "        shuffle=(mode == 'train'), drop_last=False,\n",
        "        num_workers=n_jobs, pin_memory=True)                # Construct dataloader\n",
        "    return dataloader"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGuycwR0MeQB"
      },
      "source": [
        "# **Section 4. Define classes/functions to build, train, and test neural networks**\n",
        "\n",
        "`NeuralNet` is an `nn.Module` designed for regression.\n",
        "The DNN consists of 2 fully-connected layers with ReLU activation.\n",
        "This module also included a function `cal_loss` for calculating loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49-uXYovOAI0"
      },
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    ''' A simple fully-connected deep neural network '''\n",
        "    def __init__(self, input_dim):\n",
        "        super(NeuralNet, self).__init__()\n",
        "\n",
        "        # Define your neural network here\n",
        "        # TODO: How to modify this model to achieve better performance?\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "        # Mean squared error loss\n",
        "        self.criterion = nn.MSELoss(reduction='mean')\n",
        "\n",
        "    def forward(self, x):\n",
        "        ''' Given input of size (batch_size x input_dim), compute output of the network '''\n",
        "        return self.net(x).squeeze(1)\n",
        "\n",
        "    def cal_loss(self, pred, target):\n",
        "        ''' Calculate loss '''\n",
        "        # TODO: you may implement L1/L2 regularization here\n",
        "        return self.criterion(pred, target)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAM8QecJOyqn"
      },
      "source": [
        " **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOqcmYzMO7jB"
      },
      "source": [
        "def train(tr_set, dv_set, model, config, device):\n",
        "    ''' DNN training '''\n",
        "\n",
        "    n_epochs = config['n_epochs']  # Maximum number of epochs\n",
        "\n",
        "    # Setup optimizer\n",
        "    optimizer = getattr(torch.optim, config['optimizer'])(\n",
        "        model.parameters(), **config['optim_hparas'])\n",
        "\n",
        "    min_mse = 1000.\n",
        "    loss_record = {'train': [], 'dev': []}      # for recording training loss\n",
        "    early_stop_cnt = 0\n",
        "    epoch = 0\n",
        "    while epoch < n_epochs:\n",
        "        model.train()                           # set model to training mode\n",
        "        for x, y in tr_set:                     # iterate through the dataloader\n",
        "            optimizer.zero_grad()               # set gradient to zero\n",
        "            x, y = x.to(device), y.to(device)   # move data to device (cpu/cuda)\n",
        "            pred = model(x)                     # forward pass (compute output)\n",
        "            mse_loss = model.cal_loss(pred, y)  # compute loss\n",
        "            mse_loss.backward()                 # compute gradient (backpropagation)\n",
        "            optimizer.step()                    # update model with optimizer\n",
        "            loss_record['train'].append(mse_loss.detach().cpu().item())\n",
        "\n",
        "        # After each epoch, test your model on the validation (development) set.\n",
        "        dev_mse = dev(dv_set, model, device)\n",
        "        if dev_mse < min_mse:\n",
        "            # Save model if your model improved\n",
        "            min_mse = dev_mse\n",
        "            print('Saving model (epoch = {:4d}, loss = {:.4f})'\n",
        "                .format(epoch + 1, min_mse))\n",
        "            torch.save(model.state_dict(), config['save_path'])  # Save model to specified path\n",
        "            early_stop_cnt = 0\n",
        "        else:\n",
        "            early_stop_cnt += 1\n",
        "\n",
        "        epoch += 1\n",
        "        loss_record['dev'].append(dev_mse)\n",
        "        if early_stop_cnt > config['early_stop']:\n",
        "            # Stop training if your model stops improving for \"config['early_stop']\" epochs.\n",
        "            break\n",
        "\n",
        "    print('Finished training after {} epochs'.format(epoch))\n",
        "    return min_mse, loss_record"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hSd4Bn3O2PL"
      },
      "source": [
        "**Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrxrD3YsN3U2"
      },
      "source": [
        "def dev(dv_set, model, device):\n",
        "    model.eval()                                # set model to evalutation mode\n",
        "    total_loss = 0\n",
        "    for x, y in dv_set:                         # iterate through the dataloader\n",
        "        x, y = x.to(device), y.to(device)       # move data to device (cpu/cuda)\n",
        "        with torch.no_grad():                   # disable gradient calculation\n",
        "            pred = model(x)                     # forward pass (compute output)\n",
        "            mse_loss = model.cal_loss(pred, y)  # compute loss\n",
        "        total_loss += mse_loss.detach().cpu().item() * len(x)  # accumulate loss\n",
        "    total_loss = total_loss / len(dv_set.dataset)              # compute averaged loss\n",
        "\n",
        "    return total_loss"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0pdrhQAO41L"
      },
      "source": [
        "**Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSBMRFlYN5tB"
      },
      "source": [
        "def test(tt_set, model, device):\n",
        "    model.eval()                                # set model to evalutation mode\n",
        "    preds = []\n",
        "    for x in tt_set:                            # iterate through the dataloader\n",
        "        x = x.to(device)                        # move data to device (cpu/cuda)\n",
        "        with torch.no_grad():                   # disable gradient calculation\n",
        "            pred = model(x)                     # forward pass (compute output)\n",
        "            preds.append(pred.detach().cpu())   # collect prediction\n",
        "    preds = torch.cat(preds, dim=0).numpy()     # concatenate all predictions and convert to a numpy array\n",
        "    return preds"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvckkF5dvf0j"
      },
      "source": [
        "# **Section 5. Setup Hyper-parameters and build/train a neural network**\n",
        "\n",
        "`config` contains hyper-parameters for training and the path to save your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPXpdumwPjE7"
      },
      "source": [
        "device = get_device()                 # get the current available device ('cpu' or 'cuda')\n",
        "os.makedirs('models', exist_ok=True)  # The trained model will be saved to ./models/\n",
        "feats= list(range(93))                   # TODO: Using 40 states & 2 tested_positive features\n",
        "\n",
        "# TODO: How to tune these hyper-parameters to improve your model's performance?\n",
        "config = {\n",
        "    'n_epochs': 3000,                # maximum number of epochs\n",
        "    'batch_size': 270,               # mini-batch size for dataloader\n",
        "    'optimizer': 'SGD',              # optimization algorithm (optimizer in torch.optim)\n",
        "    'optim_hparas': {                # hyper-parameters for the optimizer (depends on which optimizer you are using)\n",
        "        'lr': 0.001,                 # learning rate of SGD\n",
        "        'momentum': 0.9              # momentum for SGD\n",
        "    },\n",
        "    'early_stop': 200,               # early stopping epochs (the number epochs since your model's last improvement)\n",
        "    'save_path': 'models/model.pth'  # your model will be saved here\n",
        "}"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6j1eOV3TOH-j"
      },
      "source": [
        "**Load data and model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNrYBMmePLKm",
        "outputId": "98d25685-0959-4d68-ba93-d53dd94ab56e"
      },
      "source": [
        "tr_set = prep_dataloader(tr_path, 'train', config['batch_size'], feats=feats)\n",
        "dv_set = prep_dataloader(tr_path, 'dev', config['batch_size'], feats=feats)\n",
        "tt_set = prep_dataloader(tt_path, 'test', config['batch_size'], feats=feats)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished reading the train set of COVID19 Dataset (2430 samples found, each dim = 93)\n",
            "Finished reading the dev set of COVID19 Dataset (270 samples found, each dim = 93)\n",
            "Finished reading the test set of COVID19 Dataset (893 samples found, each dim = 93)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHylSirLP9oh"
      },
      "source": [
        "model = NeuralNet(tr_set.dataset.dim).to(device)  # Construct model and move to device"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX2B_zgSOPTJ"
      },
      "source": [
        "**Start Training!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrEbUxazQAAZ",
        "outputId": "7c611b8d-81c5-4c48-9aad-5bbc72bad8f8"
      },
      "source": [
        "model_loss, model_loss_record = train(tr_set, dv_set, model, config, device)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model (epoch =    1, loss = 78.8524)\n",
            "Saving model (epoch =    2, loss = 37.6170)\n",
            "Saving model (epoch =    3, loss = 26.1203)\n",
            "Saving model (epoch =    4, loss = 16.1862)\n",
            "Saving model (epoch =    5, loss = 9.7153)\n",
            "Saving model (epoch =    6, loss = 6.3701)\n",
            "Saving model (epoch =    7, loss = 5.1802)\n",
            "Saving model (epoch =    8, loss = 4.4255)\n",
            "Saving model (epoch =    9, loss = 3.8009)\n",
            "Saving model (epoch =   10, loss = 3.3691)\n",
            "Saving model (epoch =   11, loss = 3.0943)\n",
            "Saving model (epoch =   12, loss = 2.8176)\n",
            "Saving model (epoch =   13, loss = 2.6274)\n",
            "Saving model (epoch =   14, loss = 2.4542)\n",
            "Saving model (epoch =   15, loss = 2.3012)\n",
            "Saving model (epoch =   16, loss = 2.1766)\n",
            "Saving model (epoch =   17, loss = 2.0641)\n",
            "Saving model (epoch =   18, loss = 1.9399)\n",
            "Saving model (epoch =   19, loss = 1.8978)\n",
            "Saving model (epoch =   20, loss = 1.7950)\n",
            "Saving model (epoch =   21, loss = 1.7164)\n",
            "Saving model (epoch =   22, loss = 1.6455)\n",
            "Saving model (epoch =   23, loss = 1.5912)\n",
            "Saving model (epoch =   24, loss = 1.5599)\n",
            "Saving model (epoch =   25, loss = 1.5197)\n",
            "Saving model (epoch =   26, loss = 1.4698)\n",
            "Saving model (epoch =   27, loss = 1.4189)\n",
            "Saving model (epoch =   28, loss = 1.3992)\n",
            "Saving model (epoch =   29, loss = 1.3696)\n",
            "Saving model (epoch =   30, loss = 1.3442)\n",
            "Saving model (epoch =   31, loss = 1.3231)\n",
            "Saving model (epoch =   32, loss = 1.2834)\n",
            "Saving model (epoch =   33, loss = 1.2804)\n",
            "Saving model (epoch =   34, loss = 1.2471)\n",
            "Saving model (epoch =   36, loss = 1.2414)\n",
            "Saving model (epoch =   37, loss = 1.2138)\n",
            "Saving model (epoch =   38, loss = 1.2083)\n",
            "Saving model (epoch =   41, loss = 1.1591)\n",
            "Saving model (epoch =   42, loss = 1.1484)\n",
            "Saving model (epoch =   44, loss = 1.1209)\n",
            "Saving model (epoch =   47, loss = 1.1122)\n",
            "Saving model (epoch =   48, loss = 1.0937)\n",
            "Saving model (epoch =   50, loss = 1.0842)\n",
            "Saving model (epoch =   53, loss = 1.0655)\n",
            "Saving model (epoch =   54, loss = 1.0613)\n",
            "Saving model (epoch =   57, loss = 1.0524)\n",
            "Saving model (epoch =   58, loss = 1.0394)\n",
            "Saving model (epoch =   60, loss = 1.0267)\n",
            "Saving model (epoch =   63, loss = 1.0248)\n",
            "Saving model (epoch =   66, loss = 1.0099)\n",
            "Saving model (epoch =   70, loss = 0.9829)\n",
            "Saving model (epoch =   72, loss = 0.9817)\n",
            "Saving model (epoch =   73, loss = 0.9743)\n",
            "Saving model (epoch =   75, loss = 0.9671)\n",
            "Saving model (epoch =   78, loss = 0.9643)\n",
            "Saving model (epoch =   79, loss = 0.9597)\n",
            "Saving model (epoch =   85, loss = 0.9549)\n",
            "Saving model (epoch =   86, loss = 0.9535)\n",
            "Saving model (epoch =   90, loss = 0.9467)\n",
            "Saving model (epoch =   92, loss = 0.9432)\n",
            "Saving model (epoch =   93, loss = 0.9231)\n",
            "Saving model (epoch =   95, loss = 0.9127)\n",
            "Saving model (epoch =  104, loss = 0.9117)\n",
            "Saving model (epoch =  107, loss = 0.8994)\n",
            "Saving model (epoch =  110, loss = 0.8935)\n",
            "Saving model (epoch =  116, loss = 0.8882)\n",
            "Saving model (epoch =  124, loss = 0.8872)\n",
            "Saving model (epoch =  128, loss = 0.8724)\n",
            "Saving model (epoch =  134, loss = 0.8722)\n",
            "Saving model (epoch =  139, loss = 0.8677)\n",
            "Saving model (epoch =  146, loss = 0.8654)\n",
            "Saving model (epoch =  156, loss = 0.8642)\n",
            "Saving model (epoch =  159, loss = 0.8528)\n",
            "Saving model (epoch =  167, loss = 0.8494)\n",
            "Saving model (epoch =  173, loss = 0.8492)\n",
            "Saving model (epoch =  176, loss = 0.8461)\n",
            "Saving model (epoch =  178, loss = 0.8403)\n",
            "Saving model (epoch =  182, loss = 0.8375)\n",
            "Saving model (epoch =  199, loss = 0.8295)\n",
            "Saving model (epoch =  212, loss = 0.8273)\n",
            "Saving model (epoch =  235, loss = 0.8252)\n",
            "Saving model (epoch =  238, loss = 0.8233)\n",
            "Saving model (epoch =  251, loss = 0.8211)\n",
            "Saving model (epoch =  253, loss = 0.8205)\n",
            "Saving model (epoch =  258, loss = 0.8175)\n",
            "Saving model (epoch =  284, loss = 0.8143)\n",
            "Saving model (epoch =  308, loss = 0.8136)\n",
            "Saving model (epoch =  312, loss = 0.8075)\n",
            "Saving model (epoch =  324, loss = 0.8045)\n",
            "Saving model (epoch =  400, loss = 0.8040)\n",
            "Saving model (epoch =  404, loss = 0.8010)\n",
            "Saving model (epoch =  466, loss = 0.7998)\n",
            "Saving model (epoch =  525, loss = 0.7993)\n",
            "Saving model (epoch =  561, loss = 0.7945)\n",
            "Saving model (epoch =  584, loss = 0.7903)\n",
            "Saving model (epoch =  667, loss = 0.7896)\n",
            "Saving model (epoch =  717, loss = 0.7823)\n",
            "Saving model (epoch =  776, loss = 0.7812)\n",
            "Saving model (epoch =  835, loss = 0.7797)\n",
            "Saving model (epoch =  866, loss = 0.7771)\n",
            "Saving model (epoch =  919, loss = 0.7770)\n",
            "Saving model (epoch =  933, loss = 0.7748)\n",
            "Saving model (epoch =  965, loss = 0.7705)\n",
            "Saving model (epoch = 1027, loss = 0.7674)\n",
            "Saving model (epoch = 1119, loss = 0.7647)\n",
            "Saving model (epoch = 1140, loss = 0.7643)\n",
            "Saving model (epoch = 1196, loss = 0.7620)\n",
            "Saving model (epoch = 1234, loss = 0.7616)\n",
            "Saving model (epoch = 1243, loss = 0.7582)\n",
            "Finished training after 1444 epochs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Section 6. Assess the neural network**"
      ],
      "metadata": {
        "id": "eKV4bpmV4Ab8"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "hsNO9nnXQBvP",
        "outputId": "e2afc294-cd16-49a8-df75-adc3f8df2245"
      },
      "source": [
        "plot_learning_curve(model_loss_record, title='deep model')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "3iZTVn5WQFpX",
        "outputId": "a3d164f3-e14f-4f79-a891-0640efd679d5"
      },
      "source": [
        "del model\n",
        "model = NeuralNet(tr_set.dataset.dim).to(device)\n",
        "ckpt = torch.load(config['save_path'], map_location='cpu')  # Load your best model\n",
        "model.load_state_dict(ckpt)\n",
        "plot_pred(dv_set, model, device)  # Show prediction on the validation set"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQikz3IPiyPf"
      },
      "source": [
        "**Testing**\n",
        "The predictions of your model on testing set will be stored at `pred.csv`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8cTuQjQQOon",
        "outputId": "9d8b9e08-654c-4f72-fc9b-24cbd4776556"
      },
      "source": [
        "def save_pred(preds, file):\n",
        "    ''' Save predictions to specified file '''\n",
        "    print('Saving results to {}'.format(file))\n",
        "    with open(file, 'w') as fp:\n",
        "        writer = csv.writer(fp)\n",
        "        writer.writerow(['id', 'tested_positive'])\n",
        "        for i, p in enumerate(preds):\n",
        "            writer.writerow([i, p])\n",
        "\n",
        "preds = test(tt_set, model, device)  # predict COVID-19 cases with your model\n",
        "save_pred(preds, 'pred.csv')         # save prediction file to pred.csv"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving results to pred.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Section 7. Experiment feature selection and hyper-parameter tuning**"
      ],
      "metadata": {
        "id": "1Djtu0AR4Uyr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Section 8. Apply L2 regularization**"
      ],
      "metadata": {
        "id": "eN0PD49j4eFz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rzSTbjZ94S0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Section 9. Checklist**\n",
        "Here is a checklist of the requirements to meet in the original assignment:\n",
        "- Run sample code\n",
        "- Train the neural network with 42 features (40 features corresponding to the states and any 2 user-selected) and justify the 2 selected features.\n",
        "- Explore the DNN architecture by playing around the number of layers/dimensions or different kinds activation functions.\n",
        "- Apply L2 regularization to the model.\n",
        "- Fix Mistakes in the sample codes, if any."
      ],
      "metadata": {
        "id": "VbdxW2jf13aV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RYSSRXel4jjc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}