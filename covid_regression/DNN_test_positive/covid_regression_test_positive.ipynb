{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wehs7661/deep_learning_projects/blob/master/covid_regression/DNN_test_positive/covid_regression_test_positive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz0_QVkxCrX3"
      },
      "source": [
        "# **A deep neural network for predicting the COVID-19 positive rate**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuvRS9yxA1y8"
      },
      "source": [
        "This notebbook is adapted from the homework notebook ([Homework 1](https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.ipynb), written by Heng-Jui Chang @ NTUEE) of the 2021 Machine Learning class taught by Dr. Hung-Yi Lee @ NTUEE. The explanation about the assignment can be found in the following links:\n",
        "- Slides: https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.pdf  \n",
        "- Videos (Mandarin): https://cool.ntu.edu.tw/courses/4793/modules/items/172854  \n",
        "https://cool.ntu.edu.tw/courses/4793/modules/items/172853  \n",
        "- Video (English): https://cool.ntu.edu.tw/courses/4793/modules/items/176529"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IL05r5ZBcPIy"
      },
      "source": [
        "The overall goal of this notebook is to guide you through the process of building, training, and assessing a neural network for solving a regression problem - predicting the COVID-19 positive rate, and provide hands-on experience in improving the model. In the original assignment, the predictions made by the model were required to be uploaded to [Kaggle](https://www.kaggle.com/competitions/ml2021spring-hw1). In addition to the assignment submission, which grants 4 points, each of the remaining 6 points can be gained by passing the baselines tabulated. Notably, a lower score corresponds to a lower test loss, which is better. \n",
        "\n",
        "|                 | Public leaderboard | Private leaderboard |\n",
        "|-----------------|--------------------|---------------------|\n",
        "| Simple baseline | 2.03004            | 2.04826             |\n",
        "| Medium baseline | 1.28359            | 1.36937             |\n",
        "| Strong baseline | 0.88017            | 0.89266             |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cE3Io68B3xh"
      },
      "source": [
        "In the instructions of the original assignment, the following tips were given to pass different baselines:\n",
        "- To pass the simple baseline, one can just run the sample codes provided in Sections 1 to 5.\n",
        "- To pass the medium baseline, one needs to perform feature selections, specifically only using the one-hot vector of states (40 features) and the positive rates of Days 1 and 2 as the features (i.e. 42 features in total) instead of using all the 93 possible features. \n",
        "- To pass the strong baseline, one needs to apply L1 or L2 regularization to the model. \n",
        "\n",
        "Also, playing around with the hyper-parameters or modifying the architecture of the model could help improve the performance. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J19vGSxNCfrK"
      },
      "source": [
        "In this notebook, we will finish all the tasks mentioned above to pass as many baselines as possible. Now let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ut4h8iaaDKjY"
      },
      "source": [
        "## **Section 1. Understand our datasets**\n",
        "Here, we first first download the training set and the test set, which were extracted and adapted from the [daily surveys conducted by the Delphi Group @ CMU](https://delphi.cmu.edu/covidcast/). If the Google drive links are dead, you can download the data from [Kaggle](https://www.kaggle.com/c/ml2021spring-hw1/data).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMj55YDKG6ch",
        "outputId": "75bdb724-9d68-4116-d6cb-72ae2f56139a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19CCyCgJrUxtvgZF53vnctJiOJ23T5mqF\n",
            "To: /content/covid.train.csv\n",
            "100% 2.00M/2.00M [00:00<00:00, 226MB/s]\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CE240jLm2npU-tdz81-oVKEF3T2yfT1O\n",
            "To: /content/covid.test.csv\n",
            "100% 651k/651k [00:00<00:00, 95.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "tr_path = 'covid.train.csv'  # path to training data\n",
        "tt_path = 'covid.test.csv'   # path to testing data\n",
        "\n",
        "!gdown --id '19CCyCgJrUxtvgZF53vnctJiOJ23T5mqF' --output covid.train.csv\n",
        "!gdown --id '1CE240jLm2npU-tdz81-oVKEF3T2yfT1O' --output covid.test.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "XqyYQquILV6r",
        "outputId": "c084f16b-030c-4cb2-f6d1-5125f5078491"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id   AL   AK   AZ   AR   CA   CO   CT   FL   GA   ID   IL   IN   IA  \\\n",
              "0        0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "1        1  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "2        2  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "3        3  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "4        4  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
              "2695  2695  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "2696  2696  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "2697  2697  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "2698  2698  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "2699  2699  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "\n",
              "       KS   KY   LA   MD   MA   MI   MN   MS   MO   NE   NV   NJ   NM   NY  \\\n",
              "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
              "2695  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "2696  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "2697  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "2698  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "2699  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "\n",
              "       NC   OH   OK   OR   PA   RI   SC   TX   UT   VA   WA   WV   WI  \\\n",
              "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
              "2695  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
              "2696  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
              "2697  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
              "2698  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
              "2699  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
              "\n",
              "           cli       ili  hh_cmnty_cli  nohh_cmnty_cli  wearing_mask  \\\n",
              "0     0.814610  0.771356     25.648907       21.242063     84.644672   \n",
              "1     0.838995  0.807767     25.679101       21.280270     84.005294   \n",
              "2     0.897802  0.887893     26.060544       21.503832     84.438618   \n",
              "3     0.972842  0.965496     25.754087       21.016210     84.133873   \n",
              "4     0.955306  0.963079     25.947015       20.941798     83.995931   \n",
              "...        ...       ...           ...             ...           ...   \n",
              "2695  0.655823  0.659976     25.265366       20.468897     91.011756   \n",
              "2696  0.598352  0.602552     25.299465       20.756444     90.682057   \n",
              "2697  0.586713  0.597559     25.271178       20.770195     90.866100   \n",
              "2698  0.576435  0.595312     24.607461       20.176201     90.846126   \n",
              "2699  0.562426  0.572969     24.020275       19.654514     90.928655   \n",
              "\n",
              "      travel_outside_state  work_outside_home       shop  restaurant  \\\n",
              "0                13.462475          36.519841  63.139094   23.835119   \n",
              "1                13.467716          36.637887  63.318650   23.688882   \n",
              "2                13.038611          36.429119  62.434539   23.812411   \n",
              "3                12.581952          36.416557  62.024517   23.682974   \n",
              "4                12.938675          37.014578  62.116842   23.593983   \n",
              "...                    ...                ...        ...         ...   \n",
              "2695              6.801897          32.727184  50.265694   15.188547   \n",
              "2696              7.152368          33.638563  50.050349   15.462823   \n",
              "2697              6.857209          33.959012  50.024971   15.090116   \n",
              "2698              6.851475          33.932384  49.885129   14.779264   \n",
              "2699              6.642911          33.822577  50.056772   14.961085   \n",
              "\n",
              "      spent_time  large_event  public_transit    anxious  depressed  \\\n",
              "0      44.726055    16.946929        1.716262  15.494193  12.043275   \n",
              "1      44.385166    16.463551        1.664819  15.299228  12.051505   \n",
              "2      43.430423    16.151527        1.602635  15.409449  12.088688   \n",
              "3      43.196313    16.123386        1.641863  15.230063  11.809047   \n",
              "4      43.362200    16.159971        1.677523  15.717207  12.355918   \n",
              "...          ...          ...             ...        ...        ...   \n",
              "2695   31.597793     8.013637        1.768811  14.699027  11.227049   \n",
              "2696   31.656358     8.239559        1.789015  14.808636  11.371546   \n",
              "2697   30.839219     7.849525        1.760094  14.617563  11.163213   \n",
              "2698   30.617100     7.754800        1.780730  14.513419  11.281241   \n",
              "2699   30.595194     7.744075        1.921828  14.160990  11.163526   \n",
              "\n",
              "      felt_isolated  worried_become_ill  worried_finances  tested_positive  \\\n",
              "0         17.000647           53.439316         43.279629        19.586492   \n",
              "1         16.552264           53.256795         43.622728        20.151838   \n",
              "2         16.702086           53.991549         43.604229        20.704935   \n",
              "3         16.506973           54.185521         42.665766        21.292911   \n",
              "4         16.273294           53.637069         42.972417        21.166656   \n",
              "...             ...                 ...               ...              ...   \n",
              "2695      18.814486           68.115748         38.478143        13.869286   \n",
              "2696      19.257324           67.691795         38.953184        13.434180   \n",
              "2697      18.742673           68.024690         38.920206        13.008853   \n",
              "2698      18.539741           67.855755         39.224244        12.725638   \n",
              "2699      18.702564           67.731162         38.740651        12.613441   \n",
              "\n",
              "         cli.1     ili.1  hh_cmnty_cli.1  nohh_cmnty_cli.1  wearing_mask.1  \\\n",
              "0     0.838995  0.807767       25.679101         21.280270       84.005294   \n",
              "1     0.897802  0.887893       26.060544         21.503832       84.438618   \n",
              "2     0.972842  0.965496       25.754087         21.016210       84.133873   \n",
              "3     0.955306  0.963079       25.947015         20.941798       83.995931   \n",
              "4     0.947513  0.968764       26.350501         21.109971       83.819531   \n",
              "...        ...       ...             ...               ...             ...   \n",
              "2695  0.598352  0.602552       25.299465         20.756444       90.682057   \n",
              "2696  0.586713  0.597559       25.271178         20.770195       90.866100   \n",
              "2697  0.576435  0.595312       24.607461         20.176201       90.846126   \n",
              "2698  0.562426  0.572969       24.020275         19.654514       90.928655   \n",
              "2699  0.600671  0.611160       23.797738         19.519105       90.957424   \n",
              "\n",
              "      travel_outside_state.1  work_outside_home.1     shop.1  restaurant.1  \\\n",
              "0                  13.467716            36.637887  63.318650     23.688882   \n",
              "1                  13.038611            36.429119  62.434539     23.812411   \n",
              "2                  12.581952            36.416557  62.024517     23.682974   \n",
              "3                  12.938675            37.014578  62.116842     23.593983   \n",
              "4                  12.452336            36.270021  61.294809     22.576992   \n",
              "...                      ...                  ...        ...           ...   \n",
              "2695                7.152368            33.638563  50.050349     15.462823   \n",
              "2696                6.857209            33.959012  50.024971     15.090116   \n",
              "2697                6.851475            33.932384  49.885129     14.779264   \n",
              "2698                6.642911            33.822577  50.056772     14.961085   \n",
              "2699                6.800289            33.196095  49.620924     14.609582   \n",
              "\n",
              "      spent_time.1  large_event.1  public_transit.1  anxious.1  depressed.1  \\\n",
              "0        44.385166      16.463551          1.664819  15.299228    12.051505   \n",
              "1        43.430423      16.151527          1.602635  15.409449    12.088688   \n",
              "2        43.196313      16.123386          1.641863  15.230063    11.809047   \n",
              "3        43.362200      16.159971          1.677523  15.717207    12.355918   \n",
              "4        42.954574      15.544373          1.578030  15.295650    12.218123   \n",
              "...            ...            ...               ...        ...          ...   \n",
              "2695     31.656358       8.239559          1.789015  14.808636    11.371546   \n",
              "2696     30.839219       7.849525          1.760094  14.617563    11.163213   \n",
              "2697     30.617100       7.754800          1.780730  14.513419    11.281241   \n",
              "2698     30.595194       7.744075          1.921828  14.160990    11.163526   \n",
              "2699     30.420998       7.687974          1.992580  14.409427    11.330301   \n",
              "\n",
              "      felt_isolated.1  worried_become_ill.1  worried_finances.1  \\\n",
              "0           16.552264             53.256795           43.622728   \n",
              "1           16.702086             53.991549           43.604229   \n",
              "2           16.506973             54.185521           42.665766   \n",
              "3           16.273294             53.637069           42.972417   \n",
              "4           16.045504             52.446223           42.907472   \n",
              "...               ...                   ...                 ...   \n",
              "2695        19.257324             67.691795           38.953184   \n",
              "2696        18.742673             68.024690           38.920206   \n",
              "2697        18.539741             67.855755           39.224244   \n",
              "2698        18.702564             67.731162           38.740651   \n",
              "2699        19.134697             67.795100           38.595125   \n",
              "\n",
              "      tested_positive.1     cli.2     ili.2  hh_cmnty_cli.2  nohh_cmnty_cli.2  \\\n",
              "0             20.151838  0.897802  0.887893       26.060544         21.503832   \n",
              "1             20.704935  0.972842  0.965496       25.754087         21.016210   \n",
              "2             21.292911  0.955306  0.963079       25.947015         20.941798   \n",
              "3             21.166656  0.947513  0.968764       26.350501         21.109971   \n",
              "4             19.896607  0.883833  0.893020       26.480624         21.003982   \n",
              "...                 ...       ...       ...             ...               ...   \n",
              "2695          13.434180  0.586713  0.597559       25.271178         20.770195   \n",
              "2696          13.008853  0.576435  0.595312       24.607461         20.176201   \n",
              "2697          12.725638  0.562426  0.572969       24.020275         19.654514   \n",
              "2698          12.613441  0.600671  0.611160       23.797738         19.519105   \n",
              "2699          12.477227  0.560519  0.571126       23.467835         19.174193   \n",
              "\n",
              "      wearing_mask.2  travel_outside_state.2  work_outside_home.2     shop.2  \\\n",
              "0          84.438618               13.038611            36.429119  62.434539   \n",
              "1          84.133873               12.581952            36.416557  62.024517   \n",
              "2          83.995931               12.938675            37.014578  62.116842   \n",
              "3          83.819531               12.452336            36.270021  61.294809   \n",
              "4          84.049437               12.224644            35.380198  60.664482   \n",
              "...              ...                     ...                  ...        ...   \n",
              "2695       90.866100                6.857209            33.959012  50.024971   \n",
              "2696       90.846126                6.851475            33.932384  49.885129   \n",
              "2697       90.928655                6.642911            33.822577  50.056772   \n",
              "2698       90.957424                6.800289            33.196095  49.620924   \n",
              "2699       91.110463                6.931543            33.096657  49.510599   \n",
              "\n",
              "      restaurant.2  spent_time.2  large_event.2  public_transit.2  anxious.2  \\\n",
              "0        23.812411     43.430423      16.151527          1.602635  15.409449   \n",
              "1        23.682974     43.196313      16.123386          1.641863  15.230063   \n",
              "2        23.593983     43.362200      16.159971          1.677523  15.717207   \n",
              "3        22.576992     42.954574      15.544373          1.578030  15.295650   \n",
              "4        22.091433     43.290957      15.214655          1.641667  14.778802   \n",
              "...            ...           ...            ...               ...        ...   \n",
              "2695     15.090116     30.839219       7.849525          1.760094  14.617563   \n",
              "2696     14.779264     30.617100       7.754800          1.780730  14.513419   \n",
              "2697     14.961085     30.595194       7.744075          1.921828  14.160990   \n",
              "2698     14.609582     30.420998       7.687974          1.992580  14.409427   \n",
              "2699     14.464053     30.469791       7.692942          1.966064  14.616400   \n",
              "\n",
              "      depressed.2  felt_isolated.2  worried_become_ill.2  worried_finances.2  \\\n",
              "0       12.088688        16.702086             53.991549           43.604229   \n",
              "1       11.809047        16.506973             54.185521           42.665766   \n",
              "2       12.355918        16.273294             53.637069           42.972417   \n",
              "3       12.218123        16.045504             52.446223           42.907472   \n",
              "4       12.417256        16.134238             52.560315           43.321985   \n",
              "...           ...              ...                   ...                 ...   \n",
              "2695    11.163213        18.742673             68.024690           38.920206   \n",
              "2696    11.281241        18.539741             67.855755           39.224244   \n",
              "2697    11.163526        18.702564             67.731162           38.740651   \n",
              "2698    11.330301        19.134697             67.795100           38.595125   \n",
              "2699    11.522773        19.295834             68.284078           38.453820   \n",
              "\n",
              "      tested_positive.2  \n",
              "0             20.704935  \n",
              "1             21.292911  \n",
              "2             21.166656  \n",
              "3             19.896607  \n",
              "4             20.178428  \n",
              "...                 ...  \n",
              "2695          13.008853  \n",
              "2696          12.725638  \n",
              "2697          12.613441  \n",
              "2698          12.477227  \n",
              "2699          11.811719  \n",
              "\n",
              "[2700 rows x 95 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5b44f849-3cea-4640-9cd8-f1fe4d7ec396\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>AL</th>\n",
              "      <th>AK</th>\n",
              "      <th>AZ</th>\n",
              "      <th>AR</th>\n",
              "      <th>CA</th>\n",
              "      <th>CO</th>\n",
              "      <th>CT</th>\n",
              "      <th>FL</th>\n",
              "      <th>GA</th>\n",
              "      <th>ID</th>\n",
              "      <th>IL</th>\n",
              "      <th>IN</th>\n",
              "      <th>IA</th>\n",
              "      <th>KS</th>\n",
              "      <th>KY</th>\n",
              "      <th>LA</th>\n",
              "      <th>MD</th>\n",
              "      <th>MA</th>\n",
              "      <th>MI</th>\n",
              "      <th>MN</th>\n",
              "      <th>MS</th>\n",
              "      <th>MO</th>\n",
              "      <th>NE</th>\n",
              "      <th>NV</th>\n",
              "      <th>NJ</th>\n",
              "      <th>NM</th>\n",
              "      <th>NY</th>\n",
              "      <th>NC</th>\n",
              "      <th>OH</th>\n",
              "      <th>OK</th>\n",
              "      <th>OR</th>\n",
              "      <th>PA</th>\n",
              "      <th>RI</th>\n",
              "      <th>SC</th>\n",
              "      <th>TX</th>\n",
              "      <th>UT</th>\n",
              "      <th>VA</th>\n",
              "      <th>WA</th>\n",
              "      <th>WV</th>\n",
              "      <th>WI</th>\n",
              "      <th>cli</th>\n",
              "      <th>ili</th>\n",
              "      <th>hh_cmnty_cli</th>\n",
              "      <th>nohh_cmnty_cli</th>\n",
              "      <th>wearing_mask</th>\n",
              "      <th>travel_outside_state</th>\n",
              "      <th>work_outside_home</th>\n",
              "      <th>shop</th>\n",
              "      <th>restaurant</th>\n",
              "      <th>spent_time</th>\n",
              "      <th>large_event</th>\n",
              "      <th>public_transit</th>\n",
              "      <th>anxious</th>\n",
              "      <th>depressed</th>\n",
              "      <th>felt_isolated</th>\n",
              "      <th>worried_become_ill</th>\n",
              "      <th>worried_finances</th>\n",
              "      <th>tested_positive</th>\n",
              "      <th>cli.1</th>\n",
              "      <th>ili.1</th>\n",
              "      <th>hh_cmnty_cli.1</th>\n",
              "      <th>nohh_cmnty_cli.1</th>\n",
              "      <th>wearing_mask.1</th>\n",
              "      <th>travel_outside_state.1</th>\n",
              "      <th>work_outside_home.1</th>\n",
              "      <th>shop.1</th>\n",
              "      <th>restaurant.1</th>\n",
              "      <th>spent_time.1</th>\n",
              "      <th>large_event.1</th>\n",
              "      <th>public_transit.1</th>\n",
              "      <th>anxious.1</th>\n",
              "      <th>depressed.1</th>\n",
              "      <th>felt_isolated.1</th>\n",
              "      <th>worried_become_ill.1</th>\n",
              "      <th>worried_finances.1</th>\n",
              "      <th>tested_positive.1</th>\n",
              "      <th>cli.2</th>\n",
              "      <th>ili.2</th>\n",
              "      <th>hh_cmnty_cli.2</th>\n",
              "      <th>nohh_cmnty_cli.2</th>\n",
              "      <th>wearing_mask.2</th>\n",
              "      <th>travel_outside_state.2</th>\n",
              "      <th>work_outside_home.2</th>\n",
              "      <th>shop.2</th>\n",
              "      <th>restaurant.2</th>\n",
              "      <th>spent_time.2</th>\n",
              "      <th>large_event.2</th>\n",
              "      <th>public_transit.2</th>\n",
              "      <th>anxious.2</th>\n",
              "      <th>depressed.2</th>\n",
              "      <th>felt_isolated.2</th>\n",
              "      <th>worried_become_ill.2</th>\n",
              "      <th>worried_finances.2</th>\n",
              "      <th>tested_positive.2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.814610</td>\n",
              "      <td>0.771356</td>\n",
              "      <td>25.648907</td>\n",
              "      <td>21.242063</td>\n",
              "      <td>84.644672</td>\n",
              "      <td>13.462475</td>\n",
              "      <td>36.519841</td>\n",
              "      <td>63.139094</td>\n",
              "      <td>23.835119</td>\n",
              "      <td>44.726055</td>\n",
              "      <td>16.946929</td>\n",
              "      <td>1.716262</td>\n",
              "      <td>15.494193</td>\n",
              "      <td>12.043275</td>\n",
              "      <td>17.000647</td>\n",
              "      <td>53.439316</td>\n",
              "      <td>43.279629</td>\n",
              "      <td>19.586492</td>\n",
              "      <td>0.838995</td>\n",
              "      <td>0.807767</td>\n",
              "      <td>25.679101</td>\n",
              "      <td>21.280270</td>\n",
              "      <td>84.005294</td>\n",
              "      <td>13.467716</td>\n",
              "      <td>36.637887</td>\n",
              "      <td>63.318650</td>\n",
              "      <td>23.688882</td>\n",
              "      <td>44.385166</td>\n",
              "      <td>16.463551</td>\n",
              "      <td>1.664819</td>\n",
              "      <td>15.299228</td>\n",
              "      <td>12.051505</td>\n",
              "      <td>16.552264</td>\n",
              "      <td>53.256795</td>\n",
              "      <td>43.622728</td>\n",
              "      <td>20.151838</td>\n",
              "      <td>0.897802</td>\n",
              "      <td>0.887893</td>\n",
              "      <td>26.060544</td>\n",
              "      <td>21.503832</td>\n",
              "      <td>84.438618</td>\n",
              "      <td>13.038611</td>\n",
              "      <td>36.429119</td>\n",
              "      <td>62.434539</td>\n",
              "      <td>23.812411</td>\n",
              "      <td>43.430423</td>\n",
              "      <td>16.151527</td>\n",
              "      <td>1.602635</td>\n",
              "      <td>15.409449</td>\n",
              "      <td>12.088688</td>\n",
              "      <td>16.702086</td>\n",
              "      <td>53.991549</td>\n",
              "      <td>43.604229</td>\n",
              "      <td>20.704935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.838995</td>\n",
              "      <td>0.807767</td>\n",
              "      <td>25.679101</td>\n",
              "      <td>21.280270</td>\n",
              "      <td>84.005294</td>\n",
              "      <td>13.467716</td>\n",
              "      <td>36.637887</td>\n",
              "      <td>63.318650</td>\n",
              "      <td>23.688882</td>\n",
              "      <td>44.385166</td>\n",
              "      <td>16.463551</td>\n",
              "      <td>1.664819</td>\n",
              "      <td>15.299228</td>\n",
              "      <td>12.051505</td>\n",
              "      <td>16.552264</td>\n",
              "      <td>53.256795</td>\n",
              "      <td>43.622728</td>\n",
              "      <td>20.151838</td>\n",
              "      <td>0.897802</td>\n",
              "      <td>0.887893</td>\n",
              "      <td>26.060544</td>\n",
              "      <td>21.503832</td>\n",
              "      <td>84.438618</td>\n",
              "      <td>13.038611</td>\n",
              "      <td>36.429119</td>\n",
              "      <td>62.434539</td>\n",
              "      <td>23.812411</td>\n",
              "      <td>43.430423</td>\n",
              "      <td>16.151527</td>\n",
              "      <td>1.602635</td>\n",
              "      <td>15.409449</td>\n",
              "      <td>12.088688</td>\n",
              "      <td>16.702086</td>\n",
              "      <td>53.991549</td>\n",
              "      <td>43.604229</td>\n",
              "      <td>20.704935</td>\n",
              "      <td>0.972842</td>\n",
              "      <td>0.965496</td>\n",
              "      <td>25.754087</td>\n",
              "      <td>21.016210</td>\n",
              "      <td>84.133873</td>\n",
              "      <td>12.581952</td>\n",
              "      <td>36.416557</td>\n",
              "      <td>62.024517</td>\n",
              "      <td>23.682974</td>\n",
              "      <td>43.196313</td>\n",
              "      <td>16.123386</td>\n",
              "      <td>1.641863</td>\n",
              "      <td>15.230063</td>\n",
              "      <td>11.809047</td>\n",
              "      <td>16.506973</td>\n",
              "      <td>54.185521</td>\n",
              "      <td>42.665766</td>\n",
              "      <td>21.292911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.897802</td>\n",
              "      <td>0.887893</td>\n",
              "      <td>26.060544</td>\n",
              "      <td>21.503832</td>\n",
              "      <td>84.438618</td>\n",
              "      <td>13.038611</td>\n",
              "      <td>36.429119</td>\n",
              "      <td>62.434539</td>\n",
              "      <td>23.812411</td>\n",
              "      <td>43.430423</td>\n",
              "      <td>16.151527</td>\n",
              "      <td>1.602635</td>\n",
              "      <td>15.409449</td>\n",
              "      <td>12.088688</td>\n",
              "      <td>16.702086</td>\n",
              "      <td>53.991549</td>\n",
              "      <td>43.604229</td>\n",
              "      <td>20.704935</td>\n",
              "      <td>0.972842</td>\n",
              "      <td>0.965496</td>\n",
              "      <td>25.754087</td>\n",
              "      <td>21.016210</td>\n",
              "      <td>84.133873</td>\n",
              "      <td>12.581952</td>\n",
              "      <td>36.416557</td>\n",
              "      <td>62.024517</td>\n",
              "      <td>23.682974</td>\n",
              "      <td>43.196313</td>\n",
              "      <td>16.123386</td>\n",
              "      <td>1.641863</td>\n",
              "      <td>15.230063</td>\n",
              "      <td>11.809047</td>\n",
              "      <td>16.506973</td>\n",
              "      <td>54.185521</td>\n",
              "      <td>42.665766</td>\n",
              "      <td>21.292911</td>\n",
              "      <td>0.955306</td>\n",
              "      <td>0.963079</td>\n",
              "      <td>25.947015</td>\n",
              "      <td>20.941798</td>\n",
              "      <td>83.995931</td>\n",
              "      <td>12.938675</td>\n",
              "      <td>37.014578</td>\n",
              "      <td>62.116842</td>\n",
              "      <td>23.593983</td>\n",
              "      <td>43.362200</td>\n",
              "      <td>16.159971</td>\n",
              "      <td>1.677523</td>\n",
              "      <td>15.717207</td>\n",
              "      <td>12.355918</td>\n",
              "      <td>16.273294</td>\n",
              "      <td>53.637069</td>\n",
              "      <td>42.972417</td>\n",
              "      <td>21.166656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.972842</td>\n",
              "      <td>0.965496</td>\n",
              "      <td>25.754087</td>\n",
              "      <td>21.016210</td>\n",
              "      <td>84.133873</td>\n",
              "      <td>12.581952</td>\n",
              "      <td>36.416557</td>\n",
              "      <td>62.024517</td>\n",
              "      <td>23.682974</td>\n",
              "      <td>43.196313</td>\n",
              "      <td>16.123386</td>\n",
              "      <td>1.641863</td>\n",
              "      <td>15.230063</td>\n",
              "      <td>11.809047</td>\n",
              "      <td>16.506973</td>\n",
              "      <td>54.185521</td>\n",
              "      <td>42.665766</td>\n",
              "      <td>21.292911</td>\n",
              "      <td>0.955306</td>\n",
              "      <td>0.963079</td>\n",
              "      <td>25.947015</td>\n",
              "      <td>20.941798</td>\n",
              "      <td>83.995931</td>\n",
              "      <td>12.938675</td>\n",
              "      <td>37.014578</td>\n",
              "      <td>62.116842</td>\n",
              "      <td>23.593983</td>\n",
              "      <td>43.362200</td>\n",
              "      <td>16.159971</td>\n",
              "      <td>1.677523</td>\n",
              "      <td>15.717207</td>\n",
              "      <td>12.355918</td>\n",
              "      <td>16.273294</td>\n",
              "      <td>53.637069</td>\n",
              "      <td>42.972417</td>\n",
              "      <td>21.166656</td>\n",
              "      <td>0.947513</td>\n",
              "      <td>0.968764</td>\n",
              "      <td>26.350501</td>\n",
              "      <td>21.109971</td>\n",
              "      <td>83.819531</td>\n",
              "      <td>12.452336</td>\n",
              "      <td>36.270021</td>\n",
              "      <td>61.294809</td>\n",
              "      <td>22.576992</td>\n",
              "      <td>42.954574</td>\n",
              "      <td>15.544373</td>\n",
              "      <td>1.578030</td>\n",
              "      <td>15.295650</td>\n",
              "      <td>12.218123</td>\n",
              "      <td>16.045504</td>\n",
              "      <td>52.446223</td>\n",
              "      <td>42.907472</td>\n",
              "      <td>19.896607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.955306</td>\n",
              "      <td>0.963079</td>\n",
              "      <td>25.947015</td>\n",
              "      <td>20.941798</td>\n",
              "      <td>83.995931</td>\n",
              "      <td>12.938675</td>\n",
              "      <td>37.014578</td>\n",
              "      <td>62.116842</td>\n",
              "      <td>23.593983</td>\n",
              "      <td>43.362200</td>\n",
              "      <td>16.159971</td>\n",
              "      <td>1.677523</td>\n",
              "      <td>15.717207</td>\n",
              "      <td>12.355918</td>\n",
              "      <td>16.273294</td>\n",
              "      <td>53.637069</td>\n",
              "      <td>42.972417</td>\n",
              "      <td>21.166656</td>\n",
              "      <td>0.947513</td>\n",
              "      <td>0.968764</td>\n",
              "      <td>26.350501</td>\n",
              "      <td>21.109971</td>\n",
              "      <td>83.819531</td>\n",
              "      <td>12.452336</td>\n",
              "      <td>36.270021</td>\n",
              "      <td>61.294809</td>\n",
              "      <td>22.576992</td>\n",
              "      <td>42.954574</td>\n",
              "      <td>15.544373</td>\n",
              "      <td>1.578030</td>\n",
              "      <td>15.295650</td>\n",
              "      <td>12.218123</td>\n",
              "      <td>16.045504</td>\n",
              "      <td>52.446223</td>\n",
              "      <td>42.907472</td>\n",
              "      <td>19.896607</td>\n",
              "      <td>0.883833</td>\n",
              "      <td>0.893020</td>\n",
              "      <td>26.480624</td>\n",
              "      <td>21.003982</td>\n",
              "      <td>84.049437</td>\n",
              "      <td>12.224644</td>\n",
              "      <td>35.380198</td>\n",
              "      <td>60.664482</td>\n",
              "      <td>22.091433</td>\n",
              "      <td>43.290957</td>\n",
              "      <td>15.214655</td>\n",
              "      <td>1.641667</td>\n",
              "      <td>14.778802</td>\n",
              "      <td>12.417256</td>\n",
              "      <td>16.134238</td>\n",
              "      <td>52.560315</td>\n",
              "      <td>43.321985</td>\n",
              "      <td>20.178428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2695</th>\n",
              "      <td>2695</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.655823</td>\n",
              "      <td>0.659976</td>\n",
              "      <td>25.265366</td>\n",
              "      <td>20.468897</td>\n",
              "      <td>91.011756</td>\n",
              "      <td>6.801897</td>\n",
              "      <td>32.727184</td>\n",
              "      <td>50.265694</td>\n",
              "      <td>15.188547</td>\n",
              "      <td>31.597793</td>\n",
              "      <td>8.013637</td>\n",
              "      <td>1.768811</td>\n",
              "      <td>14.699027</td>\n",
              "      <td>11.227049</td>\n",
              "      <td>18.814486</td>\n",
              "      <td>68.115748</td>\n",
              "      <td>38.478143</td>\n",
              "      <td>13.869286</td>\n",
              "      <td>0.598352</td>\n",
              "      <td>0.602552</td>\n",
              "      <td>25.299465</td>\n",
              "      <td>20.756444</td>\n",
              "      <td>90.682057</td>\n",
              "      <td>7.152368</td>\n",
              "      <td>33.638563</td>\n",
              "      <td>50.050349</td>\n",
              "      <td>15.462823</td>\n",
              "      <td>31.656358</td>\n",
              "      <td>8.239559</td>\n",
              "      <td>1.789015</td>\n",
              "      <td>14.808636</td>\n",
              "      <td>11.371546</td>\n",
              "      <td>19.257324</td>\n",
              "      <td>67.691795</td>\n",
              "      <td>38.953184</td>\n",
              "      <td>13.434180</td>\n",
              "      <td>0.586713</td>\n",
              "      <td>0.597559</td>\n",
              "      <td>25.271178</td>\n",
              "      <td>20.770195</td>\n",
              "      <td>90.866100</td>\n",
              "      <td>6.857209</td>\n",
              "      <td>33.959012</td>\n",
              "      <td>50.024971</td>\n",
              "      <td>15.090116</td>\n",
              "      <td>30.839219</td>\n",
              "      <td>7.849525</td>\n",
              "      <td>1.760094</td>\n",
              "      <td>14.617563</td>\n",
              "      <td>11.163213</td>\n",
              "      <td>18.742673</td>\n",
              "      <td>68.024690</td>\n",
              "      <td>38.920206</td>\n",
              "      <td>13.008853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2696</th>\n",
              "      <td>2696</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.598352</td>\n",
              "      <td>0.602552</td>\n",
              "      <td>25.299465</td>\n",
              "      <td>20.756444</td>\n",
              "      <td>90.682057</td>\n",
              "      <td>7.152368</td>\n",
              "      <td>33.638563</td>\n",
              "      <td>50.050349</td>\n",
              "      <td>15.462823</td>\n",
              "      <td>31.656358</td>\n",
              "      <td>8.239559</td>\n",
              "      <td>1.789015</td>\n",
              "      <td>14.808636</td>\n",
              "      <td>11.371546</td>\n",
              "      <td>19.257324</td>\n",
              "      <td>67.691795</td>\n",
              "      <td>38.953184</td>\n",
              "      <td>13.434180</td>\n",
              "      <td>0.586713</td>\n",
              "      <td>0.597559</td>\n",
              "      <td>25.271178</td>\n",
              "      <td>20.770195</td>\n",
              "      <td>90.866100</td>\n",
              "      <td>6.857209</td>\n",
              "      <td>33.959012</td>\n",
              "      <td>50.024971</td>\n",
              "      <td>15.090116</td>\n",
              "      <td>30.839219</td>\n",
              "      <td>7.849525</td>\n",
              "      <td>1.760094</td>\n",
              "      <td>14.617563</td>\n",
              "      <td>11.163213</td>\n",
              "      <td>18.742673</td>\n",
              "      <td>68.024690</td>\n",
              "      <td>38.920206</td>\n",
              "      <td>13.008853</td>\n",
              "      <td>0.576435</td>\n",
              "      <td>0.595312</td>\n",
              "      <td>24.607461</td>\n",
              "      <td>20.176201</td>\n",
              "      <td>90.846126</td>\n",
              "      <td>6.851475</td>\n",
              "      <td>33.932384</td>\n",
              "      <td>49.885129</td>\n",
              "      <td>14.779264</td>\n",
              "      <td>30.617100</td>\n",
              "      <td>7.754800</td>\n",
              "      <td>1.780730</td>\n",
              "      <td>14.513419</td>\n",
              "      <td>11.281241</td>\n",
              "      <td>18.539741</td>\n",
              "      <td>67.855755</td>\n",
              "      <td>39.224244</td>\n",
              "      <td>12.725638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2697</th>\n",
              "      <td>2697</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.586713</td>\n",
              "      <td>0.597559</td>\n",
              "      <td>25.271178</td>\n",
              "      <td>20.770195</td>\n",
              "      <td>90.866100</td>\n",
              "      <td>6.857209</td>\n",
              "      <td>33.959012</td>\n",
              "      <td>50.024971</td>\n",
              "      <td>15.090116</td>\n",
              "      <td>30.839219</td>\n",
              "      <td>7.849525</td>\n",
              "      <td>1.760094</td>\n",
              "      <td>14.617563</td>\n",
              "      <td>11.163213</td>\n",
              "      <td>18.742673</td>\n",
              "      <td>68.024690</td>\n",
              "      <td>38.920206</td>\n",
              "      <td>13.008853</td>\n",
              "      <td>0.576435</td>\n",
              "      <td>0.595312</td>\n",
              "      <td>24.607461</td>\n",
              "      <td>20.176201</td>\n",
              "      <td>90.846126</td>\n",
              "      <td>6.851475</td>\n",
              "      <td>33.932384</td>\n",
              "      <td>49.885129</td>\n",
              "      <td>14.779264</td>\n",
              "      <td>30.617100</td>\n",
              "      <td>7.754800</td>\n",
              "      <td>1.780730</td>\n",
              "      <td>14.513419</td>\n",
              "      <td>11.281241</td>\n",
              "      <td>18.539741</td>\n",
              "      <td>67.855755</td>\n",
              "      <td>39.224244</td>\n",
              "      <td>12.725638</td>\n",
              "      <td>0.562426</td>\n",
              "      <td>0.572969</td>\n",
              "      <td>24.020275</td>\n",
              "      <td>19.654514</td>\n",
              "      <td>90.928655</td>\n",
              "      <td>6.642911</td>\n",
              "      <td>33.822577</td>\n",
              "      <td>50.056772</td>\n",
              "      <td>14.961085</td>\n",
              "      <td>30.595194</td>\n",
              "      <td>7.744075</td>\n",
              "      <td>1.921828</td>\n",
              "      <td>14.160990</td>\n",
              "      <td>11.163526</td>\n",
              "      <td>18.702564</td>\n",
              "      <td>67.731162</td>\n",
              "      <td>38.740651</td>\n",
              "      <td>12.613441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2698</th>\n",
              "      <td>2698</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.576435</td>\n",
              "      <td>0.595312</td>\n",
              "      <td>24.607461</td>\n",
              "      <td>20.176201</td>\n",
              "      <td>90.846126</td>\n",
              "      <td>6.851475</td>\n",
              "      <td>33.932384</td>\n",
              "      <td>49.885129</td>\n",
              "      <td>14.779264</td>\n",
              "      <td>30.617100</td>\n",
              "      <td>7.754800</td>\n",
              "      <td>1.780730</td>\n",
              "      <td>14.513419</td>\n",
              "      <td>11.281241</td>\n",
              "      <td>18.539741</td>\n",
              "      <td>67.855755</td>\n",
              "      <td>39.224244</td>\n",
              "      <td>12.725638</td>\n",
              "      <td>0.562426</td>\n",
              "      <td>0.572969</td>\n",
              "      <td>24.020275</td>\n",
              "      <td>19.654514</td>\n",
              "      <td>90.928655</td>\n",
              "      <td>6.642911</td>\n",
              "      <td>33.822577</td>\n",
              "      <td>50.056772</td>\n",
              "      <td>14.961085</td>\n",
              "      <td>30.595194</td>\n",
              "      <td>7.744075</td>\n",
              "      <td>1.921828</td>\n",
              "      <td>14.160990</td>\n",
              "      <td>11.163526</td>\n",
              "      <td>18.702564</td>\n",
              "      <td>67.731162</td>\n",
              "      <td>38.740651</td>\n",
              "      <td>12.613441</td>\n",
              "      <td>0.600671</td>\n",
              "      <td>0.611160</td>\n",
              "      <td>23.797738</td>\n",
              "      <td>19.519105</td>\n",
              "      <td>90.957424</td>\n",
              "      <td>6.800289</td>\n",
              "      <td>33.196095</td>\n",
              "      <td>49.620924</td>\n",
              "      <td>14.609582</td>\n",
              "      <td>30.420998</td>\n",
              "      <td>7.687974</td>\n",
              "      <td>1.992580</td>\n",
              "      <td>14.409427</td>\n",
              "      <td>11.330301</td>\n",
              "      <td>19.134697</td>\n",
              "      <td>67.795100</td>\n",
              "      <td>38.595125</td>\n",
              "      <td>12.477227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2699</th>\n",
              "      <td>2699</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.562426</td>\n",
              "      <td>0.572969</td>\n",
              "      <td>24.020275</td>\n",
              "      <td>19.654514</td>\n",
              "      <td>90.928655</td>\n",
              "      <td>6.642911</td>\n",
              "      <td>33.822577</td>\n",
              "      <td>50.056772</td>\n",
              "      <td>14.961085</td>\n",
              "      <td>30.595194</td>\n",
              "      <td>7.744075</td>\n",
              "      <td>1.921828</td>\n",
              "      <td>14.160990</td>\n",
              "      <td>11.163526</td>\n",
              "      <td>18.702564</td>\n",
              "      <td>67.731162</td>\n",
              "      <td>38.740651</td>\n",
              "      <td>12.613441</td>\n",
              "      <td>0.600671</td>\n",
              "      <td>0.611160</td>\n",
              "      <td>23.797738</td>\n",
              "      <td>19.519105</td>\n",
              "      <td>90.957424</td>\n",
              "      <td>6.800289</td>\n",
              "      <td>33.196095</td>\n",
              "      <td>49.620924</td>\n",
              "      <td>14.609582</td>\n",
              "      <td>30.420998</td>\n",
              "      <td>7.687974</td>\n",
              "      <td>1.992580</td>\n",
              "      <td>14.409427</td>\n",
              "      <td>11.330301</td>\n",
              "      <td>19.134697</td>\n",
              "      <td>67.795100</td>\n",
              "      <td>38.595125</td>\n",
              "      <td>12.477227</td>\n",
              "      <td>0.560519</td>\n",
              "      <td>0.571126</td>\n",
              "      <td>23.467835</td>\n",
              "      <td>19.174193</td>\n",
              "      <td>91.110463</td>\n",
              "      <td>6.931543</td>\n",
              "      <td>33.096657</td>\n",
              "      <td>49.510599</td>\n",
              "      <td>14.464053</td>\n",
              "      <td>30.469791</td>\n",
              "      <td>7.692942</td>\n",
              "      <td>1.966064</td>\n",
              "      <td>14.616400</td>\n",
              "      <td>11.522773</td>\n",
              "      <td>19.295834</td>\n",
              "      <td>68.284078</td>\n",
              "      <td>38.453820</td>\n",
              "      <td>11.811719</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2700 rows × 95 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b44f849-3cea-4640-9cd8-f1fe4d7ec396')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5b44f849-3cea-4640-9cd8-f1fe4d7ec396 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5b44f849-3cea-4640-9cd8-f1fe4d7ec396');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd \n",
        "pd.set_option('display.max_columns', None) # to show all coumns below\n",
        "df = pd.read_csv('covid.train.csv'); df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9t74gwFMc5A"
      },
      "source": [
        "As shown above, the training set has 95 columns, which include:\n",
        "- 1 column of the IDs\n",
        "- 40 columns showing the states encoded to one-hot vectors\n",
        "- 18 columns of Day 1 features\n",
        "- 18 columns of Day 2 features\n",
        "- 18 columns of Day 3 features\n",
        "\n",
        "More specifically, the 18 features for each day include the follows:\n",
        "- 4 columns of COVID-like illness, including\n",
        "  - `ili`: Percentage of people having influenza-like illness\n",
        "  - `cli`: Percentage of people having COVID-like illness\n",
        "  - `hh_cmnty_cli`: Percentage of people reporintg illness in their local community, including their household\n",
        "  - `noww_cmnty_cli`: Percentage of people reporting illness in their local community, not including their household \n",
        "- 8 columns of behavior indicators, including `wearing_mask`, `travel_outside_state`, `work_outside_home`, `shop`, `restaurant`, `spent_time`, `large_event`, and `public_transit`. Most names of indicators are self-explanatory, except for `spent_time`, which is the percentage of respondents who spent time indoors with someone who isn't currently staying with them in the past 24 hours. \n",
        "- 5 columns of mental health indicators, including `anxious`, `depressed`, `felt_isolated`, `worried_become_ill`, and `worried_finances`.\n",
        "- 1 column showing the percentage of people who tested positive\n",
        "\n",
        "All indicators above are expressed in percentages. For more details about how the data was collected and how the indicators were designed, please visit [this site](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/fb-survey.html).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ejKQ0SZv0LE"
      },
      "source": [
        "As can be examined, there are 2700 samples (2700 rows) in the training dataset and 893 samples in the test set. With these datasets, our goal is to build a deep neural network to **predict the COVID-19 positive rate of Day 3 (in percentage)**, first using any of the 93 indicators as features to pass the simple baseline. (Note that in the test set, there are only 94 columns, with the missing one being the test positive rate of Day 3 that we are going to predict. The test loss will be calculated on Kaggle once the predictions (the file `pred.csv` that we will generate below) is uploaded to Kaggle.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_nj1_l9OJ7d"
      },
      "source": [
        "## **Section 2. Setting things up**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS_4-77xHk44"
      },
      "source": [
        "First, we import packages to be used in our notebook and set the random seed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-onQd4JNA5H"
      },
      "outputs": [],
      "source": [
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# For data preprocess\n",
        "import numpy as np\n",
        "import csv\n",
        "import os\n",
        "\n",
        "# For plotting\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "def set_seed(seed=42069):\n",
        "    # set a random seed for reproducibility\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtE3b6JEH7rw"
      },
      "source": [
        "For convenience, here are some handy utility functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWMT3uf1NGQp"
      },
      "outputs": [],
      "source": [
        "def get_device():\n",
        "    ''' Get device (if GPU is available, use GPU) '''\n",
        "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def plot_learning_curve(loss_record, title=''):\n",
        "    ''' Plot learning curve of your DNN (train & dev loss) '''\n",
        "    total_steps = len(loss_record['train'])\n",
        "    x_1 = range(total_steps)\n",
        "    x_2 = x_1[::len(loss_record['train']) // len(loss_record['dev'])]\n",
        "    figure(figsize=(6, 4))\n",
        "    plt.plot(x_1, loss_record['train'], c='tab:red', label='Training loss')\n",
        "    plt.plot(x_2, loss_record['dev'], c='tab:cyan', label='Validation loss')\n",
        "    plt.ylim(0.0, 5.)\n",
        "    plt.xlabel('Training steps')\n",
        "    plt.ylabel('MSE loss')\n",
        "    plt.legend()\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_pred(dv_set, model, device, lim=35., preds=None, targets=None):\n",
        "    ''' Plot prediction of your DNN '''\n",
        "    if preds is None or targets is None:\n",
        "        model.eval()\n",
        "        preds, targets = [], []\n",
        "        for x, y in dv_set:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            with torch.no_grad():\n",
        "                pred = model(x)\n",
        "                preds.append(pred.detach().cpu())\n",
        "                targets.append(y.detach().cpu())\n",
        "        preds = torch.cat(preds, dim=0).numpy()\n",
        "        targets = torch.cat(targets, dim=0).numpy()\n",
        "\n",
        "    figure(figsize=(5, 5))\n",
        "    plt.scatter(targets, preds, c='r', alpha=0.5)\n",
        "    plt.plot([-0.2, lim], [-0.2, lim], c='b')\n",
        "    plt.xlim(-0.2, lim)\n",
        "    plt.ylim(-0.2, lim)\n",
        "    plt.xlabel('ground truth value')\n",
        "    plt.ylabel('predicted value')\n",
        "    plt.title('Ground Truth v.s. Prediction')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPXswSaIDq0n"
      },
      "source": [
        "# **Section 3. Preparing the datasets**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nts7djnpwjuT"
      },
      "source": [
        "Below we define the class `COVID19Dataset`, which is for prepare a training set, a validation set or a test set. Specifically, `COVID19Dataset` \n",
        "- Reads `.csv` files\n",
        "- Extracts features\n",
        "- Splits `covid.train.csv` into the training set and validation set when needed\n",
        "- Normalizes features\n",
        "\n",
        "In `COVID19Dataset`, 1 out of every 10 points in the training set is used for validation. Note that compared to the original sample code of `COVID19Dataset` written by Chang, the following changes have been made:\n",
        "- I changed the input arguments to the class to allow higher flexbility of considering arbitrary numbers of features. \n",
        "- The original code was considering features with indices from 0 to 92, which is incorrect since the ID/row index should not be a feature. I've fixed this error.\n",
        "- Some docstrings have been added."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "cstC9EBlM9Sl",
        "outputId": "1391fa2d-2a51-44c9-8b86-63316cdfbbf9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id   AL   AK   AZ   AR   CA   CO   CT   FL   GA   ID   IL   IN   IA  \\\n",
              "0      0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "1      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "2      2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "3      3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "4      4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
              "888  888  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "889  889  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "890  890  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
              "891  891  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "892  892  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "\n",
              "      KS   KY   LA   MD   MA   MI   MN   MS   MO   NE   NV   NJ   NM   NY  \\\n",
              "0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "1    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "2    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "3    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "4    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
              "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
              "888  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "889  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "890  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "891  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "892  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "\n",
              "      NC   OH   OK   OR   PA   RI   SC   TX   UT   VA   WA   WV   WI  \\\n",
              "0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "1    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "2    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "3    0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "4    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
              "888  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
              "889  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
              "890  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "891  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "892  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
              "\n",
              "          cli       ili  hh_cmnty_cli  nohh_cmnty_cli  wearing_mask  \\\n",
              "0    1.280114  1.344899     36.882651       31.764583     93.263323   \n",
              "1    0.415743  0.415544     13.228487        9.038025     88.343119   \n",
              "2    0.489393  0.470090     13.177653        8.603586     89.316674   \n",
              "3    0.543700  0.573356     21.136605       17.688285     94.837357   \n",
              "4    0.296148  0.303348     10.414241        7.094497     92.047812   \n",
              "..        ...       ...           ...             ...           ...   \n",
              "888  0.657657  0.694308     26.550817       22.455534     83.095060   \n",
              "889  0.344797  0.342201     14.772218       10.027827     90.597418   \n",
              "890  1.022277  1.027163     42.255184       36.760449     83.697191   \n",
              "891  1.138360  1.138360     31.508051       26.163547     82.742239   \n",
              "892  0.896582  0.914984     35.046441       30.863354     87.502295   \n",
              "\n",
              "     travel_outside_state  work_outside_home       shop  restaurant  \\\n",
              "0                3.830764          29.433394  51.804262    8.776250   \n",
              "1                6.717029          29.386125  58.949348   20.814688   \n",
              "2                7.091185          27.213329  57.970272   18.910505   \n",
              "3               19.251528          34.537950  56.576034   16.883810   \n",
              "4                7.027089          32.801215  60.779619   20.145119   \n",
              "..                    ...                ...        ...         ...   \n",
              "888              8.546346          38.004994  57.711869   22.076596   \n",
              "889              8.354050          28.608239  58.168652   17.253612   \n",
              "890              8.174556          32.782669  58.501525   16.647149   \n",
              "891             12.651000          35.838194  57.791325   21.361563   \n",
              "892              8.269981          35.402789  55.918937   17.298013   \n",
              "\n",
              "     spent_time  large_event  public_transit    anxious  depressed  \\\n",
              "0     30.053468     5.739902        2.735240  19.990416  13.382281   \n",
              "1     40.909173     8.961010        2.845331  23.156356  18.260055   \n",
              "2     38.658337     8.772926        2.580279  24.929777  19.377685   \n",
              "3     37.262986     6.101975        2.784397  23.146849  12.123319   \n",
              "4     42.919337    11.464731        8.278772  16.087025  11.915413   \n",
              "..          ...          ...             ...        ...        ...   \n",
              "888   44.926833    15.545649        2.320852  17.227400  12.878838   \n",
              "889   38.286082     7.767421        2.940479  19.805910  15.416250   \n",
              "890   36.593688    10.155822        1.696118  17.904787  13.310991   \n",
              "891   44.126493    18.313747        1.676570  15.899830  14.287941   \n",
              "892   39.206563    10.708303        1.825765  18.220734  13.682414   \n",
              "\n",
              "     felt_isolated  worried_become_ill  worried_finances  tested_positive  \\\n",
              "0        24.030140           66.747591         44.678740        22.055633   \n",
              "1        24.656120           56.102288         38.729149         2.331589   \n",
              "2        26.159011           54.357669         39.335294         1.658765   \n",
              "3        19.147417           63.884983         42.728412        11.600093   \n",
              "4        15.580278           61.303519         43.750004         2.458395   \n",
              "..             ...                 ...               ...              ...   \n",
              "888      17.797594           59.660193         36.521009        12.872323   \n",
              "889      23.002712           58.236162         38.162247         3.478945   \n",
              "890      21.558514           61.340855         42.406110        31.820007   \n",
              "891      16.703970           56.823625         44.393092        28.928613   \n",
              "892      21.043270           66.644469         37.992710        16.824692   \n",
              "\n",
              "        cli.1     ili.1  hh_cmnty_cli.1  nohh_cmnty_cli.1  wearing_mask.1  \\\n",
              "0    1.257046  1.302954       35.888346         30.847431       93.212831   \n",
              "1    0.417591  0.417591       12.997859          9.114625       88.742332   \n",
              "2    0.450383  0.430983       13.254896          8.767861       89.109790   \n",
              "3    0.566709  0.593109       21.746461         18.321759       95.006324   \n",
              "4    0.348166  0.355580       10.541130          7.231313       91.980572   \n",
              "..        ...       ...             ...               ...             ...   \n",
              "888  0.633411  0.674114       27.337431         23.296322       83.278498   \n",
              "889  0.349846  0.346603       14.660026          9.818391       90.516047   \n",
              "890  1.107801  1.121137       41.528939         35.971498       83.887065   \n",
              "891  0.987556  0.987556       30.484324         25.929046       81.900509   \n",
              "892  0.910928  0.934128       35.202240         31.124966       87.370270   \n",
              "\n",
              "     travel_outside_state.1  work_outside_home.1     shop.1  restaurant.1  \\\n",
              "0                  3.840129            29.313604  51.933738      8.666508   \n",
              "1                  7.038933            29.819088  59.109292     21.473941   \n",
              "2                  6.754043            27.881581  58.287380     19.698013   \n",
              "3                 18.583408            33.280678  56.382102     16.613888   \n",
              "4                  7.057509            33.054147  60.558146     19.861680   \n",
              "..                      ...                  ...        ...           ...   \n",
              "888                8.805332            37.921320  57.260442     21.903028   \n",
              "889                8.059390            28.544541  58.238041     16.932176   \n",
              "890                7.885300            32.334080  58.070265     16.277276   \n",
              "891               12.590875            35.564603  58.335873     21.350026   \n",
              "892                8.696100            35.657580  55.430604     17.104434   \n",
              "\n",
              "     spent_time.1  large_event.1  public_transit.1  anxious.1  depressed.1  \\\n",
              "0       29.870293       5.531424          2.634617  19.704998    13.532732   \n",
              "1       41.384746       9.226583          3.138238  22.481708    17.635395   \n",
              "2       39.292417       8.563846          2.846935  24.362498    18.798445   \n",
              "3       37.289014       5.854511          2.795397  21.910074    12.099771   \n",
              "4       42.750397      11.555570          8.274831  16.047472    11.953106   \n",
              "..            ...            ...               ...        ...          ...   \n",
              "888     44.383977      15.179923          2.189489  17.569079    12.804921   \n",
              "889     37.846577       7.423400          2.778458  20.229871    15.652835   \n",
              "890     36.239508      10.381392          1.789819  17.688978    13.206024   \n",
              "891     43.791898      18.851341          2.009474  15.936067    14.502422   \n",
              "892     38.402109      10.225396          1.838372  18.194805    13.588883   \n",
              "\n",
              "     felt_isolated.1  worried_become_ill.1  worried_finances.1  \\\n",
              "0          24.450491             65.790844           44.846171   \n",
              "1          23.832616             55.692361           38.756539   \n",
              "2          25.657059             55.069605           39.451691   \n",
              "3          18.539968             64.968616           42.654230   \n",
              "4          15.428406             61.249412           43.656077   \n",
              "..               ...                   ...                 ...   \n",
              "888        17.816574             60.267099           36.775876   \n",
              "889        23.324238             58.507239           38.146082   \n",
              "890        22.402706             61.580673           43.298702   \n",
              "891        17.101370             55.622923           43.538578   \n",
              "892        21.100235             66.532172           37.942374   \n",
              "\n",
              "     tested_positive.1     cli.2     ili.2  hh_cmnty_cli.2  nohh_cmnty_cli.2  \\\n",
              "0            21.029253  1.055138  1.102237       35.007218         30.230430   \n",
              "1             2.011478  0.413432  0.413432       13.408644          9.240964   \n",
              "2             2.163458  0.428718  0.440211       12.983094          8.577449   \n",
              "3            11.151200  0.570694  0.562588       22.029370         18.664454   \n",
              "4             2.525252  0.360287  0.366502       10.792680          7.341194   \n",
              "..                 ...       ...       ...             ...               ...   \n",
              "888          12.899764  0.701657  0.741869       28.137863         24.145959   \n",
              "889           3.830035  0.385528  0.382193       15.066202         10.165525   \n",
              "890          31.838902  1.293334  1.322585       40.313531         35.050732   \n",
              "891          26.335918  1.007022  1.007022       30.084547         25.458384   \n",
              "892          17.688710  0.921661  0.927959       35.909782         32.040772   \n",
              "\n",
              "     wearing_mask.2  travel_outside_state.2  work_outside_home.2     shop.2  \\\n",
              "0         93.261010                3.875565            29.249223  52.071090   \n",
              "1         89.177999                6.903325            30.309182  58.742461   \n",
              "2         88.323581                7.016447            28.660016  59.109045   \n",
              "3         95.475916               18.105202            33.479124  55.442267   \n",
              "4         92.285338                6.913195            33.042884  60.588783   \n",
              "..              ...                     ...                  ...        ...   \n",
              "888       83.103730                8.834929            37.898252  56.762931   \n",
              "889       91.151254                7.701297            28.497376  57.888461   \n",
              "890       82.736023                8.378240            31.172270  57.589848   \n",
              "891       81.096035               13.254508            35.885788  57.966384   \n",
              "892       87.586757                8.446671            35.514539  55.920650   \n",
              "\n",
              "     restaurant.2  spent_time.2  large_event.2  public_transit.2  anxious.2  \\\n",
              "0        8.624001     29.374792       5.391413          2.754804  19.695098   \n",
              "1       21.720187     41.375784       9.450179          3.150088  22.075715   \n",
              "2       20.123959     40.072556       8.781522          2.888209  23.920870   \n",
              "3       16.083529     36.977612       5.199286          2.575347  21.073800   \n",
              "4       19.503010     42.631236      11.549771          8.530551  15.896575   \n",
              "..            ...           ...            ...               ...        ...   \n",
              "888     21.494159     44.202567      14.996865          2.291745  17.740003   \n",
              "889     16.770893     37.373472       7.169675          2.631595  20.587449   \n",
              "890     16.761311     36.874822      11.046907          1.912310  16.800220   \n",
              "891     22.696669     45.350415      20.343487          2.385330  16.528265   \n",
              "892     17.002257     37.749348       9.955671          1.731796  18.555496   \n",
              "\n",
              "     depressed.2  felt_isolated.2  worried_become_ill.2  worried_finances.2  \n",
              "0      13.685645        24.747837             66.194950           44.873473  \n",
              "1      17.302077        23.559622             57.015009           38.372829  \n",
              "2      18.342506        24.993341             55.291498           38.907257  \n",
              "3      12.087171        18.608723             67.036197           43.142779  \n",
              "4      11.781634        15.065228             61.196518           43.574676  \n",
              "..           ...              ...                   ...                 ...  \n",
              "888    12.822676        18.123344             60.417531           37.156229  \n",
              "889    15.960166        23.710310             58.758735           38.673787  \n",
              "890    13.280423        22.423640             60.934851           43.122513  \n",
              "891    15.092539        17.476063             54.862386           44.016255  \n",
              "892    13.776335        21.217106             66.870763           37.930859  \n",
              "\n",
              "[893 rows x 94 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-327899b0-6166-4988-9aba-8c763544cae5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>AL</th>\n",
              "      <th>AK</th>\n",
              "      <th>AZ</th>\n",
              "      <th>AR</th>\n",
              "      <th>CA</th>\n",
              "      <th>CO</th>\n",
              "      <th>CT</th>\n",
              "      <th>FL</th>\n",
              "      <th>GA</th>\n",
              "      <th>ID</th>\n",
              "      <th>IL</th>\n",
              "      <th>IN</th>\n",
              "      <th>IA</th>\n",
              "      <th>KS</th>\n",
              "      <th>KY</th>\n",
              "      <th>LA</th>\n",
              "      <th>MD</th>\n",
              "      <th>MA</th>\n",
              "      <th>MI</th>\n",
              "      <th>MN</th>\n",
              "      <th>MS</th>\n",
              "      <th>MO</th>\n",
              "      <th>NE</th>\n",
              "      <th>NV</th>\n",
              "      <th>NJ</th>\n",
              "      <th>NM</th>\n",
              "      <th>NY</th>\n",
              "      <th>NC</th>\n",
              "      <th>OH</th>\n",
              "      <th>OK</th>\n",
              "      <th>OR</th>\n",
              "      <th>PA</th>\n",
              "      <th>RI</th>\n",
              "      <th>SC</th>\n",
              "      <th>TX</th>\n",
              "      <th>UT</th>\n",
              "      <th>VA</th>\n",
              "      <th>WA</th>\n",
              "      <th>WV</th>\n",
              "      <th>WI</th>\n",
              "      <th>cli</th>\n",
              "      <th>ili</th>\n",
              "      <th>hh_cmnty_cli</th>\n",
              "      <th>nohh_cmnty_cli</th>\n",
              "      <th>wearing_mask</th>\n",
              "      <th>travel_outside_state</th>\n",
              "      <th>work_outside_home</th>\n",
              "      <th>shop</th>\n",
              "      <th>restaurant</th>\n",
              "      <th>spent_time</th>\n",
              "      <th>large_event</th>\n",
              "      <th>public_transit</th>\n",
              "      <th>anxious</th>\n",
              "      <th>depressed</th>\n",
              "      <th>felt_isolated</th>\n",
              "      <th>worried_become_ill</th>\n",
              "      <th>worried_finances</th>\n",
              "      <th>tested_positive</th>\n",
              "      <th>cli.1</th>\n",
              "      <th>ili.1</th>\n",
              "      <th>hh_cmnty_cli.1</th>\n",
              "      <th>nohh_cmnty_cli.1</th>\n",
              "      <th>wearing_mask.1</th>\n",
              "      <th>travel_outside_state.1</th>\n",
              "      <th>work_outside_home.1</th>\n",
              "      <th>shop.1</th>\n",
              "      <th>restaurant.1</th>\n",
              "      <th>spent_time.1</th>\n",
              "      <th>large_event.1</th>\n",
              "      <th>public_transit.1</th>\n",
              "      <th>anxious.1</th>\n",
              "      <th>depressed.1</th>\n",
              "      <th>felt_isolated.1</th>\n",
              "      <th>worried_become_ill.1</th>\n",
              "      <th>worried_finances.1</th>\n",
              "      <th>tested_positive.1</th>\n",
              "      <th>cli.2</th>\n",
              "      <th>ili.2</th>\n",
              "      <th>hh_cmnty_cli.2</th>\n",
              "      <th>nohh_cmnty_cli.2</th>\n",
              "      <th>wearing_mask.2</th>\n",
              "      <th>travel_outside_state.2</th>\n",
              "      <th>work_outside_home.2</th>\n",
              "      <th>shop.2</th>\n",
              "      <th>restaurant.2</th>\n",
              "      <th>spent_time.2</th>\n",
              "      <th>large_event.2</th>\n",
              "      <th>public_transit.2</th>\n",
              "      <th>anxious.2</th>\n",
              "      <th>depressed.2</th>\n",
              "      <th>felt_isolated.2</th>\n",
              "      <th>worried_become_ill.2</th>\n",
              "      <th>worried_finances.2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.280114</td>\n",
              "      <td>1.344899</td>\n",
              "      <td>36.882651</td>\n",
              "      <td>31.764583</td>\n",
              "      <td>93.263323</td>\n",
              "      <td>3.830764</td>\n",
              "      <td>29.433394</td>\n",
              "      <td>51.804262</td>\n",
              "      <td>8.776250</td>\n",
              "      <td>30.053468</td>\n",
              "      <td>5.739902</td>\n",
              "      <td>2.735240</td>\n",
              "      <td>19.990416</td>\n",
              "      <td>13.382281</td>\n",
              "      <td>24.030140</td>\n",
              "      <td>66.747591</td>\n",
              "      <td>44.678740</td>\n",
              "      <td>22.055633</td>\n",
              "      <td>1.257046</td>\n",
              "      <td>1.302954</td>\n",
              "      <td>35.888346</td>\n",
              "      <td>30.847431</td>\n",
              "      <td>93.212831</td>\n",
              "      <td>3.840129</td>\n",
              "      <td>29.313604</td>\n",
              "      <td>51.933738</td>\n",
              "      <td>8.666508</td>\n",
              "      <td>29.870293</td>\n",
              "      <td>5.531424</td>\n",
              "      <td>2.634617</td>\n",
              "      <td>19.704998</td>\n",
              "      <td>13.532732</td>\n",
              "      <td>24.450491</td>\n",
              "      <td>65.790844</td>\n",
              "      <td>44.846171</td>\n",
              "      <td>21.029253</td>\n",
              "      <td>1.055138</td>\n",
              "      <td>1.102237</td>\n",
              "      <td>35.007218</td>\n",
              "      <td>30.230430</td>\n",
              "      <td>93.261010</td>\n",
              "      <td>3.875565</td>\n",
              "      <td>29.249223</td>\n",
              "      <td>52.071090</td>\n",
              "      <td>8.624001</td>\n",
              "      <td>29.374792</td>\n",
              "      <td>5.391413</td>\n",
              "      <td>2.754804</td>\n",
              "      <td>19.695098</td>\n",
              "      <td>13.685645</td>\n",
              "      <td>24.747837</td>\n",
              "      <td>66.194950</td>\n",
              "      <td>44.873473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.415743</td>\n",
              "      <td>0.415544</td>\n",
              "      <td>13.228487</td>\n",
              "      <td>9.038025</td>\n",
              "      <td>88.343119</td>\n",
              "      <td>6.717029</td>\n",
              "      <td>29.386125</td>\n",
              "      <td>58.949348</td>\n",
              "      <td>20.814688</td>\n",
              "      <td>40.909173</td>\n",
              "      <td>8.961010</td>\n",
              "      <td>2.845331</td>\n",
              "      <td>23.156356</td>\n",
              "      <td>18.260055</td>\n",
              "      <td>24.656120</td>\n",
              "      <td>56.102288</td>\n",
              "      <td>38.729149</td>\n",
              "      <td>2.331589</td>\n",
              "      <td>0.417591</td>\n",
              "      <td>0.417591</td>\n",
              "      <td>12.997859</td>\n",
              "      <td>9.114625</td>\n",
              "      <td>88.742332</td>\n",
              "      <td>7.038933</td>\n",
              "      <td>29.819088</td>\n",
              "      <td>59.109292</td>\n",
              "      <td>21.473941</td>\n",
              "      <td>41.384746</td>\n",
              "      <td>9.226583</td>\n",
              "      <td>3.138238</td>\n",
              "      <td>22.481708</td>\n",
              "      <td>17.635395</td>\n",
              "      <td>23.832616</td>\n",
              "      <td>55.692361</td>\n",
              "      <td>38.756539</td>\n",
              "      <td>2.011478</td>\n",
              "      <td>0.413432</td>\n",
              "      <td>0.413432</td>\n",
              "      <td>13.408644</td>\n",
              "      <td>9.240964</td>\n",
              "      <td>89.177999</td>\n",
              "      <td>6.903325</td>\n",
              "      <td>30.309182</td>\n",
              "      <td>58.742461</td>\n",
              "      <td>21.720187</td>\n",
              "      <td>41.375784</td>\n",
              "      <td>9.450179</td>\n",
              "      <td>3.150088</td>\n",
              "      <td>22.075715</td>\n",
              "      <td>17.302077</td>\n",
              "      <td>23.559622</td>\n",
              "      <td>57.015009</td>\n",
              "      <td>38.372829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.489393</td>\n",
              "      <td>0.470090</td>\n",
              "      <td>13.177653</td>\n",
              "      <td>8.603586</td>\n",
              "      <td>89.316674</td>\n",
              "      <td>7.091185</td>\n",
              "      <td>27.213329</td>\n",
              "      <td>57.970272</td>\n",
              "      <td>18.910505</td>\n",
              "      <td>38.658337</td>\n",
              "      <td>8.772926</td>\n",
              "      <td>2.580279</td>\n",
              "      <td>24.929777</td>\n",
              "      <td>19.377685</td>\n",
              "      <td>26.159011</td>\n",
              "      <td>54.357669</td>\n",
              "      <td>39.335294</td>\n",
              "      <td>1.658765</td>\n",
              "      <td>0.450383</td>\n",
              "      <td>0.430983</td>\n",
              "      <td>13.254896</td>\n",
              "      <td>8.767861</td>\n",
              "      <td>89.109790</td>\n",
              "      <td>6.754043</td>\n",
              "      <td>27.881581</td>\n",
              "      <td>58.287380</td>\n",
              "      <td>19.698013</td>\n",
              "      <td>39.292417</td>\n",
              "      <td>8.563846</td>\n",
              "      <td>2.846935</td>\n",
              "      <td>24.362498</td>\n",
              "      <td>18.798445</td>\n",
              "      <td>25.657059</td>\n",
              "      <td>55.069605</td>\n",
              "      <td>39.451691</td>\n",
              "      <td>2.163458</td>\n",
              "      <td>0.428718</td>\n",
              "      <td>0.440211</td>\n",
              "      <td>12.983094</td>\n",
              "      <td>8.577449</td>\n",
              "      <td>88.323581</td>\n",
              "      <td>7.016447</td>\n",
              "      <td>28.660016</td>\n",
              "      <td>59.109045</td>\n",
              "      <td>20.123959</td>\n",
              "      <td>40.072556</td>\n",
              "      <td>8.781522</td>\n",
              "      <td>2.888209</td>\n",
              "      <td>23.920870</td>\n",
              "      <td>18.342506</td>\n",
              "      <td>24.993341</td>\n",
              "      <td>55.291498</td>\n",
              "      <td>38.907257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.543700</td>\n",
              "      <td>0.573356</td>\n",
              "      <td>21.136605</td>\n",
              "      <td>17.688285</td>\n",
              "      <td>94.837357</td>\n",
              "      <td>19.251528</td>\n",
              "      <td>34.537950</td>\n",
              "      <td>56.576034</td>\n",
              "      <td>16.883810</td>\n",
              "      <td>37.262986</td>\n",
              "      <td>6.101975</td>\n",
              "      <td>2.784397</td>\n",
              "      <td>23.146849</td>\n",
              "      <td>12.123319</td>\n",
              "      <td>19.147417</td>\n",
              "      <td>63.884983</td>\n",
              "      <td>42.728412</td>\n",
              "      <td>11.600093</td>\n",
              "      <td>0.566709</td>\n",
              "      <td>0.593109</td>\n",
              "      <td>21.746461</td>\n",
              "      <td>18.321759</td>\n",
              "      <td>95.006324</td>\n",
              "      <td>18.583408</td>\n",
              "      <td>33.280678</td>\n",
              "      <td>56.382102</td>\n",
              "      <td>16.613888</td>\n",
              "      <td>37.289014</td>\n",
              "      <td>5.854511</td>\n",
              "      <td>2.795397</td>\n",
              "      <td>21.910074</td>\n",
              "      <td>12.099771</td>\n",
              "      <td>18.539968</td>\n",
              "      <td>64.968616</td>\n",
              "      <td>42.654230</td>\n",
              "      <td>11.151200</td>\n",
              "      <td>0.570694</td>\n",
              "      <td>0.562588</td>\n",
              "      <td>22.029370</td>\n",
              "      <td>18.664454</td>\n",
              "      <td>95.475916</td>\n",
              "      <td>18.105202</td>\n",
              "      <td>33.479124</td>\n",
              "      <td>55.442267</td>\n",
              "      <td>16.083529</td>\n",
              "      <td>36.977612</td>\n",
              "      <td>5.199286</td>\n",
              "      <td>2.575347</td>\n",
              "      <td>21.073800</td>\n",
              "      <td>12.087171</td>\n",
              "      <td>18.608723</td>\n",
              "      <td>67.036197</td>\n",
              "      <td>43.142779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.296148</td>\n",
              "      <td>0.303348</td>\n",
              "      <td>10.414241</td>\n",
              "      <td>7.094497</td>\n",
              "      <td>92.047812</td>\n",
              "      <td>7.027089</td>\n",
              "      <td>32.801215</td>\n",
              "      <td>60.779619</td>\n",
              "      <td>20.145119</td>\n",
              "      <td>42.919337</td>\n",
              "      <td>11.464731</td>\n",
              "      <td>8.278772</td>\n",
              "      <td>16.087025</td>\n",
              "      <td>11.915413</td>\n",
              "      <td>15.580278</td>\n",
              "      <td>61.303519</td>\n",
              "      <td>43.750004</td>\n",
              "      <td>2.458395</td>\n",
              "      <td>0.348166</td>\n",
              "      <td>0.355580</td>\n",
              "      <td>10.541130</td>\n",
              "      <td>7.231313</td>\n",
              "      <td>91.980572</td>\n",
              "      <td>7.057509</td>\n",
              "      <td>33.054147</td>\n",
              "      <td>60.558146</td>\n",
              "      <td>19.861680</td>\n",
              "      <td>42.750397</td>\n",
              "      <td>11.555570</td>\n",
              "      <td>8.274831</td>\n",
              "      <td>16.047472</td>\n",
              "      <td>11.953106</td>\n",
              "      <td>15.428406</td>\n",
              "      <td>61.249412</td>\n",
              "      <td>43.656077</td>\n",
              "      <td>2.525252</td>\n",
              "      <td>0.360287</td>\n",
              "      <td>0.366502</td>\n",
              "      <td>10.792680</td>\n",
              "      <td>7.341194</td>\n",
              "      <td>92.285338</td>\n",
              "      <td>6.913195</td>\n",
              "      <td>33.042884</td>\n",
              "      <td>60.588783</td>\n",
              "      <td>19.503010</td>\n",
              "      <td>42.631236</td>\n",
              "      <td>11.549771</td>\n",
              "      <td>8.530551</td>\n",
              "      <td>15.896575</td>\n",
              "      <td>11.781634</td>\n",
              "      <td>15.065228</td>\n",
              "      <td>61.196518</td>\n",
              "      <td>43.574676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>888</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.657657</td>\n",
              "      <td>0.694308</td>\n",
              "      <td>26.550817</td>\n",
              "      <td>22.455534</td>\n",
              "      <td>83.095060</td>\n",
              "      <td>8.546346</td>\n",
              "      <td>38.004994</td>\n",
              "      <td>57.711869</td>\n",
              "      <td>22.076596</td>\n",
              "      <td>44.926833</td>\n",
              "      <td>15.545649</td>\n",
              "      <td>2.320852</td>\n",
              "      <td>17.227400</td>\n",
              "      <td>12.878838</td>\n",
              "      <td>17.797594</td>\n",
              "      <td>59.660193</td>\n",
              "      <td>36.521009</td>\n",
              "      <td>12.872323</td>\n",
              "      <td>0.633411</td>\n",
              "      <td>0.674114</td>\n",
              "      <td>27.337431</td>\n",
              "      <td>23.296322</td>\n",
              "      <td>83.278498</td>\n",
              "      <td>8.805332</td>\n",
              "      <td>37.921320</td>\n",
              "      <td>57.260442</td>\n",
              "      <td>21.903028</td>\n",
              "      <td>44.383977</td>\n",
              "      <td>15.179923</td>\n",
              "      <td>2.189489</td>\n",
              "      <td>17.569079</td>\n",
              "      <td>12.804921</td>\n",
              "      <td>17.816574</td>\n",
              "      <td>60.267099</td>\n",
              "      <td>36.775876</td>\n",
              "      <td>12.899764</td>\n",
              "      <td>0.701657</td>\n",
              "      <td>0.741869</td>\n",
              "      <td>28.137863</td>\n",
              "      <td>24.145959</td>\n",
              "      <td>83.103730</td>\n",
              "      <td>8.834929</td>\n",
              "      <td>37.898252</td>\n",
              "      <td>56.762931</td>\n",
              "      <td>21.494159</td>\n",
              "      <td>44.202567</td>\n",
              "      <td>14.996865</td>\n",
              "      <td>2.291745</td>\n",
              "      <td>17.740003</td>\n",
              "      <td>12.822676</td>\n",
              "      <td>18.123344</td>\n",
              "      <td>60.417531</td>\n",
              "      <td>37.156229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>889</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.344797</td>\n",
              "      <td>0.342201</td>\n",
              "      <td>14.772218</td>\n",
              "      <td>10.027827</td>\n",
              "      <td>90.597418</td>\n",
              "      <td>8.354050</td>\n",
              "      <td>28.608239</td>\n",
              "      <td>58.168652</td>\n",
              "      <td>17.253612</td>\n",
              "      <td>38.286082</td>\n",
              "      <td>7.767421</td>\n",
              "      <td>2.940479</td>\n",
              "      <td>19.805910</td>\n",
              "      <td>15.416250</td>\n",
              "      <td>23.002712</td>\n",
              "      <td>58.236162</td>\n",
              "      <td>38.162247</td>\n",
              "      <td>3.478945</td>\n",
              "      <td>0.349846</td>\n",
              "      <td>0.346603</td>\n",
              "      <td>14.660026</td>\n",
              "      <td>9.818391</td>\n",
              "      <td>90.516047</td>\n",
              "      <td>8.059390</td>\n",
              "      <td>28.544541</td>\n",
              "      <td>58.238041</td>\n",
              "      <td>16.932176</td>\n",
              "      <td>37.846577</td>\n",
              "      <td>7.423400</td>\n",
              "      <td>2.778458</td>\n",
              "      <td>20.229871</td>\n",
              "      <td>15.652835</td>\n",
              "      <td>23.324238</td>\n",
              "      <td>58.507239</td>\n",
              "      <td>38.146082</td>\n",
              "      <td>3.830035</td>\n",
              "      <td>0.385528</td>\n",
              "      <td>0.382193</td>\n",
              "      <td>15.066202</td>\n",
              "      <td>10.165525</td>\n",
              "      <td>91.151254</td>\n",
              "      <td>7.701297</td>\n",
              "      <td>28.497376</td>\n",
              "      <td>57.888461</td>\n",
              "      <td>16.770893</td>\n",
              "      <td>37.373472</td>\n",
              "      <td>7.169675</td>\n",
              "      <td>2.631595</td>\n",
              "      <td>20.587449</td>\n",
              "      <td>15.960166</td>\n",
              "      <td>23.710310</td>\n",
              "      <td>58.758735</td>\n",
              "      <td>38.673787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>890</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.022277</td>\n",
              "      <td>1.027163</td>\n",
              "      <td>42.255184</td>\n",
              "      <td>36.760449</td>\n",
              "      <td>83.697191</td>\n",
              "      <td>8.174556</td>\n",
              "      <td>32.782669</td>\n",
              "      <td>58.501525</td>\n",
              "      <td>16.647149</td>\n",
              "      <td>36.593688</td>\n",
              "      <td>10.155822</td>\n",
              "      <td>1.696118</td>\n",
              "      <td>17.904787</td>\n",
              "      <td>13.310991</td>\n",
              "      <td>21.558514</td>\n",
              "      <td>61.340855</td>\n",
              "      <td>42.406110</td>\n",
              "      <td>31.820007</td>\n",
              "      <td>1.107801</td>\n",
              "      <td>1.121137</td>\n",
              "      <td>41.528939</td>\n",
              "      <td>35.971498</td>\n",
              "      <td>83.887065</td>\n",
              "      <td>7.885300</td>\n",
              "      <td>32.334080</td>\n",
              "      <td>58.070265</td>\n",
              "      <td>16.277276</td>\n",
              "      <td>36.239508</td>\n",
              "      <td>10.381392</td>\n",
              "      <td>1.789819</td>\n",
              "      <td>17.688978</td>\n",
              "      <td>13.206024</td>\n",
              "      <td>22.402706</td>\n",
              "      <td>61.580673</td>\n",
              "      <td>43.298702</td>\n",
              "      <td>31.838902</td>\n",
              "      <td>1.293334</td>\n",
              "      <td>1.322585</td>\n",
              "      <td>40.313531</td>\n",
              "      <td>35.050732</td>\n",
              "      <td>82.736023</td>\n",
              "      <td>8.378240</td>\n",
              "      <td>31.172270</td>\n",
              "      <td>57.589848</td>\n",
              "      <td>16.761311</td>\n",
              "      <td>36.874822</td>\n",
              "      <td>11.046907</td>\n",
              "      <td>1.912310</td>\n",
              "      <td>16.800220</td>\n",
              "      <td>13.280423</td>\n",
              "      <td>22.423640</td>\n",
              "      <td>60.934851</td>\n",
              "      <td>43.122513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>891</th>\n",
              "      <td>891</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.138360</td>\n",
              "      <td>1.138360</td>\n",
              "      <td>31.508051</td>\n",
              "      <td>26.163547</td>\n",
              "      <td>82.742239</td>\n",
              "      <td>12.651000</td>\n",
              "      <td>35.838194</td>\n",
              "      <td>57.791325</td>\n",
              "      <td>21.361563</td>\n",
              "      <td>44.126493</td>\n",
              "      <td>18.313747</td>\n",
              "      <td>1.676570</td>\n",
              "      <td>15.899830</td>\n",
              "      <td>14.287941</td>\n",
              "      <td>16.703970</td>\n",
              "      <td>56.823625</td>\n",
              "      <td>44.393092</td>\n",
              "      <td>28.928613</td>\n",
              "      <td>0.987556</td>\n",
              "      <td>0.987556</td>\n",
              "      <td>30.484324</td>\n",
              "      <td>25.929046</td>\n",
              "      <td>81.900509</td>\n",
              "      <td>12.590875</td>\n",
              "      <td>35.564603</td>\n",
              "      <td>58.335873</td>\n",
              "      <td>21.350026</td>\n",
              "      <td>43.791898</td>\n",
              "      <td>18.851341</td>\n",
              "      <td>2.009474</td>\n",
              "      <td>15.936067</td>\n",
              "      <td>14.502422</td>\n",
              "      <td>17.101370</td>\n",
              "      <td>55.622923</td>\n",
              "      <td>43.538578</td>\n",
              "      <td>26.335918</td>\n",
              "      <td>1.007022</td>\n",
              "      <td>1.007022</td>\n",
              "      <td>30.084547</td>\n",
              "      <td>25.458384</td>\n",
              "      <td>81.096035</td>\n",
              "      <td>13.254508</td>\n",
              "      <td>35.885788</td>\n",
              "      <td>57.966384</td>\n",
              "      <td>22.696669</td>\n",
              "      <td>45.350415</td>\n",
              "      <td>20.343487</td>\n",
              "      <td>2.385330</td>\n",
              "      <td>16.528265</td>\n",
              "      <td>15.092539</td>\n",
              "      <td>17.476063</td>\n",
              "      <td>54.862386</td>\n",
              "      <td>44.016255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>892</th>\n",
              "      <td>892</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.896582</td>\n",
              "      <td>0.914984</td>\n",
              "      <td>35.046441</td>\n",
              "      <td>30.863354</td>\n",
              "      <td>87.502295</td>\n",
              "      <td>8.269981</td>\n",
              "      <td>35.402789</td>\n",
              "      <td>55.918937</td>\n",
              "      <td>17.298013</td>\n",
              "      <td>39.206563</td>\n",
              "      <td>10.708303</td>\n",
              "      <td>1.825765</td>\n",
              "      <td>18.220734</td>\n",
              "      <td>13.682414</td>\n",
              "      <td>21.043270</td>\n",
              "      <td>66.644469</td>\n",
              "      <td>37.992710</td>\n",
              "      <td>16.824692</td>\n",
              "      <td>0.910928</td>\n",
              "      <td>0.934128</td>\n",
              "      <td>35.202240</td>\n",
              "      <td>31.124966</td>\n",
              "      <td>87.370270</td>\n",
              "      <td>8.696100</td>\n",
              "      <td>35.657580</td>\n",
              "      <td>55.430604</td>\n",
              "      <td>17.104434</td>\n",
              "      <td>38.402109</td>\n",
              "      <td>10.225396</td>\n",
              "      <td>1.838372</td>\n",
              "      <td>18.194805</td>\n",
              "      <td>13.588883</td>\n",
              "      <td>21.100235</td>\n",
              "      <td>66.532172</td>\n",
              "      <td>37.942374</td>\n",
              "      <td>17.688710</td>\n",
              "      <td>0.921661</td>\n",
              "      <td>0.927959</td>\n",
              "      <td>35.909782</td>\n",
              "      <td>32.040772</td>\n",
              "      <td>87.586757</td>\n",
              "      <td>8.446671</td>\n",
              "      <td>35.514539</td>\n",
              "      <td>55.920650</td>\n",
              "      <td>17.002257</td>\n",
              "      <td>37.749348</td>\n",
              "      <td>9.955671</td>\n",
              "      <td>1.731796</td>\n",
              "      <td>18.555496</td>\n",
              "      <td>13.776335</td>\n",
              "      <td>21.217106</td>\n",
              "      <td>66.870763</td>\n",
              "      <td>37.930859</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>893 rows × 94 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-327899b0-6166-4988-9aba-8c763544cae5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-327899b0-6166-4988-9aba-8c763544cae5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-327899b0-6166-4988-9aba-8c763544cae5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import pandas as pd \n",
        "pd.set_option('display.max_columns', None) # to show all coumns below\n",
        "df = pd.read_csv('covid.test.csv'); df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zlpIp9ANJRU"
      },
      "outputs": [],
      "source": [
        "class COVID19Dataset(Dataset):\n",
        "    ''' Dataset for loading and preprocessing the COVID19 dataset '''\n",
        "    def __init__(self, path, mode='train', feats=list(range(93))):\n",
        "        \"\"\"\n",
        "        Prepares a dataset as specified.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        path : str\n",
        "            The path of the training dataset or the test set. \n",
        "        mode : str\n",
        "            How the dataset should be prepared. Available options include \"train\", \n",
        "            \"dev\", and \"test\".\n",
        "        feats: \n",
        "            The list of feature indices to consider.\n",
        "        \"\"\"\n",
        "        self.mode = mode\n",
        "\n",
        "        # Step 1: Read data into numpy arrays\n",
        "        with open(path, 'r') as fp:\n",
        "            data = list(csv.reader(fp))\n",
        "            data = np.array(data[1:])[:, 1:].astype(float) # note that the ID has been left out\n",
        "        \n",
        "        # Step 2: Prepare the dataset\n",
        "        if mode == 'test':\n",
        "            # Testing data\n",
        "            # data: 893 x 93 (40 states + day 1 (18) + day 2 (18) + day 3 (17))\n",
        "            data = data[:, feats]\n",
        "            self.data = torch.FloatTensor(data)\n",
        "        else:\n",
        "            # Training data (train/dev sets)\n",
        "            # data: 2700 x 94 (40 states + day 1 (18) + day 2 (18) + day 3 (18))\n",
        "            target = data[:, -1]\n",
        "            data = data[:, feats]\n",
        "            \n",
        "            # Splitting training data into train & dev sets\n",
        "            if mode == 'train':\n",
        "                indices = [i for i in range(len(data)) if i % 10 != 0]\n",
        "            elif mode == 'dev':\n",
        "                indices = [i for i in range(len(data)) if i % 10 == 0]\n",
        "            \n",
        "            # Convert data into PyTorch tensors\n",
        "            self.data = torch.FloatTensor(data[indices])\n",
        "            self.target = torch.FloatTensor(target[indices])\n",
        "\n",
        "        # Step 3: Normalize features (you may remove this part to see what will happen)\n",
        "        self.data[:, 40:] = \\\n",
        "            (self.data[:, 40:] - self.data[:, 40:].mean(dim=0, keepdim=True)) \\\n",
        "            / self.data[:, 40:].std(dim=0, keepdim=True)\n",
        "\n",
        "        self.dim = self.data.shape[1]\n",
        "\n",
        "        print(f'Finished reading the {mode} set of COVID19 Dataset ({len(self.data)} samples found, each dim = {self.dim})')\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Returns one sample at a time\n",
        "        if self.mode in ['train', 'dev']:\n",
        "            # For training\n",
        "            return self.data[index], self.target[index]\n",
        "        else:\n",
        "            # For testing (no target)\n",
        "            return self.data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        # Returns the size of the dataset\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqHleX100pba"
      },
      "source": [
        "Then, we define `prep_dataloader`, which can be used to construct dataloaders for loading data. (Specifically, in `prep_dataloader`, `DataLoader` loads data from a given `Dataset` into batches.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlhLk5t6MBX3"
      },
      "outputs": [],
      "source": [
        "def prep_dataloader(path, mode, batch_size, n_jobs=0, feats=list(range(93))):\n",
        "    ''' Generates a dataset, then is put into a dataloader. '''\n",
        "    dataset = COVID19Dataset(path, mode=mode, feats=feats)  # Construct dataset\n",
        "    dataloader = DataLoader(dataset, batch_size, shuffle=(mode == 'train'), drop_last=False, num_workers=n_jobs, pin_memory=True)\n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGuycwR0MeQB"
      },
      "source": [
        "# **Section 4. Define classes/functions to build, train, and test neural networks**\n",
        "\n",
        "Now, we build the class `NeuralNet` that inherits `nn.Module` for data regression. This DNN consists of 2 fully-connected layers with ReLU activation. This module also includes a function `cal_loss` for calculating the MSE loss. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49-uXYovOAI0"
      },
      "outputs": [],
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    ''' A simple fully-connected deep neural network '''\n",
        "    def __init__(self, input_dim):\n",
        "        super(NeuralNet, self).__init__()\n",
        "\n",
        "        # Define your neural network here\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1))\n",
        "\n",
        "        # Mean squared error loss\n",
        "        self.criterion = nn.MSELoss(reduction='mean')\n",
        "\n",
        "    def forward(self, x):\n",
        "        ''' Given input of size (batch_size x input_dim), compute output of the network '''\n",
        "        return self.net(x).squeeze(1)\n",
        "\n",
        "    def cal_loss(self, pred, target):\n",
        "        ''' Calculate loss '''\n",
        "        return self.criterion(pred, target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61fLSrxNh7XK"
      },
      "source": [
        "Then, we define functions for training, validating, and testing the neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOqcmYzMO7jB"
      },
      "outputs": [],
      "source": [
        "def train(tr_set, dv_set, model, config, device):\n",
        "    ''' DNN training '''\n",
        "\n",
        "    n_epochs = config['n_epochs']  # Maximum number of epochs\n",
        "\n",
        "    # Setup optimizer\n",
        "    optimizer = getattr(torch.optim, config['optimizer'])(\n",
        "        model.parameters(), **config['optim_hparas'])\n",
        "\n",
        "    min_mse = 1000.\n",
        "    loss_record = {'train': [], 'dev': []}      # for recording training loss\n",
        "    early_stop_cnt = 0\n",
        "    epoch = 0\n",
        "    while epoch < n_epochs:\n",
        "        model.train()                           # set model to training mode\n",
        "        for x, y in tr_set:                     # iterate through the dataloader\n",
        "            optimizer.zero_grad()               # set gradient to zero\n",
        "            x, y = x.to(device), y.to(device)   # move data to device (cpu/cuda)\n",
        "            pred = model(x)                     # forward pass (compute output)\n",
        "            mse_loss = model.cal_loss(pred, y)  # compute loss\n",
        "            mse_loss.backward()                 # compute gradient (backpropagation)\n",
        "            optimizer.step()                    # update model with optimizer\n",
        "            loss_record['train'].append(mse_loss.detach().cpu().item())\n",
        "\n",
        "        # After each epoch, test your model on the validation (development) set.\n",
        "        dev_mse = dev(dv_set, model, device)\n",
        "        if dev_mse < min_mse:\n",
        "            # Save model if your model improved\n",
        "            min_mse = dev_mse\n",
        "            print(f'Saving model (epoch = {epoch + 1}, validation loss = {min_mse:.4f}')\n",
        "            torch.save(model.state_dict(), config['save_path'])  # Save model to specified path\n",
        "            early_stop_cnt = 0\n",
        "        else:\n",
        "            early_stop_cnt += 1\n",
        "\n",
        "        epoch += 1\n",
        "        loss_record['dev'].append(dev_mse)\n",
        "        if early_stop_cnt > config['early_stop']:\n",
        "            # Stop training if your model stops improving for \"config['early_stop']\" epochs.\n",
        "            break\n",
        "\n",
        "    print('Finished training after {} epochs'.format(epoch))\n",
        "    return min_mse, loss_record"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrxrD3YsN3U2"
      },
      "outputs": [],
      "source": [
        "def dev(dv_set, model, device):\n",
        "    model.eval()                                # set model to evalutation mode\n",
        "    total_loss = 0\n",
        "    for x, y in dv_set:                         # iterate through the dataloader\n",
        "        x, y = x.to(device), y.to(device)       # move data to device (cpu/cuda)\n",
        "        with torch.no_grad():                   # disable gradient calculation\n",
        "            pred = model(x)                     # forward pass (compute output)\n",
        "            mse_loss = model.cal_loss(pred, y)  # compute loss\n",
        "        total_loss += mse_loss.detach().cpu().item() * len(x)  # accumulate loss\n",
        "    total_loss = total_loss / len(dv_set.dataset)              # compute averaged loss\n",
        "\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSBMRFlYN5tB"
      },
      "outputs": [],
      "source": [
        "def test(tt_set, model, device):\n",
        "    model.eval()                                # set model to evalutation mode\n",
        "    preds = []\n",
        "    for x in tt_set:                            # iterate through the dataloader\n",
        "        x = x.to(device)                        # move data to device (cpu/cuda)\n",
        "        with torch.no_grad():                   # disable gradient calculation\n",
        "            pred = model(x)                     # forward pass (compute output)\n",
        "            preds.append(pred.detach().cpu())   # collect prediction\n",
        "    preds = torch.cat(preds, dim=0).numpy()     # concatenate all predictions and convert to a numpy array\n",
        "    return preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvckkF5dvf0j"
      },
      "source": [
        "# **Section 5. Build, train, and assess a neural network**\n",
        "\n",
        "With the classes and functions defined above, let's build and train a neural network to pass the simple baseline. To do this, we define a dictionary `config` that contains hyper-parameters for training, and the path to save the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPXpdumwPjE7"
      },
      "outputs": [],
      "source": [
        "device = get_device()                    # get the current available device ('cpu' or 'cuda')\n",
        "os.makedirs('models', exist_ok=True)     # The trained model will be saved to ./models/\n",
        "feats= list(range(93))\n",
        "\n",
        "config = {\n",
        "    'n_epochs': 3000,                # maximum number of epochs\n",
        "    'batch_size': 270,               # mini-batch size for dataloader\n",
        "    'optimizer': 'SGD',              # optimization algorithm (optimizer in torch.optim)\n",
        "    'optim_hparas': {                # hyper-parameters for the optimizer (depends on which optimizer you are using)\n",
        "        'lr': 0.001,                 # learning rate of SGD\n",
        "        'momentum': 0.9              # momentum for SGD\n",
        "    },\n",
        "    'early_stop': 200,               # early stopping epochs (the number epochs since your model's last improvement)\n",
        "    'save_path': 'models/model.pth'  # your model will be saved here\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6j1eOV3TOH-j"
      },
      "source": [
        "Below we set up data loaders for loading the training set, validation set and the test set. Then we construct our first neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNrYBMmePLKm",
        "outputId": "22ce71ae-26dd-48b8-d64a-b7c142b4aaa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished reading the train set of COVID19 Dataset (2430 samples found, each dim = 93)\n",
            "Finished reading the dev set of COVID19 Dataset (270 samples found, each dim = 93)\n",
            "Finished reading the test set of COVID19 Dataset (893 samples found, each dim = 93)\n"
          ]
        }
      ],
      "source": [
        "tr_set = prep_dataloader(tr_path, 'train', config['batch_size'], feats=feats)\n",
        "dv_set = prep_dataloader(tr_path, 'dev', config['batch_size'], feats=feats)\n",
        "tt_set = prep_dataloader(tt_path, 'test', config['batch_size'], feats=feats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHylSirLP9oh"
      },
      "outputs": [],
      "source": [
        "model = NeuralNet(tr_set.dataset.dim).to(device)  # Construct model and move to device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX2B_zgSOPTJ"
      },
      "source": [
        "Now let's start training the model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrEbUxazQAAZ",
        "outputId": "61279427-8a0f-42a1-8ca7-5a58727c5cb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model (epoch = 1, validation loss = 78.8524\n",
            "Saving model (epoch = 2, validation loss = 37.6170\n",
            "Saving model (epoch = 3, validation loss = 26.1203\n",
            "Saving model (epoch = 4, validation loss = 16.1862\n",
            "Saving model (epoch = 5, validation loss = 9.7153\n",
            "Saving model (epoch = 6, validation loss = 6.3701\n",
            "Saving model (epoch = 7, validation loss = 5.1802\n",
            "Saving model (epoch = 8, validation loss = 4.4255\n",
            "Saving model (epoch = 9, validation loss = 3.8009\n",
            "Saving model (epoch = 10, validation loss = 3.3691\n",
            "Saving model (epoch = 11, validation loss = 3.0943\n",
            "Saving model (epoch = 12, validation loss = 2.8176\n",
            "Saving model (epoch = 13, validation loss = 2.6274\n",
            "Saving model (epoch = 14, validation loss = 2.4542\n",
            "Saving model (epoch = 15, validation loss = 2.3012\n",
            "Saving model (epoch = 16, validation loss = 2.1766\n",
            "Saving model (epoch = 17, validation loss = 2.0641\n",
            "Saving model (epoch = 18, validation loss = 1.9399\n",
            "Saving model (epoch = 19, validation loss = 1.8978\n",
            "Saving model (epoch = 20, validation loss = 1.7950\n",
            "Saving model (epoch = 21, validation loss = 1.7164\n",
            "Saving model (epoch = 22, validation loss = 1.6455\n",
            "Saving model (epoch = 23, validation loss = 1.5912\n",
            "Saving model (epoch = 24, validation loss = 1.5599\n",
            "Saving model (epoch = 25, validation loss = 1.5197\n",
            "Saving model (epoch = 26, validation loss = 1.4698\n",
            "Saving model (epoch = 27, validation loss = 1.4189\n",
            "Saving model (epoch = 28, validation loss = 1.3992\n",
            "Saving model (epoch = 29, validation loss = 1.3696\n",
            "Saving model (epoch = 30, validation loss = 1.3442\n",
            "Saving model (epoch = 31, validation loss = 1.3231\n",
            "Saving model (epoch = 32, validation loss = 1.2834\n",
            "Saving model (epoch = 33, validation loss = 1.2804\n",
            "Saving model (epoch = 34, validation loss = 1.2471\n",
            "Saving model (epoch = 36, validation loss = 1.2414\n",
            "Saving model (epoch = 37, validation loss = 1.2138\n",
            "Saving model (epoch = 38, validation loss = 1.2083\n",
            "Saving model (epoch = 41, validation loss = 1.1591\n",
            "Saving model (epoch = 42, validation loss = 1.1484\n",
            "Saving model (epoch = 44, validation loss = 1.1209\n",
            "Saving model (epoch = 47, validation loss = 1.1122\n",
            "Saving model (epoch = 48, validation loss = 1.0937\n",
            "Saving model (epoch = 50, validation loss = 1.0842\n",
            "Saving model (epoch = 53, validation loss = 1.0655\n",
            "Saving model (epoch = 54, validation loss = 1.0613\n",
            "Saving model (epoch = 57, validation loss = 1.0524\n",
            "Saving model (epoch = 58, validation loss = 1.0394\n",
            "Saving model (epoch = 60, validation loss = 1.0267\n",
            "Saving model (epoch = 63, validation loss = 1.0248\n",
            "Saving model (epoch = 66, validation loss = 1.0099\n",
            "Saving model (epoch = 70, validation loss = 0.9829\n",
            "Saving model (epoch = 72, validation loss = 0.9817\n",
            "Saving model (epoch = 73, validation loss = 0.9743\n",
            "Saving model (epoch = 75, validation loss = 0.9671\n",
            "Saving model (epoch = 78, validation loss = 0.9643\n",
            "Saving model (epoch = 79, validation loss = 0.9597\n",
            "Saving model (epoch = 85, validation loss = 0.9549\n",
            "Saving model (epoch = 86, validation loss = 0.9535\n",
            "Saving model (epoch = 90, validation loss = 0.9467\n",
            "Saving model (epoch = 92, validation loss = 0.9432\n",
            "Saving model (epoch = 93, validation loss = 0.9231\n",
            "Saving model (epoch = 95, validation loss = 0.9127\n",
            "Saving model (epoch = 104, validation loss = 0.9117\n",
            "Saving model (epoch = 107, validation loss = 0.8994\n",
            "Saving model (epoch = 110, validation loss = 0.8935\n",
            "Saving model (epoch = 116, validation loss = 0.8882\n",
            "Saving model (epoch = 124, validation loss = 0.8872\n",
            "Saving model (epoch = 128, validation loss = 0.8724\n",
            "Saving model (epoch = 134, validation loss = 0.8722\n",
            "Saving model (epoch = 139, validation loss = 0.8677\n",
            "Saving model (epoch = 146, validation loss = 0.8654\n",
            "Saving model (epoch = 156, validation loss = 0.8642\n",
            "Saving model (epoch = 159, validation loss = 0.8528\n",
            "Saving model (epoch = 167, validation loss = 0.8494\n",
            "Saving model (epoch = 173, validation loss = 0.8492\n",
            "Saving model (epoch = 176, validation loss = 0.8461\n",
            "Saving model (epoch = 178, validation loss = 0.8403\n",
            "Saving model (epoch = 182, validation loss = 0.8375\n",
            "Saving model (epoch = 199, validation loss = 0.8295\n",
            "Saving model (epoch = 212, validation loss = 0.8273\n",
            "Saving model (epoch = 235, validation loss = 0.8252\n",
            "Saving model (epoch = 238, validation loss = 0.8233\n",
            "Saving model (epoch = 251, validation loss = 0.8211\n",
            "Saving model (epoch = 253, validation loss = 0.8205\n",
            "Saving model (epoch = 258, validation loss = 0.8175\n",
            "Saving model (epoch = 284, validation loss = 0.8143\n",
            "Saving model (epoch = 308, validation loss = 0.8136\n",
            "Saving model (epoch = 312, validation loss = 0.8075\n",
            "Saving model (epoch = 324, validation loss = 0.8045\n",
            "Saving model (epoch = 400, validation loss = 0.8040\n",
            "Saving model (epoch = 404, validation loss = 0.8010\n",
            "Saving model (epoch = 466, validation loss = 0.7998\n",
            "Saving model (epoch = 525, validation loss = 0.7993\n",
            "Saving model (epoch = 561, validation loss = 0.7945\n",
            "Saving model (epoch = 584, validation loss = 0.7903\n",
            "Saving model (epoch = 667, validation loss = 0.7896\n",
            "Saving model (epoch = 717, validation loss = 0.7823\n",
            "Saving model (epoch = 776, validation loss = 0.7812\n",
            "Saving model (epoch = 835, validation loss = 0.7797\n",
            "Saving model (epoch = 866, validation loss = 0.7771\n",
            "Saving model (epoch = 919, validation loss = 0.7770\n",
            "Saving model (epoch = 933, validation loss = 0.7748\n",
            "Saving model (epoch = 965, validation loss = 0.7705\n",
            "Saving model (epoch = 1027, validation loss = 0.7674\n",
            "Saving model (epoch = 1119, validation loss = 0.7647\n",
            "Saving model (epoch = 1140, validation loss = 0.7643\n",
            "Saving model (epoch = 1196, validation loss = 0.7620\n",
            "Saving model (epoch = 1234, validation loss = 0.7616\n",
            "Saving model (epoch = 1243, validation loss = 0.7582\n",
            "Finished training after 1444 epochs\n"
          ]
        }
      ],
      "source": [
        "model_loss, model_loss_record = train(tr_set, dv_set, model, config, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOwR1DWDjLl_"
      },
      "source": [
        "As shown above, the model was trained for 1444 epochs and the minimum loss validation loss was 0.7582. The training loss and validation loss as functions of the number of training steps can be plotted as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "hsNO9nnXQBvP",
        "outputId": "63a1cf97-4a17-464c-b30d-a911efd54920"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_learning_curve(model_loss_record)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7jpdjr2m03b"
      },
      "source": [
        "Another way to assess the neural network is to comparing its predictions with the labels in the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "3iZTVn5WQFpX",
        "outputId": "b4975c09-10c5-4739-dea2-700aafbeb041"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "del model\n",
        "model = NeuralNet(tr_set.dataset.dim).to(device)\n",
        "ckpt = torch.load(config['save_path'], map_location='cpu')  # Load your best model\n",
        "model.load_state_dict(ckpt)\n",
        "plot_pred(dv_set, model, device)  # Show prediction on the validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSrgwZytQAUW"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQikz3IPiyPf"
      },
      "source": [
        "Finally, we also want to compare the predictions of the model with the labels in the test set. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8cTuQjQQOon",
        "outputId": "a143e5d3-edd7-46a4-d263-4ce1f8aa526c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving results to pred_1.csv\n"
          ]
        }
      ],
      "source": [
        "def save_pred(preds, file):\n",
        "    ''' Save predictions to specified file '''\n",
        "    print('Saving results to {}'.format(file))\n",
        "    with open(file, 'w') as fp:\n",
        "        writer = csv.writer(fp)\n",
        "        writer.writerow(['id', 'tested_positive'])\n",
        "        for i, p in enumerate(preds):\n",
        "            writer.writerow([i, p])\n",
        "\n",
        "preds = test(tt_set, model, device)    # predict COVID-19 cases with your model\n",
        "save_pred(preds, 'pred_1.csv')         # save prediction file to pred_1.csv\n",
        "\n",
        "model = NeuralNet(tr_set.dataset.dim).to(device)  # Construct model and move to device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iAgaTjQPtsQ"
      },
      "source": [
        "As shown above, a CVS file containing the predictions, `pred.csv` will be saved. At this point, the predictions will gain a score of 1.35265, which passes the simple baseline but not both medium baselines. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Djtu0AR4Uyr"
      },
      "source": [
        "# **Section 6. Feature selection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cwb5fqWGQMqW"
      },
      "source": [
        "To pass the medium baseline, we should consider only 42 features (one-hot vector and the positive rates of Days 1 (index and 2) instead of 93. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXPYfGtrQLvH",
        "outputId": "af6b7875-88af-4108-d023-1eaa140c4a77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished reading the train set of COVID19 Dataset (2430 samples found, each dim = 42)\n",
            "Finished reading the dev set of COVID19 Dataset (270 samples found, each dim = 42)\n",
            "Finished reading the test set of COVID19 Dataset (893 samples found, each dim = 42)\n",
            "Saving model (epoch = 1, validation loss = 261.5010\n",
            "Saving model (epoch = 2, validation loss = 32.9624\n",
            "Saving model (epoch = 3, validation loss = 25.3204\n",
            "Saving model (epoch = 4, validation loss = 19.4433\n",
            "Saving model (epoch = 5, validation loss = 3.2958\n",
            "Saving model (epoch = 6, validation loss = 2.1733\n",
            "Saving model (epoch = 8, validation loss = 1.9198\n",
            "Saving model (epoch = 9, validation loss = 1.5372\n",
            "Saving model (epoch = 10, validation loss = 1.4368\n",
            "Saving model (epoch = 11, validation loss = 1.4056\n",
            "Saving model (epoch = 12, validation loss = 1.3872\n",
            "Saving model (epoch = 13, validation loss = 1.3493\n",
            "Saving model (epoch = 14, validation loss = 1.3230\n",
            "Saving model (epoch = 15, validation loss = 1.3064\n",
            "Saving model (epoch = 16, validation loss = 1.2886\n",
            "Saving model (epoch = 17, validation loss = 1.2722\n",
            "Saving model (epoch = 18, validation loss = 1.2562\n",
            "Saving model (epoch = 19, validation loss = 1.2417\n",
            "Saving model (epoch = 20, validation loss = 1.2286\n",
            "Saving model (epoch = 21, validation loss = 1.2170\n",
            "Saving model (epoch = 22, validation loss = 1.2017\n",
            "Saving model (epoch = 23, validation loss = 1.1978\n",
            "Saving model (epoch = 24, validation loss = 1.1854\n",
            "Saving model (epoch = 25, validation loss = 1.1819\n",
            "Saving model (epoch = 26, validation loss = 1.1680\n",
            "Saving model (epoch = 27, validation loss = 1.1593\n",
            "Saving model (epoch = 28, validation loss = 1.1572\n",
            "Saving model (epoch = 29, validation loss = 1.1437\n",
            "Saving model (epoch = 31, validation loss = 1.1345\n",
            "Saving model (epoch = 32, validation loss = 1.1270\n",
            "Saving model (epoch = 33, validation loss = 1.1232\n",
            "Saving model (epoch = 34, validation loss = 1.1149\n",
            "Saving model (epoch = 35, validation loss = 1.1113\n",
            "Saving model (epoch = 36, validation loss = 1.1079\n",
            "Saving model (epoch = 37, validation loss = 1.1057\n",
            "Saving model (epoch = 38, validation loss = 1.0942\n",
            "Saving model (epoch = 39, validation loss = 1.0925\n",
            "Saving model (epoch = 41, validation loss = 1.0835\n",
            "Saving model (epoch = 42, validation loss = 1.0824\n",
            "Saving model (epoch = 43, validation loss = 1.0782\n",
            "Saving model (epoch = 44, validation loss = 1.0732\n",
            "Saving model (epoch = 45, validation loss = 1.0724\n",
            "Saving model (epoch = 46, validation loss = 1.0691\n",
            "Saving model (epoch = 47, validation loss = 1.0653\n",
            "Saving model (epoch = 48, validation loss = 1.0621\n",
            "Saving model (epoch = 49, validation loss = 1.0559\n",
            "Saving model (epoch = 51, validation loss = 1.0537\n",
            "Saving model (epoch = 52, validation loss = 1.0476\n",
            "Saving model (epoch = 53, validation loss = 1.0471\n",
            "Saving model (epoch = 54, validation loss = 1.0456\n",
            "Saving model (epoch = 55, validation loss = 1.0388\n",
            "Saving model (epoch = 57, validation loss = 1.0359\n",
            "Saving model (epoch = 58, validation loss = 1.0353\n",
            "Saving model (epoch = 59, validation loss = 1.0329\n",
            "Saving model (epoch = 60, validation loss = 1.0328\n",
            "Saving model (epoch = 61, validation loss = 1.0291\n",
            "Saving model (epoch = 62, validation loss = 1.0224\n",
            "Saving model (epoch = 65, validation loss = 1.0188\n",
            "Saving model (epoch = 66, validation loss = 1.0161\n",
            "Saving model (epoch = 68, validation loss = 1.0127\n",
            "Saving model (epoch = 69, validation loss = 1.0107\n",
            "Saving model (epoch = 72, validation loss = 1.0068\n",
            "Saving model (epoch = 74, validation loss = 1.0047\n",
            "Saving model (epoch = 75, validation loss = 1.0020\n",
            "Saving model (epoch = 78, validation loss = 0.9977\n",
            "Saving model (epoch = 80, validation loss = 0.9976\n",
            "Saving model (epoch = 81, validation loss = 0.9941\n",
            "Saving model (epoch = 83, validation loss = 0.9934\n",
            "Saving model (epoch = 84, validation loss = 0.9920\n",
            "Saving model (epoch = 86, validation loss = 0.9903\n",
            "Saving model (epoch = 87, validation loss = 0.9894\n",
            "Saving model (epoch = 90, validation loss = 0.9843\n",
            "Saving model (epoch = 93, validation loss = 0.9842\n",
            "Saving model (epoch = 95, validation loss = 0.9831\n",
            "Saving model (epoch = 97, validation loss = 0.9821\n",
            "Saving model (epoch = 102, validation loss = 0.9794\n",
            "Saving model (epoch = 106, validation loss = 0.9758\n",
            "Saving model (epoch = 116, validation loss = 0.9744\n",
            "Saving model (epoch = 121, validation loss = 0.9742\n",
            "Saving model (epoch = 122, validation loss = 0.9740\n",
            "Saving model (epoch = 125, validation loss = 0.9724\n",
            "Saving model (epoch = 128, validation loss = 0.9721\n",
            "Saving model (epoch = 129, validation loss = 0.9710\n",
            "Saving model (epoch = 132, validation loss = 0.9708\n",
            "Saving model (epoch = 136, validation loss = 0.9703\n",
            "Saving model (epoch = 139, validation loss = 0.9702\n",
            "Saving model (epoch = 143, validation loss = 0.9697\n",
            "Saving model (epoch = 145, validation loss = 0.9692\n",
            "Saving model (epoch = 146, validation loss = 0.9683\n",
            "Saving model (epoch = 152, validation loss = 0.9671\n",
            "Saving model (epoch = 156, validation loss = 0.9670\n",
            "Saving model (epoch = 169, validation loss = 0.9665\n",
            "Saving model (epoch = 174, validation loss = 0.9660\n",
            "Saving model (epoch = 202, validation loss = 0.9644\n",
            "Saving model (epoch = 230, validation loss = 0.9642\n",
            "Saving model (epoch = 236, validation loss = 0.9638\n",
            "Saving model (epoch = 255, validation loss = 0.9635\n",
            "Saving model (epoch = 329, validation loss = 0.9632\n",
            "Saving model (epoch = 360, validation loss = 0.9630\n",
            "Saving model (epoch = 459, validation loss = 0.9627\n",
            "Saving model (epoch = 464, validation loss = 0.9621\n",
            "Finished training after 665 epochs\n"
          ]
        }
      ],
      "source": [
        "device = get_device()                    # get the current available device ('cpu' or 'cuda')\n",
        "os.makedirs('models', exist_ok=True)     # The trained model will be saved to ./models/\n",
        "feats= list(range(40)) +  [57, 75]\n",
        "\n",
        "config = {\n",
        "    'n_epochs': 3000,                # maximum number of epochs\n",
        "    'batch_size': 270,               # mini-batch size for dataloader\n",
        "    'optimizer': 'SGD',              # optimization algorithm (optimizer in torch.optim)\n",
        "    'optim_hparas': {                # hyper-parameters for the optimizer (depends on which optimizer you are using)\n",
        "        'lr': 0.001,                 # learning rate of SGD\n",
        "        'momentum': 0.9              # momentum for SGD\n",
        "    },\n",
        "    'early_stop': 200,               # early stopping epochs (the number epochs since your model's last improvement)\n",
        "    'save_path': 'models/model.pth'  # your model will be saved here\n",
        "}\n",
        "\n",
        "tr_set = prep_dataloader(tr_path, 'train', config['batch_size'], feats=feats)\n",
        "dv_set = prep_dataloader(tr_path, 'dev', config['batch_size'], feats=feats)\n",
        "tt_set = prep_dataloader(tt_path, 'test', config['batch_size'], feats=feats)\n",
        "\n",
        "model = NeuralNet(tr_set.dataset.dim).to(device)  # Construct model and move to device\n",
        "\n",
        "model_loss, model_loss_record = train(tr_set, dv_set, model, config, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "buzSK-clRTJY",
        "outputId": "afda9fcf-ffba-4fc1-cbed-ac7dd5a48430"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEKCAYAAAAYd05sAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5hU1fnA8e87bfsusPSioCKLIh0VUVTsSiyABTVKUFTsvUYlMZYoSQz5qRE1ikbFFrGLDREhAWkisPSidNjeZqed3x9zd3aGna3sbBnfz/Pss3duOefc2dl3zj3n3HPFGINSSqn4Y2vuAiillIoNDfBKKRWnNMArpVSc0gCvlFJxSgO8UkrFKQ3wSikVpxyxTFxEtgBFgB/wGWOGxjI/pZRSlWIa4C0nG2P2NUE+SimlwmgTjVJKxSmJ5Z2sIrIZyAMM8LwxZnqUfa4BrgFISUkZkpWV1aC8CjdvZnP7TnTdu4f2PbohTucBlFwppVqHJUuW7DPGdIi2LdYBvpsxZruIdAS+BG4yxnxX3f5Dhw41ixcvblBesy+9gisn3c6U6X/jqr88jrNr1waWWimlWg8RWVJd/2ZMm2iMMdut33uA94GjY5lfWMZNko1SSrVkMQvwIpIiImkVy8DpwMpY5aeUUipSLEfRdALeF5GKfN4wxnwew/yUUkqFiVmAN8ZsAgbEKv2a826OXJVqfbxeL9u2bcPtdjd3UVQtEhMT6d69O856DCBpinHwTULQqK5UfW3bto20tDR69uyJdbWtWiBjDDk5OWzbto1evXrV+bg4HQevwV6punC73WRmZmpwb+FEhMzMzHpfacVpgFdK1ZUG99ahIX8nDfBKKRWn4jPAay+rUq1CTk4OAwcOZODAgXTu3Jlu3bqFXns8nhqPXbx4MTfffHOteRx33HGNUtZvv/2W0aNHN0paTSVuOlkrGL3cVKrVyMzMZPny5QBMmTKF1NRU7rzzztB2n8+HwxE9TA0dOpShQ2ufoHbBggWNU9hWKH5q8OGVdq3BK9VqTZgwgeuuu45jjjmGu+++m0WLFjF8+HAGDRrEcccdx9q1a4HIGvWUKVOYOHEiJ510EocccgjTpk0LpZeamhra/6STTmLcuHFkZWVx2WWXUTFVy6effkpWVhZDhgzh5ptvrrWmnpuby/nnn0///v059thjWbFiBQBz584NXYEMGjSIoqIidu7cyciRIxk4cCD9+vVj3rx5jf6eVSfuavBKqYbZ9dhjlGevadQ0E/pm0fn+++t93LZt21iwYAF2u53CwkLmzZuHw+Hgq6++4v777+e9996rcsyaNWuYM2cORUVF9OnTh8mTJ1cZM75s2TJWrVpF165dGTFiBPPnz2fo0KFce+21fPfdd/Tq1Yvx48fXWr6HH36YQYMGMWvWLL755huuuOIKli9fztSpU3nmmWcYMWIExcXFJCYmMn36dM444wweeOAB/H4/paWl9X4/GkoDvFKqxbnwwgux2+0AFBQUcOWVV7J+/XpEBK/XG/WYc845h4SEBBISEujYsSO7d++me/fuEfscffTRoXUDBw5ky5YtpKamcsghh4TGl48fP57p06tMfBvh+++/D33JjBo1ipycHAoLCxkxYgS33347l112GWPGjKF79+4MGzaMiRMn4vV6Of/88xk4cOABvTf1EZ8BXptolKq3htS0YyUlJSW0/OCDD3LyySfz/vvvs2XLFk466aSoxyQkJISW7XY7Pp+vQfsciHvvvZdzzjmHTz/9lBEjRjB79mxGjhzJd999xyeffMKECRO4/fbbueKKKxo13+rETxu8UiouFRQU0K1bNwBeeeWVRk+/T58+bNq0iS1btgDw1ltv1XrMCSecwOuvvw4E2/bbt29Peno6Gzdu5KijjuKee+5h2LBhrFmzhq1bt9KpUycmTZrE1VdfzdKlSxv9HKoTdwHeIFqDVyqO3H333dx3330MGjSo0WvcAElJSTz77LOceeaZDBkyhLS0NDIyMmo8ZsqUKSxZsoT+/ftz7733MmPGDACefvpp+vXrR//+/XE6nZx11ll8++23DBgwgEGDBvHWW29xyy23NPo5VCemD/yorwN54MeX4y/nt9fcyUMv/J2rH3sYV8+ejVs4peJQdnY2ffv2be5iNLvi4mJSU1MxxnDDDTfQu3dvbrvttuYuVhXR/l7N9sAPpZRqDV544QUGDhzIkUceSUFBAddee21zF6lRxGUna0u6KlFKtXy33XZbi6yxHyitwSulVJyKuwBvBJ0tWCmliKMALxrUlVIqQtwEeKWUUpHiNMBrdV6p1uDkk09m9uzZEeuefvppJk+eXO0xJ510EhXDqc8++2zy8/Or7DNlyhSmTp1aY96zZs1i9erVodcPPfQQX331VX2KH1VLmlY4TgO8Uqo1GD9+PDNnzoxYN3PmzDpN+AXBWSDbtGnToLz3D/B//OMfOfXUUxuUVksVnwFeh0kq1SqMGzeOTz75JPRwjy1btrBjxw5OOOEEJk+ezNChQznyyCN5+OGHox7fs2dP9u3bB8Cjjz7K4YcfzvHHHx+aUhiCY9yHDRvGgAEDGDt2LKWlpSxYsIAPP/yQu+66i4EDB7Jx40YmTJjAu+++C8DXX3/NoEGDOOqoo5g4cSLl5eWh/B5++GEGDx7MUUcdxZo1Nc++2dzTCsffOHh94IdSDfLg+m2sLC5r1DT7pSbxSO/u1W5v164dRx99NJ999hnnnXceM2fO5KKLLkJEePTRR2nXrh1+v59TTjmFFStW0L9//6jpLFmyhJkzZ7J8+XJ8Ph+DBw9myJAhAIwZM4ZJkyYB8Pvf/56XXnqJm266iXPPPZfRo0czbty4iLTcbjcTJkzg66+/5vDDD+eKK67gueee49ZbbwWgffv2LF26lGeffZapU6fy4osvVnt+zT2tcNzU4EXb3ZVqlcKbacKbZ95++20GDx7MoEGDWLVqVURzyv7mzZvHBRdcQHJyMunp6Zx77rmhbStXruSEE07gqKOO4vXXX2fVqlU1lmft2rX06tWLww8/HIArr7yS7777LrR9zJgxAAwZMiQ0QVl1vv/+e377298C0acVnjZtGvn5+TgcDoYNG8bLL7/MlClT+Omnn0hLS6sx7bqImxp8+8mTIWC90CYapeqtppp2LJ133nncdtttLF26lNLSUoYMGcLmzZuZOnUqP/zwA23btmXChAm43e4GpT9hwgRmzZrFgAEDeOWVV/j2228PqLwVUw4fyHTDTTWtcNzU4JPr8GxGpVTLk5qaysknn8zEiRNDtffCwkJSUlLIyMhg9+7dfPbZZzWmMXLkSGbNmkVZWRlFRUV89NFHoW1FRUV06dIFr9cbmuIXIC0tjaKioipp9enThy1btrBhwwYAXnvtNU488cQGnVtzTyscNzV4pVTrNX78eC644IJQU03F9LpZWVn06NGDESNG1Hj84MGDufjiixkwYAAdO3Zk2LBhoW2PPPIIxxxzDB06dOCYY44JBfVLLrmESZMmMW3atFDnKkBiYiIvv/wyF154IT6fj2HDhnHdddc16LwqnhXbv39/kpOTI6YVnjNnDjabjSOPPJKzzjqLmTNn8tRTT+F0OklNTeXVV19tUJ7h4ma64PUlbk5YtIYHX5rG1Q/fR0Lv3o1cOqXij04X3Lr86qcLNugoGqWUgjgK8OGjI1vSVYlSSjWXuAnwSqmG0QpR69CQv5MGeKV+xRITE8nJydEg38IZY8jJySExMbFex8XnKBr9rCpVJ927d2fbtm3s3bu3uYuiapGYmEj37vW7VyE+A7xSqk6cTie9evVq7mKoGIm7JhojoFV4pZRqggAvInYRWSYiH8c0n1gmrpRSrVBT1OBvAbKbIB+llFJhYhrgRaQ7cA5Q/XyasaAjApRSKuY1+KeBu6mc57EKEblGRBaLyGLtyVdKqcYTswAvIqOBPcaYJTXtZ4yZbowZaowZ2qFDhwPO1yBag1dKKWJbgx8BnCsiW4CZwCgR+XesMhPtZlVKqQgxC/DGmPuMMd2NMT2BS4BvjDGXxyo/pZRSkeJuHDygTTRKKUUT3clqjPkW+LYp8lJKKRUUlzV4nThJKaXiMcCLdrYqpRTEUYDXsK6UUpHiJsBH0BYapZSK0wCvlFIqTgO8drIqpVScBnillFLxF+C17q6UUkFxE+AjR0dqmFdKqbgJ8EoppSJpgFdKqTgVnwFeR9EopVScBnillFLxF+CN6BOdlFIK4ijA61w0SikVKW4CvFJKqUjxGeC1iUYppeI0wCullIq/AG9E9IlOSilFHAZ4pZRSQRrglVIqTsVngNcWGqWUitMAr5RSKl4DvFbhlVIqbgJ8xZ2sRvSeVqWUgjgK8DYrsBudtEAppYB4CvDW74DNpneyKqUUcRTg7VYNPqBNNEopBcRRgLdZcd3YdLpgpZSCOArwQkUNPm5OSSmlDkjcREO7VYMP2LSJRimlII4CfKiTVbSTVSmlII4CfEUnq9EmGqWUAuIowEtYE41OF6yUUjEM8CKSKCKLRORHEVklIn+IVV4ANu1kVUqpCI4Ypl0OjDLGFIuIE/heRD4zxvwvFplpJ6tSSkWKWYA3wXaSYuul0/qJWdtJRA1eW2iUUiq2bfAiYheR5cAe4EtjzMIo+1wjIotFZPHevXsbnJc9dKOTNtEopRTEOMAbY/zGmIFAd+BoEekXZZ/pxpihxpihHTp0aHBeolMVKKVUhHoFeBGxiUh6fTMxxuQDc4Az63tsfdgCAZ1sTCmlLLUGeBF5Q0TSRSQFWAmsFpG76nBcBxFpYy0nAacBaw60wDWxBQJag1dKKUtdavBHGGMKgfOBz4BewG/rcFwXYI6IrAB+INgG/3GDS1oHYgIExMaO++6LZTZKKdUq1GUUjdMa5ng+8H/GGK+I1NoGYoxZAQw60ALWh80YjE3w7dzZlNkqpVSLVJca/PPAFiAF+E5EDgYKY1mohgo20egoGqWUgjrU4I0x04BpYau2isjJsStSw9mMCXayKqWUqlMn6y1WJ6uIyEsishQY1QRlqzftZFVKqUp1qe5OtDpZTwfaEuxgfSKmpWog0Rq8UkqF1CUaVlSJzwZeM8asClvXothMAKM1eKWUAuoW4JeIyBcEA/xsEUkDArEtVsNoE41SSlWqyzDJq4CBwCZjTKmIZAK/i22xGkY7WZVSqlJdRtEERKQ7cKk138tcY8xHMS9ZA+gwSaWUqlSXUTRPALcAq62fm0XksVgXrCHEGG2DV0opS12aaM4GBhpjAgAiMgNYBtwfy4I1hM0EtIlGKaUsdY2GbcKWM2JRkMagnaxKKVWpLjX4x4FlIjKH4PDIkcC9MS1VA2knq1JKVapLJ+ubIvItMMxadY8xZldMS9VA2smqlFKVqg3wIjJ4v1XbrN9dRaSrMWZp7IrVMNrJqpRSlWqqwf+lhm2GFjgfjS2gTTRKKVWh2gBvjGmRM0bWxGa0k1UppSrEVXVXdJikUkqFxFU0tAd0sjGllKoQVwFejNFRNEopZak2GorI5WHLI/bbdmMsC9VQ2smqlFKVaoqGt4ct/2O/bRNjUJYDpp2sSilVqaYAL9UsR3vdIiT17as1eKWUstQUDU01y9Fetwh2m2gnq1JKWWq60SlLRFYQrK0fai1jvT4k5iVrAJvNpk00SillqSnA922yUjQSu9OlTTRKKWWp6U7WreGvrUf1jQR+NsYsiXXBGsLusCPp6SQNGNDcRVFKqWZX0zDJj0Wkn7XcBVhJcPTMayJyaxOVr15sCKvad8anrTRKKVVjJ2svY8xKa/l3wJfGmN8Ax9BCh0l+nVsIwMd9+jdzSZRSqvnVFOC9YcunAJ8CGGOKgEAsC3WgSp2u5i6CUko1u5o6WX8RkZsIzgM/GPgcQESSAGcTlK3B2paVNHcRlFKq2dVUg78KOBKYAFxsjMm31h8LvBzjcjXIsRkpAHht9mYuiVJKNb+aRtHsAa6Lsn4OMCeWhWqoF/r15Kj5q/BogFdKqRof2fdhTQcaY85t/OIcmARrDHzp3r0E3G5siYnNXCKllGo+NbXBDwd+Ad4EFtJC558J57LuYvU4XeS+8grtr6tyAaKUUr8aNQX4zsBpwHjgUuAT4E1jzKqmKFhDJNgqAryTgNvdzKVRSqnmVW0nqzHGb4z53BhzJcGO1Q3At3WdC15EeojIHBFZLSKrROSWRipzTXni9HrwOhy4s7NjnZ1SSrVoNdXgEZEE4ByCtfiewDTg/Tqm7QPuMMYsFZE0YImIfGmMWX0A5a2Vy+fD43Qh+mQnpdSvXE2drK8C/Qje4PSHsLta68QYsxPYaS0XiUg20A2IbYD3evE4nKCzSiqlfuVqquZeDvQGbgEWiEih9VMkIoX1yUREegKDCHbW7r/tGhFZLCKL9+7dW59ko3JZTTRKKfVrV9M4+EZp4xCRVOA94FZjTJUvBmPMdGA6wNChQw/4QSJOq4lGa/BKqV+7mDZUi4iTYHB/3Rjzn1jmVcHl9QZr8BrglVK/cjEL8CIiwEtAtjHmr7HKZ38unwePs0VPlaOUUk0iljX4EcBvgVEistz6OTuG+QFhTTSBFj3hpVJKxVzMeiONMd/TDHe/urxe3C4XxXPmkPvGG7S79NKmLoJSSrUIcTdY3OWtbKLZ/cdHmrk0SinVfOIuwDt9PjwOfeCHUkrFXYAPjaJRSqlfufgL8DqKRimlgDgM8KFRNEop9SsXdwF+/yYa744dzVgapZRqPnEY4CObaEr+V2X6G6WU+lWIuwDv9Pnw2x34rakKdt5/fzOXSCmlmkfcBXiX1wuA16EdrUqpX7f4C/A+D0CVkTTu1asxHk9zFEkppZpF3AV4p9cHEDGSxvPzz2weM5bdf36yzumULluGe+3aRi9fUzGBAP6CguYuhlKqGcVdgHf5KppoKkfS+PPyAChbsaLO6Wwdfymbzzu/cQvXhPb+7WnWHXMs/vz85i6KUqqZxF2AT+3RHYhsojE+n7XQsOeJ+PLyMFbbfmtR+MVsAA3wSv2KxV2A73jeeQAR89FsvexyANzZ2ZQuWxb1uOysvvx81dVV1htjWD/8OHbcc28MSqtUdMbjoXTJkuYuhmrl4i7AZ9iCwyMLU1OrbvT72Tr+0mo7W0vmz6823cJPP22U8jU108CrlpZuz1/+SnZW3+YuRszsfuLPbL3sctzr1jU4DV9eHutHjTqgNFTrFncBvpM9GOD3tmlX7T71CnoxDpA/T7yKNf0HNHq60vRT8TepnBdeaO4ixJR7XbCD/0Ca2Iq/nYtvx05yX/pXYxVLtTJxF+A724O/97VpW+0+5evW1z3BGAf4kgULfjXDN0t/+IHsrL74cnObuyj14i8upnzDhmbJWxrl2cLxdRUXKClp8LH5s2aRndUX7+7djViilivuAnySzUZaSTE5GdUH+IJZs/AXFeGzRteEy581i7x33onYt1WL8r/ty8sjUFra5EXJsWqSZct/bPK89077R4ObdH6eeBWbRv+mkUvUcO516yiaM4fdf36yVQ/lbYj89/7D2iFDKd+0uUHHF7wf/H/2bNpU72MLP/2Ush+b/rN7IOIuwAN03bub9T16Vrs97/XXWTfsaNYPP47djz9O4ZdfhrbtvPc+dj34UOXrB35fbTrG768coVMHJQsW8MuNN+LLzcW7fXudj6uL0sWLI2rHnq1bAch/990q+64ffhybzr+gynrj8bD+hJEUzv6CojlzyHvzzRrzLJz9BUVffdUIpa9qx+9/z7pjjg299u3bh7+4uMHp7Xv22QYf667H8NqGCp8Uz7tnD2WLq+9g3XzueWybfD25L7/Mz1dcGfOyVafw89lsOvc8TBM+/7hozjcAlG9s4BVVxRW5dWXkz88nO6sveW+9Xeuh22+/gy0XX9KwfJtJ/AV4EY7/cTGrDu3D1s5da909d8arbL/p5gZltfXSy1jT7yiM31/jfr6cHAIlJfxy7XUUf/U1648bwYZTTm1QntXJ+dfLAJTtN0rIs3Fj1P29P/9ctZx5efj27mX3o4+ybfL17PrDH2vMc/stt7DtxpsaWGLIefFFiud9H3VbwbvvRdyotf74E9h42un1zsO9bh2BJmoCC5SUkH1Uf4q+mVOv44q++ooNo06heO5cAAree69yY21NNI3ShNMwO+66i/J16+pVyWl2oSbX4PvmsSpaeTNnkjtjRr2uDPZvatx03vlsOOOMRilmY4m7AG9LSmL091+T5C7j7VPPadS0vbt2hZbLN24MXa5tHjO22mPKN21m/YjjWXfciBrTznvrbfxFRY1T0CgC5eW1fhE1tT1T/8Ivkyax6YIxFH7+ea37+6M0qdXEt28fm889L+KKLBpjTOgmOM8vv1C2alW98qlQvmULeL3s/cc/6nVc2YqfAHBnrwmukHr8W9YxwPuLi8nO6sv2u+6mfNMmyjfXr4nDn58favvO7ncU226+JWK7CQSiDl4IlJQQKCurV14QvDrc/fjjodebx4wlO6sv7tWrq+ybO2NG3c/HKmOxdSUQasL0+9n9+BNsuaRuNfTSpUtZf9yIiM9t+dq1eLdWrTgBbLvlVjacelrdytiI4i7Au3r2pE1xEUev+pFFRwxo1O6linbY4nnfs+mc0aH15WvXUvbTyqhTE+e9/joApry8xrR3Pfwwux6e0niFtRjrHVg7YCA77r2vQWlsOPU0dj74YMS6fc89V+fjf772Woq++Sb02p+fT/77lX0b5dnZbL/zrgaVLXfGjGqbbgLW+urufaiQ99prbLnoYornz2fjaaezZey4BpWl4sPm27u3Tl/Wxphg0Nyv2QBb2L/lgdTgwzb5du4EoPCjj9h09jlsOuvsag/LzurL1t/9LmLdumOHs2HUKVZiPoq++CL8RFhzxJHsfuRPVdJaO2QoawcNpvj76ocgR7P9llvInfFq6HVFYPftCJ5HoCj4tw2Ul7P78SdC97rsr3zjRkoWLqosqvVHqki77MflEfvXtW/KvTJYCSj9YXG1+/jz80NfbkWzZ+Pdtq1OaTemuAvwFYb/tJR9bTP5sXfjjZUOFBfjz8/HvfKnKtu2XHghP0+YAEDBBx+Q8/Ir5M18KxTggVrvhvXl5FTmVVbG+pNHUbJgQZ3KVtMXSEXNqvCjj+qU1v4jh7zbtpH/TmRb/t6/T6tyWMnCRcFaVljHn/F4KJn7HduuvwHv9uAHfOf997Pzvv2+bGoIVP7i6kdN7H78CXY/8ifKVq1i7zPPRNYio6S54/4HqqwrXx8cVRWtX6R06dLQsnfHDoq+/bayXEVF7J32jyp3Svv37WPT2bVfPea+9BJrhwytHPJplVdsDWt2McaQ99bboZr2gYw2Kf3v/6qsq21uo7w33gCgeO5cir6ZQ/G8eaFtBe+/36ByVPxt9rfz/vsp+OhjfrFuTqzuXDedM5qfr4zeT7H54osrv5QqPisVNfx584KjbfbsCaZfXeCv4XO77tjhbDq/eac7idsAf+LShWQUFTL9gvGhueEbw7pjh0cNbuF23HMve/78Z3ZNmVKvtEsXLiRv5lsAeDZvxrdzJ7ufmgpYNZWnniJQUsKagYPYcPoZoY5UqPkmrT11mGTNs3VrqA043LZbbg0t1/YPvv2OOwAo/ORTcl55hZKFi9g0Zkxoe/n62jvGjNeL16ptVij5b+WXXLQJ4wo++IAtY8ex7x//h2fjRozfT+6MGQSifOkV/Oc/oWXP1q3kWkEpmHnlYqC8HH9hIVsvvSy0bsOoU9h23eTQ6z1PTWXfs89SODs4LUTO9Omhbb69e0PLZStWsPvJp9j54IMRQ2ILP58dWTjrY1qvEU4i7J02Dffq1ZT+97/BK0GraSO8Rl3bvR/enTvZeMaZEe998fz55L7274h+kmgdquG1+d1P/Jlfrr2Obddfzy+TromalzGmzveibKphPqgdd91F6eLqa9DhQvcThGXr/jGs83y/GJH3evBz4V65Mvj6zZmhbcbvp+ynqpW8aKprsgm34777q1wxNRZH7bu0PolHHgmrVnHDO6/y2MQbef/kMxn3zWdNkve6Eccf0PG7pkyh7SUXh16XZ2eT86+XEYed3Jf+hSkrw7jdeH/+mY1nnEnfNdk1/rOUzP2O0kU/hF5XN/534xlnVr4I+7AXza4MQttuupmDX51RbV7+ffuAyEBXZ14v/uJi9vz5SfLDhqnmzphB6bLKy+jcl1+m0z13V5tM8dy5OFatYvfjT5BWQ4fXrj8+EqpxOrsH5y/a9fDDoe1bLrqY8lqGIAbcVtuyz4fxeikKG40VbstFlX/PlOHDST87evPI3r/8lZSjj2bfs3Vv/vLn5LDv2efY9+xzdP+/YNu/P7dqX0XBf6LXoHNnzCD5mGMo+uILPFu3kv9e5RfgL1Gm7oio3Fifkx13Vf49cl95JWo+hZ98QuIRfcm86io2/eY3eH/+hawVwT4s7+7d2JKTKfjoI9qOH48Jb7MPBCKuBKpl/Q9kZ/WlzSUX02XKFMqWV35utt9+Bwf966Vq72spX2P1f/j9BNxuTGD//qrK49Yc2a/GogRKSyn7aWWN++S++hq7H3uMrOzVDb66qYu4DPDiCs5Dc+oP8/l62AheOvciRvy4mC45e2s58sD5w5pZahOtwyiaPU8+Scc7g7XjvDeqDl2srekl/B9m3z//GVrOffVV8t54k0M++jBy/2qGvZUuWsT22++g21//Uqdy15dnS9WriN2PP1GvNPZYVzwAgWrawcs3bAgFdyBq22hNwX3zhRfR8a478e2p/DzV5+7okv8tZM/f/hqqHYar0sFrBVETCGDcbmzJydWma3z+0DH7d1pHywus99fhIHOSFcxrudgt+LDys1LfG/T2PDWVpIED8WwIjuzy5+fjy8uL6A/w5+Sy75lnIo6r7kqgOvkz36LN2HFsuWR8aF3oarcOf6e1AwdVlicvv+bzjNI6sHH06FBfAUQ287lXr6bgo48rvwhjPMQ0LgN8qC0TuP3NF5nw0FSe/O21TJ32GPYmHLNbm+pG37hXr64y8mDP1OhB9eeJEylZ8N8655kfdqm5+7HgpXzFEMsKFTXxaAo//RR726o3kTXWUESf1ebZGCq+qPYfEhrtS7I+3NNGhI4AAB47SURBVD/9FDH+vHjud6SMHFllv0BpaZWAXL5hA/uevaMeuQU/y3uefIrcV16hz/LqO4y33xpsTiv++muKv/46YpsnSv/Cvn8+H1zw+UKdhtFq/+F8+zWf1Vf4Z3XdscPJvO7ayDLtF9zrI7yPa8uFF0Zs827fHuxjqeed6TsfeICiOd8gzro/IS48uAMRzXxbLr0M43aHXjdkhFF9SEuajGro0KFmcR3b1GqydcLvKP1fZSfR7GNO4IkJ1zPuq0+4/r1/t45ZWmy2Bn+793jpxaiX19VxHXxwRHt+fXX+4x/Y9dDDte/YSOlkjBtLwbvv1bpfU3IddmioZlqh4513kHn11Y06KVrHu+5iz1NP1euY9LPPovDTpmmibMnq+39RH32WLmHt4CEHlEbfNdkNOk5ElhhjhkbdFo8B3rt7NxtOPCli3dOX/I4PTjydEct/4K5/TyejpOF3RSpVV32WL4u45FfNJ+X44yn5PvqNdQcq9ZRTqlw11VcsAnxcNtE4O3Wqsu6mt2eQUVzEq+eMJadNW+5/+Rl67NkV5WilGk/Zj7Gf5kDVTayCO3DAwT1W4naYZNvLLot4bQ8E+N3H7/KH5//Kxm4Hc8Uf/sYL512Mz2ZvphKqX4PqxmAr1RTiNsB3vOtOXIceGnwR9nzWkct/4MVH76H/umzeOPN8Jj3wOPMGDMUd9pBupZSKB3HZBl/BvW4dm889j4Teh0W9yWbuoKN5buzl7M7sQHpxEefN/YLR87+hY17rmq9cKdX6aRt8fdXy3XXiskUM/2kpS/v049kLf8tr54zltXPG0m/DGkYuW8SJyxZqsFdKtVoxC/Ai8i9gNLDHGFPzrV8xV/3ASJfPx7GrlnPsquVs6dyNr48ewX/7DeLZC6/gubGXc/Cu7Yz4cTG9f9nCwHXZZJTEbsZHpZRqTLGswb8C/B/wai37xVD9mp967trOVR++zVUfvs32Dp349LiT+emwPrx+VvDhGBII0LaogAHrszlo1w6O2rCGw7b9rEFfKdUixSzAG2O+E5GesUq/joUI/m7AZGPd9u5m0gfBuz5LExL54Yj+bOp2ELsyOzB38DHMGXocAHa/D5fXS/c9uzjsly2kuMtoW1jAQbu20zEvh8yCfNoV5reOm6uUUnGl2dvgReQa4BqAgw46qFHTdnTsCED66NHs/etfI/NNSKh1jvYKyeVuTly2iBOXBeeVvv2NFylOSuHH3lls7H4whSmpbO3SnfkDhlKWkIh3v9uabX4/AbudNkUFJJeVkVzuxuNwklFSROd9e7AHArh8XpLcbjJKiihJTCKpvJxkdylJ5eWklJUixlCWmER6SRG2QICSpGTaFhYgGBI8XrwOO3Z/gHKXi845e0nweljW50i67t1NUrmbBI+HpPJy7H4fe9tl4rM5sAf8OPx+OufsoSwhCb/Nhs0EcHm9eJxO3K4E7IEARsBnd5BSVoY94Mfl9ZCXlkHbokI8Tic+ux0jghiDGENJUjI+u4PU0hLSSotx+v14HE5KExMRY3D6fOSlZ5BaWoIYQ4LXg8/uwOtwYA8ESHK7KU5OJtldht9mx+N0kuwuw4iQl5aB1+Gk677dlCYmgTE4/H6MCAGbjRR3GX6bjZLEJAI2G22KiyhNSMQe8BMQGy6vB4/TRW56Bu2KCrD7/Tit6X5LEpNw+bzY/X5sFdPGJqeQXBac3dFugrOJl1ppJ3jK8ThdpJSVUu50keANTtewvUNn2ufnYkSwBwLY/T7sxhAQwe1KICASysdvdxAQwR4InkPFOrs12VVhSiqJ5eV4nE4cfj/FScm0LSoABIffR0FqGillZTh9XrwOJ3a/D7/djhiDERtGwGGdn80YPE4nfpsdtysh+LnwevBao8wcPh8Bmw2vw0luehu67d2F32bHHvDjdiWQm55BosdDQITMwnx8djsunw+/CD6HAzEGn91BwGbDb7ORn5ZOu8ICUktLKE1Mwmd3kOAJ/s95nE4SPeWUJSSR4Cknweuh3OnC4fcTsAX/zh3zcihMSWNv23ZkFBdh9/tJLSvlp0MPp+fO7SR6ykl2lyFAQUoqLp+XcqcLv80eWs4syKM0MYkEj8cqrxcDBGw2K69gWZ0+X/Dz5/fjt9sBwe1ykVTuxp2QiAQClLsSSC8pwmd3UJaQSJLHjcPnw4jgt9vxi43kcjdehwNbIIDP4cAvwc9kRdqlScl4HQ48DicJXg8urxef3R76vDW2mI6isWrwH9e1Db6xR9FAcK4HSUxkTd8jItYfNGMG+e++W/c50uvI7XRRkJrGL526UpCaRkFqGvvatGVXZgd8dgdFySmUJCXTIT+X4qRkdmV2CAatesx10dokeMoJiK3e51jxxVhXEgiQ4PHgTkwMrXN6vVXylUAAY6t+hLDD5yMggmDw2x2h/SuCU7krIWJ/p9eD1+ki0e2m3OWKSNvm9+PyeQmIDY+r6lDcaGWxBQKICRAQW9RyBoN4ZN0swVNOuSshanoOnw+fw1HlOFsggIEa34vq8qs43uX14E5IrP5c/H7sAT/esGHIdf27RvvbVTkH68u9IedQsU4CARx+X0QZG6risxDOFggQsNlCv6OZ+OHbPPa3xxqU5693FA3BR/gBdH/m/3AdfDCuQw+lfO1aErOySB42lA4338TPV19dp3mb6yLR6yExL4dOeXWfVdJrtyMGArZgDc/l9VKQmoYtEMDjdFKWmITX7sCdkEBpYhJGJFhDsNtDtRADeJ1OctLbhGojGcVFFKakkl5SjN9upywhkXKni4ziItwJCdgCAfLSM7AFAqRYU98WJyXj8Puw+wNkFBfhs9vxuFwExEbAehBFfmo6mQV55Kelk1FcjMPvw+1KwOH3YQsESC0rxeH3UZyUQnFyCkXJKbhdCbQrzAcR8lPT8NvstCkuJNG6inInJJBkTcJUnJyMGENpYhLtCvMJiC1YG7LZsAcC7GmbSVpJManuMpLcZRSmpOJ1OHH4fXgcTlLdZaSUllCSlEypVStP8HiwB/wUJafg8PlILykmPy2dRKtmFxAJXQmUJSTi9PsoSk4hrbTECrgGd0ICfrGBCBnFhcErAp+X/NR0AjYbHqeT1NIStnfoTGZhPunFRRQnp1CWkECy243Pbg/ll+D1hK56bIEARckpJJW7MWILfbl4HU7aFeaTl5aB3XrcYrCmZ0j0eELvh89upzgpOZgmgrFJ8D2zO8goLqQ0MYmkcjdeR/BKyON0srVzNzKKi8goLsRvt+NxOHEnJNAxL5cd7Tvi9PmsGqYnVDstSEsnraQYh98fugr12e3WlZYNj9OF1+HAb60rSE0j2e3G7veTXlJMSVIyLq+HssREUktLyU1vg8MfvLqoCIApZaWUJSSS7C6jNDGJ1LJSsnseSnpJMQfv2s7eNu3w2R14nE6Syt24vF6cfh8On4/8tHTsgQASCIQ+G3vbtKM0KYnU0lLaFBficboIWP8/HqcLu9+HsdnwOJwIwb9FQIK1+k65+yhJSmZfm7YEbDbSSktILS3B7g/gdTjY0649mQV5FCclk+Iuo8yVgNfppENe8OrNb7NR7nIFr9C9XgqTU0j0evDaHbQvyGNfRtvglVwgwPAV1T9k/UDEfYCvkHbKKaHlxKwsAMRmw9WjR3MVKcRZ8azUQHBUD0BiPb4glFIqmpjdySoibwL/BfqIyDYRuSpWeR2otFNObe4iKKV+5WLRXB6zAG+MGW+M6WKMcRpjuhtjXopVXgeq4x2303v+9xFTGiilVFOSRny0aIW4nYumPsRux5GZSYebbgKg5zvv0OOFF3AdfHAzl0wdiKRBOk2v+nXTAB8mc9LV9PrgA5KO6kfqCcdz6OzP6bsmm0M//4ze877DnpkZ2rfzlPo94MLRoUNouePdd5MR9jDq1uTgf7/W4GOThx/biCWpXc8336h9p2rY27evdR/XIYc0OP36smdkhJYPm/ttzPPreOcdHFTN81UPRNLAgY2eZlNIPOqoWveRGh6n2Fw0wIcRm43EPodXWe/q2RNHhw70fOstkgYMIGPcWNpecgnUYwhfz3feDi1nTvwdXR97FFtKSmhd73nfReyffMwx9S5/TY9zq06n+++vdpKjzlOmVFmX1L8/nR56kN4L5tc7r4Nffhln1671Pi6azn/4Q5326/XBB6HlpMGD655BHa6Wu/yxbmU4EO1vuAGA5OHDgeAXj7NTJ7rW86lOXR59lINenUGbC8fVum/mpKvJvPpqUo49Jvig6jB1+fu1vfTSasvXJuyB8o4uXWpNqybtr7++5u3We1fFfv+3aaedVmteB79W+w35Xf/0SJV1zjre23P4ooV12q++NMDXg6t7N3q+NZOuf/pT1O2Z111bOUVxmL5rsnF27kz7G24gc/J1UY8Nr+EDpJ95Rq3l6bN0CT3ffou0008HwBY2/rv3gvl0eawO42qtdj9Hly4kHnlkaHXPd96h7SUX0+G220LrOt51J+Jy0e7SS3G0a1dtkj2e/yc9XnyRrn+ZWmVbh9tvB5GIQNFu4kQOD7v/wd6mTa3FrvhyTBkxgkM++5SuTz0Zdb/EPoeTOmoUCX360PON1wFw9epF3zXZHPTyv6pNv83554cedF6d5KFDyRhbeSXm6tUrtHzol1+ElnvP/z70Pvf68AMOeiXyGbjhOt59d8TrtFNGAZB+1lkAoWeDpp99Vo1l25+zWzdSjj6aLo9EBqFo74G9beXfNuW44+g9/3tSTzyRQ2d/zqGzKx/m3fbSS0nofVjEsamnnEKn3z9A8rCqw7K7/mUqbc4/P/S6/bXX4jy45gBYXZB2dOlC0sABwXJcfjmH/7Ao+JhL4LCvvyIrezVtL7+synEZY8fQe78roO7/mMbhixZWqWQBtL/xRro88Ti2xMTKB5OHp3feuTg6d8aWkYE9s+pV38Gvzqj23LJW/kTGmDEc+sVs7Onp1e53ILRX8UDs1ynS8dZb8e3eg2dj8Nmc7W+4AXFU1hY63HRj1GR6vhWcEsHeoT3+vfs49MsvcHbvTsn/FtJm7BjK12+I+hxOW3IySf370+0vU/EXBx9BmDlpEuUbN+Jo1442Yy4gedhQcqZPp824cez8/YOAwbdnL/6Cgoi0es/5Bgg+8FsSE0mwmh/aX3sNpYsXUzJvHgm9e1ctvMNBh5tvJlBURMnChbhXrMCWlkayVVu2JSRQungJCYcHr4wyRp9DxuhzMIEA5WvXsvmCMaSdeiriqryhJeGwwyjd74a3dldNJPelKMEoI52EXr1w9eyJuBJIGTGC7bfdRpsxF4T26fFs5YOcD5s7F3t6WvCFRK/f9Hr/PyT06YPYbFWeqdr7+3msP/4EJCF4s1PXRx+lzZgxSEIiBf95D8/mzQC4evSg58w3saVn4MjMpP3k69j37HM4O3fG2bUr9nbt6P73p9n62ysi8k49+SS8234h7403ycpejYjQd0023oqHXVsjLcRuJ/3ssyn89NMq5Xd260baaadR/N13eDZtst7TyorH4Qv/x4ZTTiVQXEzK8OHYUlIIlJSQMXYMBe/9p8rn2pGZSY/n/1kln07334d31y42nnoazq5daTdxIhm/GY3YbDg7d6b3gvmsP25EKM/wZiYASUzgoBdeoPCTTyj66mvcq1ZVycPeruoD3gG6T/s7if360f2Z/yN15EjE6eSQD2ZR8sMPOLt1C5a7bVu6Pf03EBvicrJt8vXBK+8o9g+wB7/2KoiQPLTqF1X66NEUfvwxrl696PrnP4fWlyxcFFo+6JVXCLjLcHbuTLsrryR3xgw63nMPzi5d2H7rrXR66EHE4aDrY49GLU9j0QB/AFzdu+PZsiViXacHHqDg/feB6gN6hdRTRlH44UckWOPybUnJ+AnWxEWE7n9/OrjfyJFkXjWRzWPHkdC7NwWzZkWkI04njrbBf4SOd9weWcYePUK1tkM++hCA4nnz+GXSNdbBkf/MiUdE3vFbk0M//wxbWhoOq29iy/hLq+yTduqppJ1adRiq2Gwk9u0b0Tx06JdfULb8R1KOH8Huxx+n8MOwu4zDRpA5unQh7fTTyBgzho633WqdhpB+RvBK5qAXpldbZmenjqHl5KOHkXnNNeRMn07iUUfh6tmTwo8+wt4uE6nmjkN7ejqHfvVlRPNa8pDgw5YdHdqT98abofXh7c3tb7yRzKuvxma10x5uNXF1+dMj1hdv5XzgnX7/ezree2/EqAq7dcXU4eabq5QpddQoOt55J5vOPhuAxCOPpNO991C6dGnw/ZgxA0dYn4I9I4Pe380lUDFVR0U+AevLw1a30RzicBDeltVuvxqzo107Mq+9FuPxRAT3PsuXkffGm2T85jeI3U77yZNpP3ly6Iu014cfULZ8ObseerjaJiFHZiYiEnF/S0Lv3lUqIelnnhlarnh/jSc4pUSHO26nzbjoTVbJw4ZVWZd68ihyXniRtNNOo/Djj3F26VztsSnHRmliNYa0M07noFdeblATbIMYY1rMz5AhQ0xr4tm92xR++aVZ3SfLbLns8tD61X2yzOo+WbUeHygvN56dO0Ovy3/+2ex9fnrNxwQCZnWfLJMz49WGF9wYU7p8uVndJ8uUb95c675br55kVvfJMkVz59a4X/HChWbdCSONr6j4gMpmjDEBny/0Pq7uk2V2Pflknd/X+vLm5hp/WZnxl5WZ0hUrqmxfM3SYWd0ny/jy82tNq2z1apP/wQf1yr+h5+Vet85sOONM48vLi0jHXxx8/3c9/kTwb7x1a43prBky1Kzuk2XyP/jArO6TZUqWLq1x/7VHH2O2/PYKY4wx5b9sM6v7ZJl1J59c7/LvL/x9CAQCpnTZstDnfXWfLFOyeHHlOZaUHHB+1ZXh5xtuqHW//I8/Nt7c3Ih1xf9bWCUWGGNM+ebNZu2I4yP+1xsTsNhUE1ObPaiH/7S2AF/BV1RkAuXlode5b75pcv7972YsUeMq+v57s7pPlvHu29ek+e6YMsWs7pNldjz4kPEVFsYswNemIgD6Cgpikn5jndfup54yhd98E3od8HqNe926Wo8rWbrUbL/7HhMIBOr95ewvKTGr+2SZfS++WO/y7m/NkKFmx8MPV1lf8f4E/P5m+wzUhTc316zuk2UKvviiSfOtKcDH9SP7VHzxFxeDMdjT0po037y33mbXww+TtfInq1micVU0TTT0kW3xruL9ycpezZq+R+Dq2ZNDP/+smUvVcvyqJxtT8cOemtos+ba9+CLaXnxRzNI/5JOPQ5PiqeqJCD2mP09i376176wADfBKNbuEKENrVSVxuUIdo6kjRzZzaVoXDfBKqRbtkI8/wr1mTXMXo1XSAK+UatFcBx2Eq5Gf9vZroXeyKqVUnNIAr5RScUoDvFJKxSkN8EopFac0wCulVJzSAK+UUnFKA7xSSsUpDfBKKRWnNMArpVSc0gCvlFJxSgO8UkrFKQ3wSikVpzTAK6VUnNIAr5RScUoDvFJKxSkN8EopFac0wCulVJzSAK+UUnFKA7xSSsUpDfBKKRWnNMArpVSc0gCvlFJxKqYBXkTOFJG1IrJBRO6NZV5KKaUixSzAi4gdeAY4CzgCGC8iR8QqP6WUUpFiWYM/GthgjNlkjPEAM4HzYpifUkqpMI4Ypt0N+CXs9TbgmP13EpFrgGusl8UisraB+bUH9jXw2JZGz6XliZfzAD2Xlqqh53JwdRtiGeDrxBgzHZh+oOmIyGJjzNBGKFKz03NpeeLlPEDPpaWKxbnEsolmO9Aj7HV3a51SSqkmEMsA/wPQW0R6iYgLuAT4MIb5KaWUChOzJhpjjE9EbgRmA3bgX8aYVbHKj0Zo5mlB9Fxanng5D9Bzaaka/VzEGNPYaSqllGoB9E5WpZSKUxrglVIqTrX6AN8apkMQkX+JyB4RWRm2rp2IfCki663fba31IiLTrPNZISKDw4650tp/vYhc2Uzn0kNE5ojIahFZJSK3tNbzEZFEEVkkIj9a5/IHa30vEVlolfkta5AAIpJgvd5gbe8ZltZ91vq1InJGU5+LVQa7iCwTkY9b+XlsEZGfRGS5iCy21rW6z5dVhjYi8q6IrBGRbBEZ3qTnYoxptT8EO283AocALuBH4IjmLleUco4EBgMrw9Y9CdxrLd8L/NlaPhv4DBDgWGChtb4dsMn63dZabtsM59IFGGwtpwHrCE5F0erOxypTqrXsBBZaZXwbuMRa/09gsrV8PfBPa/kS4C1r+Qjrs5cA9LI+k/Zm+NvcDrwBfGy9bq3nsQVov9+6Vvf5ssoxA7jaWnYBbZryXJr0ZGPw5g0HZoe9vg+4r7nLVU1ZexIZ4NcCXazlLsBaa/l5YPz++wHjgefD1kfs14zn9QFwWms/HyAZWErwbut9gGP/zxjBEWHDrWWHtZ/s/7kL368Jy98d+BoYBXxslavVnYeV7xaqBvhW9/kCMoDNWINZmuNcWnsTTbTpELo1U1nqq5MxZqe1vAvoZC1Xd04t7lytS/tBBGu+rfJ8rGaN5cAe4EuCtdZ8Y4wvSrlCZba2FwCZtIxzeRq4GwhYrzNpnecBYIAvRGSJBKcygdb5+eoF7AVetprOXhSRFJrwXFp7gI8LJvi13KrGq4pIKvAecKsxpjB8W2s6H2OM3xgzkGAN+Gggq5mLVG8iMhrYY4xZ0txlaSTHG2MGE5yJ9gYRGRm+sRV9vhwEm2afM8YMAkoINsmExPpcWnuAb83TIewWkS4A1u891vrqzqnFnKuIOAkG99eNMf+xVrfa8wEwxuQDcwg2ZbQRkYqbAMPLFSqztT0DyKH5z2UEcK6IbCE4a+so4O+0vvMAwBiz3fq9B3if4Bdva/x8bQO2GWMWWq/fJRjwm+xcWnuAb83TIXwIVPSGX0mwLbti/RVWj/qxQIF1OTcbOF1E2lq97qdb65qUiAjwEpBtjPlr2KZWdz4i0kFE2ljLSQT7ErIJBvpx1m77n0vFOY4DvrFqYB8Cl1ijU3oBvYFFTXMWYIy5zxjT3RjTk+D/wDfGmMtoZecBICIpIpJWsUzwc7GSVvj5MsbsAn4RkT7WqlOA1TTluTR1B0oMOjLOJjiSYyPwQHOXp5oyvgnsBLwEv9WvItjm+TWwHvgKaGftKwQflLIR+AkYGpbORGCD9fO7ZjqX4wleUq4Alls/Z7fG8wH6A8usc1kJPGStP4RgYNsAvAMkWOsTrdcbrO2HhKX1gHWOa4GzmvGzdhKVo2ha3XlYZf7R+llV8T/dGj9fVhkGAoutz9gsgqNgmuxcdKoCpZSKU629iUYppVQ1NMArpVSc0gCvlFJxSgO8UkrFKQ3wSikVpzTAqxZLRDKtGQWXi8guEdke9tpVy7FDRWRaHfJY0HglrpJ2GxG5PlbpK1UbHSapWgURmQIUG2Omhq1zmMq5Vloca66ej40x/Zq5KOpXSmvwqlURkVdE5J8ishB4UkSOFpH/WpM5Lai4a1BETpLKedGnSHBO/m9FZJOI3ByWXnHY/t+Gzd39unXXLiJytrVuiTVf98dRynWkBOeWX27N5d0beAI41Fr3lLXfXSLyg7VPxfzzPcPyzLbKkGxte0KCc++vEJGp++erVE1i9tBtpWKoO3CcMcYvIunACSb4kPdTgceAsVGOyQJOJjiH/VoRec4Y491vn0HAkcAOYD4wQoIPnHgeGGmM2Swib1ZTpuuAvxtjXreaj+wEJ5bqZ4KTmSEipxO8/f9ognctfijBibR+BvoAVxlj5ovIv4DrReRl4AIgyxhjKqZVUKqutAavWqN3jDF+azkDeEeCT8v6G8EAHc0nxphyY8w+gpM7dYqyzyJjzDZjTIDgFAw9CX4xbDLGbLb2qS7A/xe4X0TuAQ42xpRF2ed062cZwbnnswgGfIBfjDHzreV/E5wSogBwAy+JyBigtJq8lYpKA7xqjUrClh8B5ljt3L8hOM9KNOVhy36iX73WZZ+ojDFvAOcCZcCnIjIqym4CPG6MGWj9HGaMeakiiapJGh/B2v67wGjg87qWRynQAK9avwwqp06dEIP01wKHSOVzSy+OtpOIHEKwpj+N4OyA/YEigk1CFWYDEyU4lz4i0k1EOlrbDhKR4dbypcD31n4ZxphPgduAAY12VupXQQO8au2eBB4XkWXEoE/Jamq5HvhcRJYQDNoFUXa9CFgpwadD9QNeNcbkAPNFZKWIPGWM+YLgM1P/KyI/EayZV3wBrCX4cItsgjMOPmdt+1hEVgDfE3zmqlJ1psMklaqFiKQaY4qtUTXPAOuNMX9rxPR7osMpVQxoDV6p2k2yauarCDYJPd/M5VGqTrQGr5RScUpr8EopFac0wCulVJzSAK+UUnFKA7xSSsUpDfBKKRWn/h9jl/9dqHtQ7QAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_learning_curve(model_loss_record)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "kzLQMv2fRX4_",
        "outputId": "8fa76491-ef28-4987-8b12-e1a4927edd6c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "del model\n",
        "model = NeuralNet(tr_set.dataset.dim).to(device)\n",
        "ckpt = torch.load(config['save_path'], map_location='cpu')  # Load your best model\n",
        "model.load_state_dict(ckpt)\n",
        "plot_pred(dv_set, model, device)  # Show prediction on the validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnCRPrKzRdMQ",
        "outputId": "27a1ecfd-6700-486b-d95f-839e5565b9f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving results to pred_2.csv\n"
          ]
        }
      ],
      "source": [
        "preds = test(tt_set, model, device)    # predict COVID-19 cases with your model\n",
        "save_pred(preds, 'pred_2.csv')         # save prediction file to pred_2.csv\n",
        "\n",
        "model = NeuralNet(tr_set.dataset.dim).to(device)  # Construct model and move to device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdDTPE0VR2Ep"
      },
      "source": [
        "As examined on Kaggle, the predictions generated by the model considering only 42 features gained a score of 1.05789, which is lower than the score we originally got and passed both the medium baselines. Notably, the minimum validation loss of the second model was higher. This indicates that the first model, which considered 93 features, clearly overfitted the data, so even if it was able to get a pretty low validation loss, the test loss was high. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN0PD49j4eFz"
      },
      "source": [
        "# **Section 7. Apply L1 and L2 regularization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uz7KqtFnTuJq"
      },
      "source": [
        "Note that at this point, we are not sure if the second model also overfitted the data but just not as much as the first model did. To further prevent overfitting, we can apply common techniques like regularization, boosting or bagging. In this section, we will apply L1 and L2 regularization to the model. \n",
        "\n",
        "As a reminder, a regression model that uses L1 regularization is called Lasso regression (with Lasso standing for Least Absolute Shrinkage and Selection Operator) and the model which uses L2 regularization is called ridge regression. The key difference between these two is the penalty term (the term associated with $\\lambda$ below). Specifically, in the context of multiple linear regression,\n",
        "- The cost function of Lasso regression: $\\text{Loss}=\\text{Error}(y, \\hat{y})+\\lambda\\sum_{i=1}^pw_{i}^2$\n",
        "- The cost function of ridge regression: $\\text{Loss}=\\text{Error}(y, \\hat{y})+\\lambda\\sum_{i=1}^p|w_{i}|$\n",
        "\n",
        "The underlying working principle of both techniques is based on the fact that the predicted value is less sensitive to features associated with a smaller weight. \n",
        "\n",
        "Notably, if $\\lambda=0$, both Lasso regression and ridge regression degrade to ordinary linear regression in this case, while an excessively large $\\lambda$ value will lead to under-fitting. \n",
        "\n",
        "\n",
        "https://www.youtube.com/watch?v=NyG-7nRpsW8&ab_channel=DeepLearningAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkYlH9_rcs-I"
      },
      "source": [
        "https://stackoverflow.com/questions/42704283/l1-l2-regularization-in-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlBCS0ZUqzvT"
      },
      "outputs": [],
      "source": [
        "class NeuralNet_L1Regularized(nn.Module):\n",
        "    ''' A simple fully-connected deep neural network '''\n",
        "    def __init__(self, input_dim):\n",
        "        super(NeuralNet_L1Regularized, self).__init__()\n",
        "\n",
        "        # Define your neural network here\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1))\n",
        "\n",
        "        # Mean squared error loss\n",
        "        self.criterion = nn.MSELoss(reduction='mean')\n",
        "\n",
        "    def forward(self, x):\n",
        "        ''' Given input of size (batch_size x input_dim), compute output of the network '''\n",
        "        return self.net(x).squeeze(1)\n",
        "\n",
        "    def cal_loss(self, pred, target, L1_lambda=1e-3):\n",
        "        ''' Calculate loss '''\n",
        "        loss = self.criterion(pred, target)\n",
        "        reg = 0\n",
        "        for name, param in model.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                reg += torch.norm(param, 1)\n",
        "        loss += L1_lambda * reg\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMKsCvvurfae",
        "outputId": "f2f9184d-3cc4-4408-8b39-0ce781992b5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished reading the train set of COVID19 Dataset (2430 samples found, each dim = 93)\n",
            "Finished reading the dev set of COVID19 Dataset (270 samples found, each dim = 93)\n",
            "Finished reading the test set of COVID19 Dataset (893 samples found, each dim = 93)\n",
            "Saving model (epoch = 1, validation loss = 72.4538\n",
            "Saving model (epoch = 2, validation loss = 56.6179\n",
            "Saving model (epoch = 3, validation loss = 36.9211\n",
            "Saving model (epoch = 4, validation loss = 18.9587\n",
            "Saving model (epoch = 5, validation loss = 10.9251\n",
            "Saving model (epoch = 6, validation loss = 7.6819\n",
            "Saving model (epoch = 7, validation loss = 6.4082\n",
            "Saving model (epoch = 8, validation loss = 5.5567\n",
            "Saving model (epoch = 9, validation loss = 4.9509\n",
            "Saving model (epoch = 10, validation loss = 4.3650\n",
            "Saving model (epoch = 11, validation loss = 3.9680\n",
            "Saving model (epoch = 12, validation loss = 3.6075\n",
            "Saving model (epoch = 13, validation loss = 3.3418\n",
            "Saving model (epoch = 14, validation loss = 3.1350\n",
            "Saving model (epoch = 15, validation loss = 2.9385\n",
            "Saving model (epoch = 16, validation loss = 2.7853\n",
            "Saving model (epoch = 17, validation loss = 2.6579\n",
            "Saving model (epoch = 18, validation loss = 2.4903\n",
            "Saving model (epoch = 19, validation loss = 2.3779\n",
            "Saving model (epoch = 20, validation loss = 2.2914\n",
            "Saving model (epoch = 21, validation loss = 2.2192\n",
            "Saving model (epoch = 22, validation loss = 2.1623\n",
            "Saving model (epoch = 23, validation loss = 2.0799\n",
            "Saving model (epoch = 24, validation loss = 2.0085\n",
            "Saving model (epoch = 25, validation loss = 1.9494\n",
            "Saving model (epoch = 26, validation loss = 1.8861\n",
            "Saving model (epoch = 27, validation loss = 1.8320\n",
            "Saving model (epoch = 28, validation loss = 1.8136\n",
            "Saving model (epoch = 29, validation loss = 1.7829\n",
            "Saving model (epoch = 30, validation loss = 1.7480\n",
            "Saving model (epoch = 31, validation loss = 1.7213\n",
            "Saving model (epoch = 32, validation loss = 1.6725\n",
            "Saving model (epoch = 33, validation loss = 1.6375\n",
            "Saving model (epoch = 34, validation loss = 1.6225\n",
            "Saving model (epoch = 35, validation loss = 1.6144\n",
            "Saving model (epoch = 36, validation loss = 1.5650\n",
            "Saving model (epoch = 39, validation loss = 1.5325\n",
            "Saving model (epoch = 41, validation loss = 1.5023\n",
            "Saving model (epoch = 42, validation loss = 1.4937\n",
            "Saving model (epoch = 44, validation loss = 1.4612\n",
            "Saving model (epoch = 46, validation loss = 1.4487\n",
            "Saving model (epoch = 48, validation loss = 1.4390\n",
            "Saving model (epoch = 49, validation loss = 1.4335\n",
            "Saving model (epoch = 51, validation loss = 1.4184\n",
            "Saving model (epoch = 53, validation loss = 1.4079\n",
            "Saving model (epoch = 54, validation loss = 1.3656\n",
            "Saving model (epoch = 57, validation loss = 1.3546\n",
            "Saving model (epoch = 59, validation loss = 1.3408\n",
            "Saving model (epoch = 62, validation loss = 1.3275\n",
            "Saving model (epoch = 65, validation loss = 1.3070\n",
            "Saving model (epoch = 69, validation loss = 1.2886\n",
            "Saving model (epoch = 74, validation loss = 1.2767\n",
            "Saving model (epoch = 77, validation loss = 1.2693\n",
            "Saving model (epoch = 80, validation loss = 1.2610\n",
            "Saving model (epoch = 83, validation loss = 1.2557\n",
            "Saving model (epoch = 86, validation loss = 1.2542\n",
            "Saving model (epoch = 87, validation loss = 1.2492\n",
            "Saving model (epoch = 90, validation loss = 1.2482\n",
            "Saving model (epoch = 91, validation loss = 1.2364\n",
            "Saving model (epoch = 92, validation loss = 1.2300\n",
            "Saving model (epoch = 95, validation loss = 1.2170\n",
            "Saving model (epoch = 96, validation loss = 1.2168\n",
            "Saving model (epoch = 99, validation loss = 1.2082\n",
            "Saving model (epoch = 108, validation loss = 1.2010\n",
            "Saving model (epoch = 115, validation loss = 1.1917\n",
            "Saving model (epoch = 118, validation loss = 1.1861\n",
            "Saving model (epoch = 119, validation loss = 1.1859\n",
            "Saving model (epoch = 123, validation loss = 1.1767\n",
            "Saving model (epoch = 125, validation loss = 1.1745\n",
            "Saving model (epoch = 126, validation loss = 1.1662\n",
            "Saving model (epoch = 129, validation loss = 1.1647\n",
            "Saving model (epoch = 132, validation loss = 1.1635\n",
            "Saving model (epoch = 134, validation loss = 1.1592\n",
            "Saving model (epoch = 137, validation loss = 1.1422\n",
            "Saving model (epoch = 151, validation loss = 1.1376\n",
            "Saving model (epoch = 163, validation loss = 1.1318\n",
            "Saving model (epoch = 167, validation loss = 1.1316\n",
            "Saving model (epoch = 173, validation loss = 1.1266\n",
            "Saving model (epoch = 174, validation loss = 1.1251\n",
            "Saving model (epoch = 175, validation loss = 1.1100\n",
            "Saving model (epoch = 182, validation loss = 1.1094\n",
            "Saving model (epoch = 188, validation loss = 1.1026\n",
            "Saving model (epoch = 190, validation loss = 1.1016\n",
            "Saving model (epoch = 193, validation loss = 1.0988\n",
            "Saving model (epoch = 197, validation loss = 1.0973\n",
            "Saving model (epoch = 205, validation loss = 1.0948\n",
            "Saving model (epoch = 209, validation loss = 1.0836\n",
            "Saving model (epoch = 229, validation loss = 1.0758\n",
            "Saving model (epoch = 238, validation loss = 1.0718\n",
            "Saving model (epoch = 252, validation loss = 1.0709\n",
            "Saving model (epoch = 261, validation loss = 1.0698\n",
            "Saving model (epoch = 262, validation loss = 1.0694\n",
            "Saving model (epoch = 267, validation loss = 1.0615\n",
            "Saving model (epoch = 278, validation loss = 1.0568\n",
            "Saving model (epoch = 282, validation loss = 1.0561\n",
            "Saving model (epoch = 285, validation loss = 1.0460\n",
            "Saving model (epoch = 310, validation loss = 1.0433\n",
            "Saving model (epoch = 313, validation loss = 1.0398\n",
            "Saving model (epoch = 324, validation loss = 1.0352\n",
            "Saving model (epoch = 330, validation loss = 1.0327\n",
            "Saving model (epoch = 335, validation loss = 1.0317\n",
            "Saving model (epoch = 354, validation loss = 1.0291\n",
            "Saving model (epoch = 360, validation loss = 1.0289\n",
            "Saving model (epoch = 361, validation loss = 1.0239\n",
            "Saving model (epoch = 375, validation loss = 1.0234\n",
            "Saving model (epoch = 382, validation loss = 1.0176\n",
            "Saving model (epoch = 385, validation loss = 1.0090\n",
            "Saving model (epoch = 394, validation loss = 1.0065\n",
            "Saving model (epoch = 416, validation loss = 1.0054\n",
            "Saving model (epoch = 417, validation loss = 1.0042\n",
            "Saving model (epoch = 438, validation loss = 1.0014\n",
            "Saving model (epoch = 440, validation loss = 0.9977\n",
            "Saving model (epoch = 454, validation loss = 0.9948\n",
            "Saving model (epoch = 468, validation loss = 0.9902\n",
            "Saving model (epoch = 497, validation loss = 0.9846\n",
            "Saving model (epoch = 513, validation loss = 0.9826\n",
            "Saving model (epoch = 519, validation loss = 0.9779\n",
            "Saving model (epoch = 528, validation loss = 0.9737\n",
            "Saving model (epoch = 556, validation loss = 0.9676\n",
            "Saving model (epoch = 563, validation loss = 0.9585\n",
            "Saving model (epoch = 616, validation loss = 0.9555\n",
            "Saving model (epoch = 643, validation loss = 0.9505\n",
            "Saving model (epoch = 663, validation loss = 0.9504\n",
            "Saving model (epoch = 692, validation loss = 0.9444\n",
            "Saving model (epoch = 697, validation loss = 0.9432\n",
            "Saving model (epoch = 698, validation loss = 0.9377\n",
            "Saving model (epoch = 735, validation loss = 0.9369\n",
            "Saving model (epoch = 746, validation loss = 0.9308\n",
            "Saving model (epoch = 778, validation loss = 0.9296\n",
            "Saving model (epoch = 789, validation loss = 0.9296\n",
            "Saving model (epoch = 817, validation loss = 0.9285\n",
            "Saving model (epoch = 830, validation loss = 0.9285\n",
            "Saving model (epoch = 834, validation loss = 0.9266\n",
            "Saving model (epoch = 845, validation loss = 0.9227\n",
            "Saving model (epoch = 885, validation loss = 0.9212\n",
            "Saving model (epoch = 887, validation loss = 0.9209\n",
            "Saving model (epoch = 903, validation loss = 0.9155\n",
            "Saving model (epoch = 904, validation loss = 0.9154\n",
            "Saving model (epoch = 913, validation loss = 0.9148\n",
            "Saving model (epoch = 922, validation loss = 0.9096\n",
            "Saving model (epoch = 1001, validation loss = 0.9080\n",
            "Saving model (epoch = 1008, validation loss = 0.9055\n",
            "Saving model (epoch = 1048, validation loss = 0.9035\n",
            "Saving model (epoch = 1219, validation loss = 0.9032\n",
            "Saving model (epoch = 1241, validation loss = 0.9029\n",
            "Saving model (epoch = 1248, validation loss = 0.9025\n",
            "Saving model (epoch = 1329, validation loss = 0.8982\n",
            "Saving model (epoch = 1387, validation loss = 0.8924\n",
            "Saving model (epoch = 1559, validation loss = 0.8918\n",
            "Saving model (epoch = 1672, validation loss = 0.8907\n",
            "Saving model (epoch = 1679, validation loss = 0.8888\n",
            "Finished training after 1880 epochs\n"
          ]
        }
      ],
      "source": [
        "device = get_device()                    # get the current available device ('cpu' or 'cuda')\n",
        "os.makedirs('models', exist_ok=True)     # The trained model will be saved to ./models/\n",
        "feats= list(range(93))\n",
        "\n",
        "config = {\n",
        "    'n_epochs': 3000,                # maximum number of epochs\n",
        "    'batch_size': 270,               # mini-batch size for dataloader\n",
        "    'optimizer': 'SGD',              # optimization algorithm (optimizer in torch.optim)\n",
        "    'optim_hparas': {                # hyper-parameters for the optimizer (depends on which optimizer you are using)\n",
        "        'lr': 0.001,                 # learning rate of SGD\n",
        "        'momentum': 0.9              # momentum for SGD\n",
        "    },\n",
        "    'early_stop': 200,               # early stopping epochs (the number epochs since your model's last improvement)\n",
        "    'save_path': 'models/model.pth'  # your model will be saved here\n",
        "}\n",
        "\n",
        "tr_set = prep_dataloader(tr_path, 'train', config['batch_size'], feats=feats)\n",
        "dv_set = prep_dataloader(tr_path, 'dev', config['batch_size'], feats=feats)\n",
        "tt_set = prep_dataloader(tt_path, 'test', config['batch_size'], feats=feats)\n",
        "\n",
        "model = NeuralNet_L1Regularized(tr_set.dataset.dim).to(device)  # Construct model and move to device\n",
        "\n",
        "model_loss, model_loss_record = train(tr_set, dv_set, model, config, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoUIKxJlrk9S",
        "outputId": "bcc0eaf7-8a15-4cd1-894f-906dab7c3c6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving results to pred_3.csv\n"
          ]
        }
      ],
      "source": [
        "preds = test(tt_set, model, device)  # predict COVID-19 cases with your model\n",
        "save_pred(preds, 'pred_3.csv')         # save prediction file to pred_3.csv\n",
        "\n",
        "model = NeuralNet(tr_set.dataset.dim).to(device)  # Construct model and move to device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbA2o0UspPeW"
      },
      "outputs": [],
      "source": [
        "class NeuralNet_L2Regularized(nn.Module):\n",
        "    ''' A simple fully-connected deep neural network '''\n",
        "    def __init__(self, input_dim):\n",
        "        super(NeuralNet_L2Regularized, self).__init__()\n",
        "\n",
        "        # Define your neural network here\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1))\n",
        "\n",
        "        # Mean squared error loss\n",
        "        self.criterion = nn.MSELoss(reduction='mean')\n",
        "\n",
        "    def forward(self, x):\n",
        "        ''' Given input of size (batch_size x input_dim), compute output of the network '''\n",
        "        return self.net(x).squeeze(1)\n",
        "\n",
        "    def cal_loss(self, pred, target, L2_lambda=1e-3):\n",
        "        ''' Calculate loss '''\n",
        "        loss = self.criterion(pred, target)\n",
        "        reg = 0\n",
        "        for name, param in model.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                reg += torch.norm(param, 2) ** 2\n",
        "        loss += L2_lambda * reg\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GA9tXssTu2te",
        "outputId": "ffa792e4-e972-48d5-da47-31567e9513a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished reading the train set of COVID19 Dataset (2430 samples found, each dim = 93)\n",
            "Finished reading the dev set of COVID19 Dataset (270 samples found, each dim = 93)\n",
            "Finished reading the test set of COVID19 Dataset (893 samples found, each dim = 93)\n",
            "Saving model (epoch = 1, validation loss = 92.0185\n",
            "Saving model (epoch = 2, validation loss = 47.4792\n",
            "Saving model (epoch = 3, validation loss = 32.5150\n",
            "Saving model (epoch = 4, validation loss = 19.7341\n",
            "Saving model (epoch = 5, validation loss = 12.5001\n",
            "Saving model (epoch = 6, validation loss = 7.8977\n",
            "Saving model (epoch = 7, validation loss = 6.0645\n",
            "Saving model (epoch = 8, validation loss = 5.1280\n",
            "Saving model (epoch = 9, validation loss = 4.4077\n",
            "Saving model (epoch = 10, validation loss = 3.9489\n",
            "Saving model (epoch = 11, validation loss = 3.5226\n",
            "Saving model (epoch = 12, validation loss = 3.2015\n",
            "Saving model (epoch = 13, validation loss = 2.9357\n",
            "Saving model (epoch = 14, validation loss = 2.6962\n",
            "Saving model (epoch = 15, validation loss = 2.5539\n",
            "Saving model (epoch = 16, validation loss = 2.3621\n",
            "Saving model (epoch = 17, validation loss = 2.2368\n",
            "Saving model (epoch = 18, validation loss = 2.1048\n",
            "Saving model (epoch = 19, validation loss = 2.0163\n",
            "Saving model (epoch = 20, validation loss = 1.9626\n",
            "Saving model (epoch = 21, validation loss = 1.9302\n",
            "Saving model (epoch = 22, validation loss = 1.7945\n",
            "Saving model (epoch = 23, validation loss = 1.7170\n",
            "Saving model (epoch = 24, validation loss = 1.6645\n",
            "Saving model (epoch = 25, validation loss = 1.6137\n",
            "Saving model (epoch = 26, validation loss = 1.5556\n",
            "Saving model (epoch = 27, validation loss = 1.5151\n",
            "Saving model (epoch = 28, validation loss = 1.4836\n",
            "Saving model (epoch = 29, validation loss = 1.4311\n",
            "Saving model (epoch = 30, validation loss = 1.4133\n",
            "Saving model (epoch = 31, validation loss = 1.3720\n",
            "Saving model (epoch = 32, validation loss = 1.3517\n",
            "Saving model (epoch = 33, validation loss = 1.3334\n",
            "Saving model (epoch = 34, validation loss = 1.2929\n",
            "Saving model (epoch = 35, validation loss = 1.2889\n",
            "Saving model (epoch = 36, validation loss = 1.2716\n",
            "Saving model (epoch = 37, validation loss = 1.2280\n",
            "Saving model (epoch = 38, validation loss = 1.2169\n",
            "Saving model (epoch = 39, validation loss = 1.2053\n",
            "Saving model (epoch = 40, validation loss = 1.2010\n",
            "Saving model (epoch = 41, validation loss = 1.1873\n",
            "Saving model (epoch = 42, validation loss = 1.1632\n",
            "Saving model (epoch = 43, validation loss = 1.1463\n",
            "Saving model (epoch = 45, validation loss = 1.1195\n",
            "Saving model (epoch = 47, validation loss = 1.1149\n",
            "Saving model (epoch = 48, validation loss = 1.0960\n",
            "Saving model (epoch = 50, validation loss = 1.0766\n",
            "Saving model (epoch = 53, validation loss = 1.0757\n",
            "Saving model (epoch = 54, validation loss = 1.0515\n",
            "Saving model (epoch = 56, validation loss = 1.0326\n",
            "Saving model (epoch = 59, validation loss = 1.0226\n",
            "Saving model (epoch = 62, validation loss = 1.0165\n",
            "Saving model (epoch = 63, validation loss = 1.0074\n",
            "Saving model (epoch = 64, validation loss = 1.0038\n",
            "Saving model (epoch = 68, validation loss = 1.0010\n",
            "Saving model (epoch = 72, validation loss = 0.9940\n",
            "Saving model (epoch = 75, validation loss = 0.9800\n",
            "Saving model (epoch = 77, validation loss = 0.9739\n",
            "Saving model (epoch = 79, validation loss = 0.9678\n",
            "Saving model (epoch = 81, validation loss = 0.9602\n",
            "Saving model (epoch = 87, validation loss = 0.9454\n",
            "Saving model (epoch = 93, validation loss = 0.9307\n",
            "Saving model (epoch = 102, validation loss = 0.9245\n",
            "Saving model (epoch = 103, validation loss = 0.9136\n",
            "Saving model (epoch = 112, validation loss = 0.9100\n",
            "Saving model (epoch = 113, validation loss = 0.9072\n",
            "Saving model (epoch = 114, validation loss = 0.9039\n",
            "Saving model (epoch = 118, validation loss = 0.9024\n",
            "Saving model (epoch = 121, validation loss = 0.9017\n",
            "Saving model (epoch = 122, validation loss = 0.8983\n",
            "Saving model (epoch = 123, validation loss = 0.8930\n",
            "Saving model (epoch = 125, validation loss = 0.8882\n",
            "Saving model (epoch = 128, validation loss = 0.8842\n",
            "Saving model (epoch = 139, validation loss = 0.8798\n",
            "Saving model (epoch = 146, validation loss = 0.8753\n",
            "Saving model (epoch = 156, validation loss = 0.8649\n",
            "Saving model (epoch = 157, validation loss = 0.8645\n",
            "Saving model (epoch = 159, validation loss = 0.8593\n",
            "Saving model (epoch = 167, validation loss = 0.8573\n",
            "Saving model (epoch = 173, validation loss = 0.8534\n",
            "Saving model (epoch = 177, validation loss = 0.8445\n",
            "Saving model (epoch = 189, validation loss = 0.8438\n",
            "Saving model (epoch = 193, validation loss = 0.8428\n",
            "Saving model (epoch = 203, validation loss = 0.8399\n",
            "Saving model (epoch = 220, validation loss = 0.8359\n",
            "Saving model (epoch = 227, validation loss = 0.8352\n",
            "Saving model (epoch = 235, validation loss = 0.8263\n",
            "Saving model (epoch = 278, validation loss = 0.8257\n",
            "Saving model (epoch = 288, validation loss = 0.8246\n",
            "Saving model (epoch = 296, validation loss = 0.8235\n",
            "Saving model (epoch = 305, validation loss = 0.8213\n",
            "Saving model (epoch = 326, validation loss = 0.8184\n",
            "Saving model (epoch = 329, validation loss = 0.8173\n",
            "Saving model (epoch = 345, validation loss = 0.8128\n",
            "Saving model (epoch = 369, validation loss = 0.8125\n",
            "Saving model (epoch = 378, validation loss = 0.8078\n",
            "Saving model (epoch = 431, validation loss = 0.8042\n",
            "Saving model (epoch = 489, validation loss = 0.8003\n",
            "Saving model (epoch = 497, validation loss = 0.7983\n",
            "Saving model (epoch = 596, validation loss = 0.7967\n",
            "Saving model (epoch = 690, validation loss = 0.7953\n",
            "Saving model (epoch = 720, validation loss = 0.7906\n",
            "Saving model (epoch = 826, validation loss = 0.7894\n",
            "Finished training after 1027 epochs\n"
          ]
        }
      ],
      "source": [
        "device = get_device()                    # get the current available device ('cpu' or 'cuda')\n",
        "os.makedirs('models', exist_ok=True)     # The trained model will be saved to ./models/\n",
        "feats= list(range(93))\n",
        "\n",
        "config = {\n",
        "    'n_epochs': 3000,                # maximum number of epochs\n",
        "    'batch_size': 270,               # mini-batch size for dataloader\n",
        "    'optimizer': 'SGD',              # optimization algorithm (optimizer in torch.optim)\n",
        "    'optim_hparas': {                # hyper-parameters for the optimizer (depends on which optimizer you are using)\n",
        "        'lr': 0.001,                 # learning rate of SGD\n",
        "        'momentum': 0.9              # momentum for SGD\n",
        "    },\n",
        "    'early_stop': 200,               # early stopping epochs (the number epochs since your model's last improvement)\n",
        "    'save_path': 'models/model.pth'  # your model will be saved here\n",
        "}\n",
        "\n",
        "tr_set = prep_dataloader(tr_path, 'train', config['batch_size'], feats=feats)\n",
        "dv_set = prep_dataloader(tr_path, 'dev', config['batch_size'], feats=feats)\n",
        "tt_set = prep_dataloader(tt_path, 'test', config['batch_size'], feats=feats)\n",
        "\n",
        "model = NeuralNet_L2Regularized(tr_set.dataset.dim).to(device)  # Construct model and move to device\n",
        "\n",
        "model_loss, model_loss_record = train(tr_set, dv_set, model, config, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqnVwnq_u54N",
        "outputId": "206c69e0-36df-42f7-dafb-da0a793922d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving results to pred_4.csv\n"
          ]
        }
      ],
      "source": [
        "preds = test(tt_set, model, device)  # predict COVID-19 cases with your model\n",
        "save_pred(preds, 'pred_4.csv')         # save prediction file to pred_4.csv\n",
        "\n",
        "model = NeuralNet(tr_set.dataset.dim).to(device)  # Construct model and move to device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcdbUUSMUVrR"
      },
      "source": [
        "# **Section 8. Hyper-parameter tuning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbdxW2jf13aV"
      },
      "source": [
        "# **Section 9. Checklist**\n",
        "Here is a checklist of the requirements to meet in the original assignment:\n",
        "- Run sample code\n",
        "- Train the neural network with 42 features (40 features corresponding to the states and any 2 user-selected) and justify the 2 selected features.\n",
        "- Explore the DNN architecture by playing around the number of layers/dimensions or different kinds activation functions.\n",
        "- Apply L2 regularization to the model.\n",
        "- Fix Mistakes in the sample codes, if any."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYSSRXel4jjc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}